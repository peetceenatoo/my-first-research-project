{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IMPORT LIBS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from openrec.tf1.legacy.utils import ImplicitDataset\n",
    "from openrec.tf1.legacy.recommenders import CML, BPR, PMF\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../Lib')  # Adjusts path to include the Lib directory where utilities.py is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GENERATE THE DATASET**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "seed = 2384795\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "# Preparing folder for output data\n",
    "output_name = f\"./generated_data/\"\n",
    "if os.path.exists(output_name) == False:\n",
    "    os.makedirs(output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MODEL CHOICE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_1430/3362066690.py:4: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prevent tensorflow from using cached embeddings\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.reset_default_graph()\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Here I won't comment anything, we are just using the code provided by the authors of the paper\n",
    "\n",
    "raw_data = dict()\n",
    "raw_data['train_data'] = np.load(output_name + \"training_arr.npy\")\n",
    "raw_data['test_data_pos_biased'] = np.load(output_name + \"biased-test_arr_pos.npy\")\n",
    "raw_data['test_data_neg_biased'] = np.load(output_name + \"biased-test_arr_neg.npy\")\n",
    "raw_data['test_data_pos_unbiased'] = np.load(output_name + \"unbiased-test_arr_pos.npy\")\n",
    "raw_data['test_data_neg_unbiased'] = np.load(output_name + \"unbiased-test_arr_neg.npy\")\n",
    "raw_data['max_user'] = 7177\n",
    "raw_data['max_item'] = 10729\n",
    "batch_size = 8000\n",
    "test_batch_size = 1000\n",
    "display_itr = 1000\n",
    "\n",
    "train_dataset = ImplicitDataset(raw_data['train_data'], raw_data['max_user'], raw_data['max_item'], name='Train')\n",
    "\n",
    "MODEL_CLASS = CML\n",
    "MODEL_PREFIX = \"cml\"\n",
    "DATASET_NAME = \"KuaiRec\"\n",
    "OUTPUT_FOLDER = output_name\n",
    "OUTPUT_PATH = OUTPUT_FOLDER + MODEL_PREFIX + \"-\" + DATASET_NAME + \"/\"\n",
    "OUTPUT_PREFIX = str(OUTPUT_PATH) + str(MODEL_PREFIX) + \"-\" + str(DATASET_NAME)\n",
    "\n",
    "\n",
    "if os.path.exists(OUTPUT_PATH) == False:\n",
    "    os.makedirs(OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **EVALUATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "raw_data = dict()\n",
    "raw_data['train_data'] = np.load(output_name + \"training_arr.npy\")\n",
    "raw_data['test_data_pos_biased'] = np.load(output_name + \"biased-test_arr_pos.npy\")\n",
    "raw_data['test_data_neg_biased'] = np.load(output_name + \"biased-test_arr_neg.npy\")\n",
    "raw_data['test_data_pos_unbiased'] = np.load(output_name + \"unbiased-test_arr_pos.npy\")\n",
    "raw_data['test_data_neg_unbiased'] = np.load(output_name + \"unbiased-test_arr_neg.npy\")\n",
    "raw_data['max_user'] = 7177\n",
    "raw_data['max_item'] = 10729\n",
    "batch_size = 8000\n",
    "test_batch_size = 1000\n",
    "display_itr = 1000\n",
    "\n",
    "# Load data\n",
    "train_dataset = ImplicitDataset(raw_data['train_data'], raw_data['max_user'], raw_data['max_item'], name='Train')\n",
    "test_dataset_pos_biased = ImplicitDataset(raw_data['test_data_pos_biased'], raw_data['max_user'], raw_data['max_item'])\n",
    "test_dataset_neg_biased = ImplicitDataset(raw_data['test_data_neg_biased'], raw_data['max_user'], raw_data['max_item'])\n",
    "test_dataset_pos_unbiased = ImplicitDataset(raw_data['test_data_pos_unbiased'], raw_data['max_user'], raw_data['max_item'])\n",
    "test_dataset_neg_unbiased = ImplicitDataset(raw_data['test_data_neg_unbiased'], raw_data['max_user'], raw_data['max_item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMAS = [1.5,2,2.5,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Propensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.5: array([[9.60897519e-04, 6.16416046e-05, 7.01853525e-04, ...,\n",
       "         6.16416046e-05, 3.48697573e-04, 0.00000000e+00],\n",
       "        [9.60897519e-04, 6.16416046e-05, 7.01853525e-04, ...,\n",
       "         6.16416046e-05, 3.48697573e-04, 0.00000000e+00],\n",
       "        [9.60897519e-04, 6.16416046e-05, 7.01853525e-04, ...,\n",
       "         6.16416046e-05, 3.48697573e-04, 0.00000000e+00],\n",
       "        ...,\n",
       "        [9.60897519e-04, 6.16416046e-05, 7.01853525e-04, ...,\n",
       "         6.16416046e-05, 3.48697573e-04, 0.00000000e+00],\n",
       "        [9.60897519e-04, 6.16416046e-05, 7.01853525e-04, ...,\n",
       "         6.16416046e-05, 3.48697573e-04, 0.00000000e+00],\n",
       "        [9.60897519e-04, 6.16416046e-05, 7.01853525e-04, ...,\n",
       "         6.16416046e-05, 3.48697573e-04, 0.00000000e+00]]),\n",
       " 2: array([[2.39448702e-04, 8.86847043e-06, 1.64246371e-04, ...,\n",
       "         8.86847043e-06, 7.09477635e-05, 0.00000000e+00],\n",
       "        [2.39448702e-04, 8.86847043e-06, 1.64246371e-04, ...,\n",
       "         8.86847043e-06, 7.09477635e-05, 0.00000000e+00],\n",
       "        [2.39448702e-04, 8.86847043e-06, 1.64246371e-04, ...,\n",
       "         8.86847043e-06, 7.09477635e-05, 0.00000000e+00],\n",
       "        ...,\n",
       "        [2.39448702e-04, 8.86847043e-06, 1.64246371e-04, ...,\n",
       "         8.86847043e-06, 7.09477635e-05, 0.00000000e+00],\n",
       "        [2.39448702e-04, 8.86847043e-06, 1.64246371e-04, ...,\n",
       "         8.86847043e-06, 7.09477635e-05, 0.00000000e+00],\n",
       "        [2.39448702e-04, 8.86847043e-06, 1.64246371e-04, ...,\n",
       "         8.86847043e-06, 7.09477635e-05, 0.00000000e+00]]),\n",
       " 2.5: array([[5.96688821e-05, 1.27592019e-06, 3.84366102e-05, ...,\n",
       "         1.27592019e-06, 1.44353891e-05, 0.00000000e+00],\n",
       "        [5.96688821e-05, 1.27592019e-06, 3.84366102e-05, ...,\n",
       "         1.27592019e-06, 1.44353891e-05, 0.00000000e+00],\n",
       "        [5.96688821e-05, 1.27592019e-06, 3.84366102e-05, ...,\n",
       "         1.27592019e-06, 1.44353891e-05, 0.00000000e+00],\n",
       "        ...,\n",
       "        [5.96688821e-05, 1.27592019e-06, 3.84366102e-05, ...,\n",
       "         1.27592019e-06, 1.44353891e-05, 0.00000000e+00],\n",
       "        [5.96688821e-05, 1.27592019e-06, 3.84366102e-05, ...,\n",
       "         1.27592019e-06, 1.44353891e-05, 0.00000000e+00],\n",
       "        [5.96688821e-05, 1.27592019e-06, 3.84366102e-05, ...,\n",
       "         1.27592019e-06, 1.44353891e-05, 0.00000000e+00]]),\n",
       " 3: array([[1.48690532e-05, 1.83568558e-07, 8.99485935e-06, ...,\n",
       "         1.83568558e-07, 2.93709693e-06, 0.00000000e+00],\n",
       "        [1.48690532e-05, 1.83568558e-07, 8.99485935e-06, ...,\n",
       "         1.83568558e-07, 2.93709693e-06, 0.00000000e+00],\n",
       "        [1.48690532e-05, 1.83568558e-07, 8.99485935e-06, ...,\n",
       "         1.83568558e-07, 2.93709693e-06, 0.00000000e+00],\n",
       "        ...,\n",
       "        [1.48690532e-05, 1.83568558e-07, 8.99485935e-06, ...,\n",
       "         1.83568558e-07, 2.93709693e-06, 0.00000000e+00],\n",
       "        [1.48690532e-05, 1.83568558e-07, 8.99485935e-06, ...,\n",
       "         1.83568558e-07, 2.93709693e-06, 0.00000000e+00],\n",
       "        [1.48690532e-05, 1.83568558e-07, 8.99485935e-06, ...,\n",
       "         1.83568558e-07, 2.93709693e-06, 0.00000000e+00]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propensities = calculate_propensities(7176,10728, output_name+\"training_arr.npy\",normalize=True)\n",
    "propensities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biased Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **COMPUTE RESULTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute AOA and unbiased evaluator metrics with biased testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "biased_results = dict()\n",
    "\n",
    "biased_results[\"AOA\"] = aoa(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", K=10)\n",
    "\n",
    "for gamma in GAMMAS:\n",
    "    key = \"UB_\" + str(gamma).replace(\".\",\"\")\n",
    "    biased_results[key] = eq(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", propensities[gamma], K=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute AOA and unbiased evaluator metrics with unbiased testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unbiased_results = dict()\n",
    "\n",
    "# unbiased_results[\"STRATIFIED_15\"] = stratified(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=1.5, K=4, partition=100)\n",
    "unbiased_results[\"AOA\"] = aoa(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", K=10)\n",
    "for gamma in GAMMAS:\n",
    "    key = \"UB_\" + str(gamma).replace(\".\",\"\")\n",
    "    unbiased_results[key] = eq(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", propensities[gamma], K=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10393,  3122,  3945,  5355,  5477,  6413,  3649,  4348,  1189,\n",
       "        1815,  6342,  8656,  5778,  8103,  6939,  5165,  6961,  8447,\n",
       "        7271,  4144,  8969,  7957,  6721,  5714,  9512,  3462,  6610,\n",
       "        8165,   630,  1460, 10510,  9667,   938, 10454,   615,  6336,\n",
       "        9287,  9686,  5768,   823,  8662,  5922,  4994,  6879,  4765,\n",
       "        8393,  3452,  4764,  2047,  4189,  9741,  5288,  8022,  4579,\n",
       "        3263,  4572,  3963,   754,  2072,  1867,  2822,  9926,  7794,\n",
       "        3833,  4800,  5253, 10281,  9049, 10707,  7062,   203,  5673,\n",
       "        8982,  4057,  6177,   527,  4346,  3661,  4005,  1802,  5220,\n",
       "        3027,  6612,  9276,  6622,  3516,  5349,  6256,  7421,  2157,\n",
       "       10658,  8175,  6753,  2406,  9792,   685,  2389,  4269,   117,\n",
       "          54,  4645,  1299,  4217,  6501,  8253,  8186,  9435,  3473,\n",
       "        5281,  7925,  1612,  3317,  6570,  5574,  2147, 10084,  4962,\n",
       "        7940,  5767,  2091,  7764,  9680,  2412,  5290,  1952,  4227,\n",
       "        1668,  9403,   813,  8740, 10407,  5300,  2442,  5883,  6976,\n",
       "        2035,  9604,  3552,  8863,  9998,  9132,  4431,  3985,  3020,\n",
       "        3506,  9992, 10513,  8698,  1242,  6540,  3872,    61,  5331,\n",
       "        2934,  2358,  7026,  9853,  3584,  1205, 10361,  3486,  8949,\n",
       "       10125,   575,  2241,  9961,  1777,  3423,  3937,   380,  5687,\n",
       "        1341,  7102,  5503,  2757,  5513,  9044,  4136, 10191,  5102,\n",
       "        7520,  3130,  4705,  1669,  6183,  6711,  2416,  8631,  7044,\n",
       "        1928,  9218,  5037,  4667, 10466, 10338,  5716, 10434,  5495,\n",
       "       10514,  3772])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get number of items\n",
    "num_items =  raw_data['max_item']\n",
    "\n",
    "# Get the n_p partitions\n",
    "n_p = 200\n",
    "nums = np.arange(1, num_items+1)\n",
    "partitions = np.random.choice(nums, n_p, replace=False)\n",
    "\n",
    "# Visualize\n",
    "partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the partition which minimizes the sum of AUC and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRATIFIED_15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae97ed51c934ef4a70243d0222e4160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1430/540939123.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     temp_biased = stratified(OUTPUT_PREFIX + \"-test-pos-biased_evaluate_partial.pickle\",\n\u001b[1;32m     24\u001b[0m                              \u001b[0mOUTPUT_PREFIX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"-test-neg-biased_evaluate_partial.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                              output_name + \"training_arr.npy\", propensities[gamma], K=30, partition=p)\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Calculate combined score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RecSys_Eval2/RecSys-Evaluation/Implementation/Lib/helper.py\u001b[0m in \u001b[0;36mstratified\u001b[0;34m(infilename, infilename_neg, trainfilename, propensities, K, partition, delta)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_item\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mpos_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0mZui\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheuser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_scores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mpos_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compute biased and unbiased results with stratified for each partition\n",
    "# and store biased and unbiased results such that the sum of AUC and Recall is minimized\n",
    "\n",
    "# Value of gamma to use for minimization\n",
    "gamma = 1.5\n",
    "\n",
    "# To print :)\n",
    "key = \"STRATIFIED_\" + str(gamma).replace(\".\",\"\")\n",
    "print(key)\n",
    "\n",
    "unbiased_results[key] = {}\n",
    "biased_results[key] = {}\n",
    "best_partition = np.random.choice(nums, 1)[0]\n",
    "best_score = float('inf')\n",
    "\n",
    "history = np.full(10729, np.inf)  # Adjusted to match the size of nums\n",
    "\n",
    "for p in tqdm(partitions):\n",
    "    # Fetch stratified results; these functions need to be defined or replaced with actual logic\n",
    "    temp_unbiased = stratified(OUTPUT_PREFIX + \"-test-pos-unbiased_evaluate_partial.pickle\",\n",
    "                               OUTPUT_PREFIX + \"-test-neg-unbiased_evaluate_partial.pickle\",\n",
    "                               output_name + \"training_arr.npy\", propensities[gamma], K=10, partition=p)\n",
    "    temp_biased = stratified(OUTPUT_PREFIX + \"-test-pos-biased_evaluate_partial.pickle\",\n",
    "                             OUTPUT_PREFIX + \"-test-neg-biased_evaluate_partial.pickle\",\n",
    "                             output_name + \"training_arr.npy\", propensities[gamma], K=10, partition=p)\n",
    "\n",
    "    # Calculate combined score\n",
    "    combined_score = temp_unbiased['bias'] + temp_unbiased['concentration'] + \\\n",
    "                     temp_biased['bias'] + temp_biased['concentration']\n",
    "\n",
    "    history[p-1] = combined_score  # Store the combined score\n",
    "\n",
    "    # Update the best_partition and best_score if the current partition's score is lower\n",
    "    if combined_score < best_score:\n",
    "        best_score = combined_score\n",
    "        best_partition = p\n",
    "\n",
    "print(f\"Best partition: {best_partition} with combined score: {best_score}\")\n",
    "print(f\"Minimum score from history: {np.min(history)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional outputs for verification\n",
    "print(\"Detailed scores from history:\", history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for the chosen value of gamma, the best partition is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "best_partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute stratified metrics with unbiased testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gamma in GAMMAS:\n",
    "    key = \"STRATIFIED_\" + str(gamma).replace(\".\",\"\")\n",
    "    unbiased_results[key] = stratified(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", propensities[gamma], K=10, partition=best_partition)\n",
    "    biased_results[key] = stratified(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", propensities[gamma], K=10, partition=best_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version uses the linspace of items instead of linspace of propensities to make the partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gamma in GAMMAS:\n",
    "    key = \"STRATIFIED_v2_\" + str(gamma).replace(\".\",\"\")\n",
    "    unbiased_results[key] = stratified_2(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", propensities[gamma], K=10, partition=best_partition)\n",
    "    biased_results[key] = stratified_2(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", propensities[gamma], K=10, partition=best_partition)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare table for results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 0\n",
    "columns = len(biased_results.keys())\n",
    "\n",
    "for key in biased_results.keys():\n",
    "    rows = max(rows, len(biased_results[key].keys()))\n",
    "\n",
    "for key in unbiased_results.keys():\n",
    "    rows = max(rows, len(biased_results[key].keys()))\n",
    "\n",
    "rows, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init dictionary\n",
    "mae_results = dict()\n",
    "\n",
    "# Get the names of the rows\n",
    "list_biased_res = list(biased_results.keys())\n",
    "\n",
    "# Init results\n",
    "results_array = np.zeros((rows,columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the table with the MAE results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each row\n",
    "for i in range(len(list_biased_res)):\n",
    "    key = list_biased_res[i]\n",
    "\n",
    "    # For each column\n",
    "    for j in range(len(list(biased_results[key].keys()))):\n",
    "        key_2 = list(biased_results[key].keys())[j]\n",
    "\n",
    "        # Compute MAE\n",
    "        results_array[j][i] = abs(biased_results[key][key_2] - unbiased_results[key][key_2])\n",
    "\n",
    "# Make it a DataFrame\n",
    "mae_df = pd.DataFrame(columns=list(biased_results.keys()), data=results_array)\n",
    "metric_values = list(biased_results[list(biased_results.keys())[0]].keys())\n",
    "mae_df.insert(0, \"metric\", metric_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RESULTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>AOA</th>\n",
       "      <th>UB_15</th>\n",
       "      <th>UB_2</th>\n",
       "      <th>UB_25</th>\n",
       "      <th>UB_3</th>\n",
       "      <th>STRATIFIED_15</th>\n",
       "      <th>STRATIFIED_2</th>\n",
       "      <th>STRATIFIED_25</th>\n",
       "      <th>STRATIFIED_3</th>\n",
       "      <th>STRATIFIED_v2_15</th>\n",
       "      <th>STRATIFIED_v2_2</th>\n",
       "      <th>STRATIFIED_v2_25</th>\n",
       "      <th>STRATIFIED_v2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.15724</td>\n",
       "      <td>0.27763</td>\n",
       "      <td>0.29181</td>\n",
       "      <td>0.29922</td>\n",
       "      <td>0.30254</td>\n",
       "      <td>0.29681</td>\n",
       "      <td>0.47593</td>\n",
       "      <td>1.36697</td>\n",
       "      <td>6.12093</td>\n",
       "      <td>0.27763</td>\n",
       "      <td>0.29181</td>\n",
       "      <td>0.29922</td>\n",
       "      <td>0.30254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.01971</td>\n",
       "      <td>0.00915</td>\n",
       "      <td>0.00802</td>\n",
       "      <td>0.00703</td>\n",
       "      <td>0.00623</td>\n",
       "      <td>0.00915</td>\n",
       "      <td>0.00802</td>\n",
       "      <td>0.00703</td>\n",
       "      <td>0.00623</td>\n",
       "      <td>0.00915</td>\n",
       "      <td>0.00802</td>\n",
       "      <td>0.00703</td>\n",
       "      <td>0.00623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>biased_bias</td>\n",
       "      <td>To be compute</td>\n",
       "      <td>Nope</td>\n",
       "      <td>Nope</td>\n",
       "      <td>Nope</td>\n",
       "      <td>Nope</td>\n",
       "      <td>3451663.26356</td>\n",
       "      <td>20184762.59991</td>\n",
       "      <td>93130045.83054</td>\n",
       "      <td>433559092.77438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>biased_concentration</td>\n",
       "      <td>Nope</td>\n",
       "      <td>Nope</td>\n",
       "      <td>Nope</td>\n",
       "      <td>Nope</td>\n",
       "      <td>Nope</td>\n",
       "      <td>113435.15748</td>\n",
       "      <td>66868.45999</td>\n",
       "      <td>43364.51613</td>\n",
       "      <td>32965.15099</td>\n",
       "      <td>154463.5961</td>\n",
       "      <td>153588.14088</td>\n",
       "      <td>153037.84968</td>\n",
       "      <td>152671.0668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unbiased_bias</td>\n",
       "      <td>To be compute</td>\n",
       "      <td>Nope</td>\n",
       "      <td>Nope</td>\n",
       "      <td>Nope</td>\n",
       "      <td>Nope</td>\n",
       "      <td>19434.09558</td>\n",
       "      <td>190039.46594</td>\n",
       "      <td>936784.57082</td>\n",
       "      <td>5960091.41135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 metric            AOA    UB_15     UB_2    UB_25     UB_3  \\\n",
       "0                   auc        0.15724  0.27763  0.29181  0.29922  0.30254   \n",
       "1                recall        0.01971  0.00915  0.00802  0.00703  0.00623   \n",
       "2           biased_bias  To be compute     Nope     Nope     Nope     Nope   \n",
       "3  biased_concentration           Nope     Nope     Nope     Nope     Nope   \n",
       "4         unbiased_bias  To be compute     Nope     Nope     Nope     Nope   \n",
       "\n",
       "   STRATIFIED_15    STRATIFIED_2   STRATIFIED_25     STRATIFIED_3  \\\n",
       "0        0.29681         0.47593         1.36697          6.12093   \n",
       "1        0.00915         0.00802         0.00703          0.00623   \n",
       "2  3451663.26356  20184762.59991  93130045.83054  433559092.77438   \n",
       "3   113435.15748     66868.45999     43364.51613      32965.15099   \n",
       "4    19434.09558    190039.46594    936784.57082    5960091.41135   \n",
       "\n",
       "  STRATIFIED_v2_15 STRATIFIED_v2_2 STRATIFIED_v2_25 STRATIFIED_v2_3  \n",
       "0          0.27763         0.29181          0.29922         0.30254  \n",
       "1          0.00915         0.00802          0.00703         0.00623  \n",
       "2              0.0             0.0              0.0             0.0  \n",
       "3      154463.5961    153588.14088     153037.84968     152671.0668  \n",
       "4              0.0             0.0              0.0             0.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize\n",
    "mae_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecSys-Evaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
