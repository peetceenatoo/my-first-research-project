{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **SETUP**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjYyDBmbcEL9"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nUxhCz5MkDZk"
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "from openrec.tf1.legacy import ImplicitModelTrainer\n",
        "from openrec.tf1.legacy.utils import ImplicitDataset\n",
        "from openrec.tf1.legacy.utils.evaluators import ImplicitEvalManager\n",
        "from openrec.tf1.legacy.recommenders import CML\n",
        "from openrec.tf1.legacy.utils.evaluators import AUC\n",
        "from openrec.tf1.legacy.utils.samplers import PairwiseSampler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "seed = 76424236\n",
        "np.random.seed(seed=seed)\n",
        "\n",
        "folder_name = f\"./generated_data/\"\n",
        "if os.path.exists(folder_name) == False:\n",
        "    os.makedirs(folder_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "g0C--vI7lUe2"
      },
      "outputs": [],
      "source": [
        "raw_data = dict()\n",
        "raw_data['train_data'] = np.load(folder_name+\"training_arr.npy\")\n",
        "raw_data['test_data_pos'] = np.load(folder_name+\"unbiased-test_arr_pos.npy\")\n",
        "raw_data['test_data_neg'] = np.load(folder_name+\"unbiased-test_arr_neg.npy\")\n",
        "raw_data['max_user'] = 15401\n",
        "raw_data['max_item'] = 1001\n",
        "batch_size = 8000\n",
        "test_batch_size = 1000\n",
        "display_itr = 1000\n",
        "\n",
        "train_dataset = ImplicitDataset(raw_data['train_data'], raw_data['max_user'], raw_data['max_item'], name='Train')\n",
        "test_dataset_pos = ImplicitDataset(raw_data['test_data_pos'], raw_data['max_user'], raw_data['max_item'])\n",
        "test_dataset_neg = ImplicitDataset(raw_data['test_data_neg'], raw_data['max_user'], raw_data['max_item'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c61lBOIqcawA"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "2vrFxwG6lrmS",
        "outputId": "944587b9-842f-4695-8607-afae26b9b217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:391: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:31: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:41: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:43: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:33: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/interactions/pairwise_eu_dist.py:71: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:596: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:75: The name tf.scatter_update is deprecated. Please use tf.compat.v1.scatter_update instead.\n",
            "\n",
            "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:144: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:365: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:148: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-24 10:13:43.513101: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2024-04-24 10:13:43.515987: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 4192050000 Hz\n",
            "2024-04-24 10:13:43.516573: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56340cd7a700 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2024-04-24 10:13:43.516591: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./generated_data/cml-yahoo\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf                         # Code to avoid tf using cached embeddings\n",
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "cml_model = CML(batch_size=batch_size, max_user=train_dataset.max_user(), max_item=train_dataset.max_item(),\n",
        "    dim_embed=50, l2_reg=0.001, opt='Adam', sess_config=None)\n",
        "sampler = PairwiseSampler(batch_size=batch_size, dataset=train_dataset, num_process=4)\n",
        "model_trainer = ImplicitModelTrainer(batch_size=batch_size, test_batch_size=test_batch_size,\n",
        "                                     train_dataset=train_dataset, model=cml_model, sampler=sampler,\n",
        "                                     eval_save_prefix=folder_name+\"yahoo\",\n",
        "                                     item_serving_size=500)\n",
        "auc_evaluator = AUC()\n",
        "\n",
        "cml_model.load(folder_name+\"cml-yahoo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTBMf1BPcvgL"
      },
      "source": [
        "## Generate Raw Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Subsampling negative items]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2296/2296 [00:00<00:00, 2936.18it/s]   \n",
            "100%|██████████| 2296/2296 [00:01<00:00, 1625.42it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'AUC': [0.4077777777777778,\n",
              "  0.46399999999999997,\n",
              "  0.5833333333333334,\n",
              "  0.5927777777777777,\n",
              "  0.4261111111111111,\n",
              "  0.29571428571428576,\n",
              "  0.33416666666666667,\n",
              "  0.495,\n",
              "  0.4075,\n",
              "  0.5044444444444445,\n",
              "  0.410625,\n",
              "  0.4857142857142857,\n",
              "  0.4828571428571428,\n",
              "  0.46437500000000004,\n",
              "  0.45562500000000006,\n",
              "  0.5883333333333334,\n",
              "  0.42000000000000004,\n",
              "  0.43499999999999994,\n",
              "  0.5471428571428572,\n",
              "  0.4905555555555556,\n",
              "  0.501875,\n",
              "  0.4675000000000001,\n",
              "  0.4116666666666667,\n",
              "  0.50125,\n",
              "  0.606875,\n",
              "  0.37625,\n",
              "  0.2,\n",
              "  0.445625,\n",
              "  0.306875,\n",
              "  0.63,\n",
              "  0.47214285714285714,\n",
              "  0.5816666666666667,\n",
              "  0.3638888888888889,\n",
              "  0.5038888888888889,\n",
              "  0.4861111111111111,\n",
              "  0.42714285714285716,\n",
              "  0.48062499999999997,\n",
              "  0.2075,\n",
              "  0.6461111111111111,\n",
              "  0.4035714285714286,\n",
              "  0.54,\n",
              "  0.33625,\n",
              "  0.639375,\n",
              "  0.5959999999999999,\n",
              "  0.4288888888888889,\n",
              "  0.42312500000000003,\n",
              "  0.5549999999999999,\n",
              "  0.4066666666666667,\n",
              "  0.59,\n",
              "  0.4311111111111111,\n",
              "  0.42000000000000004,\n",
              "  0.483,\n",
              "  0.3025,\n",
              "  0.3333333333333333,\n",
              "  0.3105555555555556,\n",
              "  0.5828571428571429,\n",
              "  0.59125,\n",
              "  0.48,\n",
              "  0.36166666666666664,\n",
              "  0.4069999999999999,\n",
              "  0.39111111111111113,\n",
              "  0.5638888888888888,\n",
              "  0.44833333333333325,\n",
              "  0.42357142857142854,\n",
              "  0.48777777777777775,\n",
              "  0.6522222222222223,\n",
              "  0.48666666666666675,\n",
              "  0.448125,\n",
              "  0.4838888888888888,\n",
              "  0.42416666666666664,\n",
              "  0.5283333333333333,\n",
              "  0.48187500000000005,\n",
              "  0.4983333333333333,\n",
              "  0.42166666666666663,\n",
              "  0.5940000000000001,\n",
              "  0.41944444444444445,\n",
              "  0.31833333333333336,\n",
              "  0.48777777777777787,\n",
              "  0.4494444444444444,\n",
              "  0.50875,\n",
              "  0.35062499999999996,\n",
              "  0.4783333333333333,\n",
              "  0.3425,\n",
              "  0.513125,\n",
              "  0.5722222222222222,\n",
              "  0.5544444444444444,\n",
              "  0.62,\n",
              "  0.441875,\n",
              "  0.2775,\n",
              "  0.48,\n",
              "  0.5238888888888888,\n",
              "  0.5505555555555557,\n",
              "  0.59375,\n",
              "  0.5411111111111111,\n",
              "  0.6883333333333334,\n",
              "  0.41333333333333333,\n",
              "  0.4083333333333333,\n",
              "  0.5988888888888888,\n",
              "  0.4472222222222222,\n",
              "  0.4864285714285715,\n",
              "  0.454375,\n",
              "  0.35,\n",
              "  0.40166666666666667,\n",
              "  0.3483333333333334,\n",
              "  0.6155555555555555,\n",
              "  0.6127777777777778,\n",
              "  0.5733333333333334,\n",
              "  0.42625,\n",
              "  0.56625,\n",
              "  0.47071428571428575,\n",
              "  0.49,\n",
              "  0.5272222222222223,\n",
              "  0.42277777777777786,\n",
              "  0.515,\n",
              "  0.45375,\n",
              "  0.34750000000000003,\n",
              "  0.41000000000000003,\n",
              "  0.585,\n",
              "  0.50125,\n",
              "  0.32428571428571423,\n",
              "  0.42666666666666664,\n",
              "  0.6216666666666667,\n",
              "  0.47555555555555556,\n",
              "  0.53,\n",
              "  0.27666666666666667,\n",
              "  0.4233333333333333,\n",
              "  0.5114285714285715,\n",
              "  0.4116666666666667,\n",
              "  0.38875000000000004,\n",
              "  0.5035714285714286,\n",
              "  0.5655555555555556,\n",
              "  0.38125,\n",
              "  0.3116666666666667,\n",
              "  0.479375,\n",
              "  0.61,\n",
              "  0.4422222222222223,\n",
              "  0.6644444444444445,\n",
              "  0.4593750000000001,\n",
              "  0.5577777777777777,\n",
              "  0.42833333333333334,\n",
              "  0.4772222222222222,\n",
              "  0.45444444444444443,\n",
              "  0.426,\n",
              "  0.4444444444444444,\n",
              "  0.5777777777777778,\n",
              "  0.396875,\n",
              "  0.59,\n",
              "  0.5794444444444444,\n",
              "  0.475,\n",
              "  0.5077777777777778,\n",
              "  0.4516666666666667,\n",
              "  0.5527777777777777,\n",
              "  0.475,\n",
              "  0.423125,\n",
              "  0.5183333333333333,\n",
              "  0.3514285714285714,\n",
              "  0.44111111111111106,\n",
              "  0.548888888888889,\n",
              "  0.46437500000000004,\n",
              "  0.2927777777777778,\n",
              "  0.33055555555555555,\n",
              "  0.6766666666666666,\n",
              "  0.4577777777777778,\n",
              "  0.6177777777777778,\n",
              "  0.505,\n",
              "  0.45687500000000003,\n",
              "  0.38500000000000006,\n",
              "  0.23124999999999998,\n",
              "  0.6544444444444444,\n",
              "  0.499375,\n",
              "  0.5725,\n",
              "  0.3483333333333334,\n",
              "  0.3375,\n",
              "  0.5666666666666667,\n",
              "  0.5877777777777777,\n",
              "  0.5592857142857143,\n",
              "  0.110625,\n",
              "  0.525625,\n",
              "  0.3927777777777778,\n",
              "  0.6483333333333333,\n",
              "  0.469375,\n",
              "  0.445,\n",
              "  0.4464285714285715,\n",
              "  0.4921428571428571,\n",
              "  0.3971428571428572,\n",
              "  0.24833333333333338,\n",
              "  0.3966666666666667,\n",
              "  0.41125,\n",
              "  0.5538888888888889,\n",
              "  0.6794444444444444,\n",
              "  0.359375,\n",
              "  0.3944444444444445,\n",
              "  0.299375,\n",
              "  0.2488888888888889,\n",
              "  0.34428571428571425,\n",
              "  0.39749999999999996,\n",
              "  0.30666666666666664,\n",
              "  0.51875,\n",
              "  0.48666666666666664,\n",
              "  0.5606249999999999,\n",
              "  0.42388888888888887,\n",
              "  0.44,\n",
              "  0.3605555555555555,\n",
              "  0.6027777777777777,\n",
              "  0.6033333333333333,\n",
              "  0.3357142857142857,\n",
              "  0.35333333333333333,\n",
              "  0.38000000000000006,\n",
              "  0.45055555555555554,\n",
              "  0.3375,\n",
              "  0.5544444444444444,\n",
              "  0.5233333333333333,\n",
              "  0.43062500000000004,\n",
              "  0.6475,\n",
              "  0.5466666666666666,\n",
              "  0.43937499999999996,\n",
              "  0.44500000000000006,\n",
              "  0.5577777777777778,\n",
              "  0.45222222222222225,\n",
              "  0.45722222222222225,\n",
              "  0.5166666666666667,\n",
              "  0.7266666666666667,\n",
              "  0.31777777777777777,\n",
              "  0.5288888888888889,\n",
              "  0.5505555555555556,\n",
              "  0.37611111111111106,\n",
              "  0.6477777777777778,\n",
              "  0.5866666666666666,\n",
              "  0.285,\n",
              "  0.36687499999999995,\n",
              "  0.3333333333333333,\n",
              "  0.5472222222222222,\n",
              "  0.5633333333333334,\n",
              "  0.41333333333333333,\n",
              "  0.3738888888888889,\n",
              "  0.5458333333333334,\n",
              "  0.26166666666666666,\n",
              "  0.2892857142857143,\n",
              "  0.5037499999999999,\n",
              "  0.5711111111111111,\n",
              "  0.5506249999999999,\n",
              "  0.45888888888888896,\n",
              "  0.5825,\n",
              "  0.465625,\n",
              "  0.4983333333333333,\n",
              "  0.6228571428571429,\n",
              "  0.4511111111111112,\n",
              "  0.33928571428571425,\n",
              "  0.549375,\n",
              "  0.563,\n",
              "  0.42375000000000007,\n",
              "  0.5605555555555556,\n",
              "  0.591111111111111,\n",
              "  0.5033333333333334,\n",
              "  0.5994444444444444,\n",
              "  0.5238888888888888,\n",
              "  0.3855555555555556,\n",
              "  0.5133333333333332,\n",
              "  0.5064285714285715,\n",
              "  0.4483333333333334,\n",
              "  0.5222222222222223,\n",
              "  0.4521428571428571,\n",
              "  0.354375,\n",
              "  0.5105555555555557,\n",
              "  0.47500000000000003,\n",
              "  0.34388888888888886,\n",
              "  0.4811111111111111,\n",
              "  0.37444444444444447,\n",
              "  0.4383333333333333,\n",
              "  0.3783333333333334,\n",
              "  0.28500000000000003,\n",
              "  0.5038888888888889,\n",
              "  0.2683333333333333,\n",
              "  0.3428571428571429,\n",
              "  0.49388888888888893,\n",
              "  0.28500000000000003,\n",
              "  0.67625,\n",
              "  0.5416666666666666,\n",
              "  0.4422222222222222,\n",
              "  0.4383333333333333,\n",
              "  0.595625,\n",
              "  0.6188888888888889,\n",
              "  0.4705555555555556,\n",
              "  0.39375,\n",
              "  0.3785714285714286,\n",
              "  0.46611111111111114,\n",
              "  0.500625,\n",
              "  0.30000000000000004,\n",
              "  0.5138888888888888,\n",
              "  0.32166666666666666,\n",
              "  0.414375,\n",
              "  0.4516666666666667,\n",
              "  0.5311111111111111,\n",
              "  0.43833333333333335,\n",
              "  0.683125,\n",
              "  0.41,\n",
              "  0.39437500000000003,\n",
              "  0.6207142857142857,\n",
              "  0.6611111111111111,\n",
              "  0.32875,\n",
              "  0.4871428571428571,\n",
              "  0.34062499999999996,\n",
              "  0.4333333333333333,\n",
              "  0.6383333333333333,\n",
              "  0.56125,\n",
              "  0.49374999999999997,\n",
              "  0.2922222222222222,\n",
              "  0.536111111111111,\n",
              "  0.5637500000000001,\n",
              "  0.6175,\n",
              "  0.4033333333333334,\n",
              "  0.7671428571428571,\n",
              "  0.625,\n",
              "  0.400625,\n",
              "  0.31055555555555553,\n",
              "  0.31166666666666665,\n",
              "  0.14500000000000002,\n",
              "  0.5299999999999999,\n",
              "  0.2327777777777778,\n",
              "  0.42333333333333334,\n",
              "  0.5137499999999999,\n",
              "  0.29333333333333333,\n",
              "  0.3458333333333334,\n",
              "  0.5085714285714287,\n",
              "  0.3335714285714286,\n",
              "  0.4058333333333333,\n",
              "  0.3566666666666667,\n",
              "  0.43062500000000004,\n",
              "  0.41000000000000003,\n",
              "  0.4016666666666666,\n",
              "  0.35444444444444445,\n",
              "  0.4061111111111111,\n",
              "  0.4538888888888889,\n",
              "  0.566111111111111,\n",
              "  0.6083333333333333,\n",
              "  0.5285714285714286,\n",
              "  0.346,\n",
              "  0.6231249999999999,\n",
              "  0.5188888888888888,\n",
              "  0.38166666666666665,\n",
              "  0.651875,\n",
              "  0.5425,\n",
              "  0.3464285714285714,\n",
              "  0.5108333333333334,\n",
              "  0.3705555555555555,\n",
              "  0.3757142857142858,\n",
              "  0.4244444444444444,\n",
              "  0.56,\n",
              "  0.3333333333333333,\n",
              "  0.5122222222222222,\n",
              "  0.713125,\n",
              "  0.5733333333333333,\n",
              "  0.4558333333333333,\n",
              "  0.4338888888888889,\n",
              "  0.6755555555555556,\n",
              "  0.5237499999999999,\n",
              "  0.5761111111111111,\n",
              "  0.6283333333333333,\n",
              "  0.48666666666666664,\n",
              "  0.37062500000000004,\n",
              "  0.46499999999999997,\n",
              "  0.4905555555555556,\n",
              "  0.595,\n",
              "  0.4855555555555557,\n",
              "  0.45611111111111113,\n",
              "  0.395625,\n",
              "  0.41388888888888886,\n",
              "  0.6077777777777778,\n",
              "  0.4021428571428571,\n",
              "  0.49214285714285716,\n",
              "  0.31777777777777777,\n",
              "  0.5988888888888889,\n",
              "  0.3833333333333333,\n",
              "  0.5022222222222221,\n",
              "  0.43500000000000005,\n",
              "  0.40125,\n",
              "  0.4305555555555556,\n",
              "  0.396,\n",
              "  0.3738888888888889,\n",
              "  0.4583333333333333,\n",
              "  0.46562499999999996,\n",
              "  0.40800000000000003,\n",
              "  0.4861111111111111,\n",
              "  0.6116666666666667,\n",
              "  0.5005555555555556,\n",
              "  0.43,\n",
              "  0.46222222222222226,\n",
              "  0.6594444444444445,\n",
              "  0.2577777777777778,\n",
              "  0.48625,\n",
              "  0.4049999999999999,\n",
              "  0.6661111111111111,\n",
              "  0.564375,\n",
              "  0.43357142857142855,\n",
              "  0.5706249999999999,\n",
              "  0.6611111111111111,\n",
              "  0.48687500000000006,\n",
              "  0.596111111111111,\n",
              "  0.5772222222222223,\n",
              "  0.5166666666666667,\n",
              "  0.5935714285714286,\n",
              "  0.511,\n",
              "  0.42166666666666663,\n",
              "  0.4122222222222222,\n",
              "  0.426875,\n",
              "  0.3905555555555556,\n",
              "  0.5575,\n",
              "  0.48625,\n",
              "  0.44833333333333336,\n",
              "  0.45875,\n",
              "  0.501,\n",
              "  0.58,\n",
              "  0.5085714285714286,\n",
              "  0.7116666666666667,\n",
              "  0.5992857142857143,\n",
              "  0.45722222222222225,\n",
              "  0.4511111111111111,\n",
              "  0.48666666666666664,\n",
              "  0.46611111111111114,\n",
              "  0.4822222222222222,\n",
              "  0.6900000000000001,\n",
              "  0.4666666666666666,\n",
              "  0.47,\n",
              "  0.5277777777777778,\n",
              "  0.555,\n",
              "  0.3985714285714285,\n",
              "  0.4166666666666667,\n",
              "  0.4605555555555556,\n",
              "  0.41944444444444445,\n",
              "  0.5364285714285714,\n",
              "  0.34500000000000003,\n",
              "  0.495,\n",
              "  0.45999999999999996,\n",
              "  0.520625,\n",
              "  0.40388888888888885,\n",
              "  0.41444444444444445,\n",
              "  0.35285714285714287,\n",
              "  0.5433333333333333,\n",
              "  0.340625,\n",
              "  0.37833333333333335,\n",
              "  0.5055555555555555,\n",
              "  0.5464285714285714,\n",
              "  0.5643750000000001,\n",
              "  0.45166666666666666,\n",
              "  0.22916666666666666,\n",
              "  0.479375,\n",
              "  0.36333333333333334,\n",
              "  0.43714285714285717,\n",
              "  0.520625,\n",
              "  0.5811111111111111,\n",
              "  0.575,\n",
              "  0.571875,\n",
              "  0.3555555555555555,\n",
              "  0.35375,\n",
              "  0.34062499999999996,\n",
              "  0.4672222222222222,\n",
              "  0.6543749999999999,\n",
              "  0.5283333333333333,\n",
              "  0.69625,\n",
              "  0.39777777777777773,\n",
              "  0.511875,\n",
              "  0.6675,\n",
              "  0.43555555555555553,\n",
              "  0.3861111111111111,\n",
              "  0.5727777777777778,\n",
              "  0.36999999999999994,\n",
              "  0.40055555555555555,\n",
              "  0.5393749999999999,\n",
              "  0.535,\n",
              "  0.48499999999999993,\n",
              "  0.5433333333333334,\n",
              "  0.45166666666666666,\n",
              "  0.45722222222222225,\n",
              "  0.5244444444444445,\n",
              "  0.40388888888888885,\n",
              "  0.4514285714285714,\n",
              "  0.339375,\n",
              "  0.58375,\n",
              "  0.4066666666666667,\n",
              "  0.49666666666666665,\n",
              "  0.4627777777777778,\n",
              "  0.5966666666666667,\n",
              "  0.59125,\n",
              "  0.42625,\n",
              "  0.5025,\n",
              "  0.704375,\n",
              "  0.543888888888889,\n",
              "  0.17,\n",
              "  0.6361111111111111,\n",
              "  0.254,\n",
              "  0.19833333333333336,\n",
              "  0.4625,\n",
              "  0.5225,\n",
              "  0.31777777777777777,\n",
              "  0.49625,\n",
              "  0.3757142857142857,\n",
              "  0.45999999999999996,\n",
              "  0.5127777777777777,\n",
              "  0.30874999999999997,\n",
              "  0.44555555555555565,\n",
              "  0.47555555555555556,\n",
              "  0.483125,\n",
              "  0.4775,\n",
              "  0.4258333333333333,\n",
              "  0.315,\n",
              "  0.5883333333333334,\n",
              "  0.48375,\n",
              "  0.43388888888888894,\n",
              "  0.4321428571428571,\n",
              "  0.5800000000000001,\n",
              "  0.595,\n",
              "  0.5311111111111111,\n",
              "  0.3283333333333333,\n",
              "  0.3707142857142857,\n",
              "  0.35833333333333334,\n",
              "  0.4000000000000001,\n",
              "  0.45499999999999996,\n",
              "  0.43722222222222223,\n",
              "  0.5427777777777778,\n",
              "  0.32562499999999994,\n",
              "  0.41857142857142854,\n",
              "  0.42888888888888893,\n",
              "  0.544375,\n",
              "  0.4366666666666667,\n",
              "  0.45055555555555554,\n",
              "  0.5875,\n",
              "  0.43375,\n",
              "  0.51125,\n",
              "  0.6133333333333334,\n",
              "  0.4444444444444444,\n",
              "  0.43,\n",
              "  0.5025000000000001,\n",
              "  0.5416666666666666,\n",
              "  0.48055555555555557,\n",
              "  0.42000000000000004,\n",
              "  0.4438888888888889,\n",
              "  0.44125000000000003,\n",
              "  0.48500000000000004,\n",
              "  0.668888888888889,\n",
              "  0.4577777777777778,\n",
              "  0.30799999999999994,\n",
              "  0.44055555555555553,\n",
              "  0.5227777777777778,\n",
              "  0.33714285714285713,\n",
              "  0.625,\n",
              "  0.3377777777777778,\n",
              "  0.2811111111111111,\n",
              "  0.4577777777777778,\n",
              "  0.6422222222222222,\n",
              "  0.26071428571428573,\n",
              "  0.6593749999999999,\n",
              "  0.5421428571428571,\n",
              "  0.583125,\n",
              "  0.4949999999999999,\n",
              "  0.3383333333333333,\n",
              "  0.551875,\n",
              "  0.3961111111111111,\n",
              "  0.5064285714285713,\n",
              "  0.33666666666666667,\n",
              "  0.47888888888888886,\n",
              "  0.5594444444444444,\n",
              "  0.42722222222222217,\n",
              "  0.5461111111111111,\n",
              "  0.29416666666666663,\n",
              "  0.4327777777777777,\n",
              "  0.3672222222222223,\n",
              "  0.3966666666666666,\n",
              "  0.4135714285714286,\n",
              "  0.4114285714285714,\n",
              "  0.40199999999999997,\n",
              "  0.484,\n",
              "  0.63,\n",
              "  0.5188888888888888,\n",
              "  0.5383333333333333,\n",
              "  0.5821428571428572,\n",
              "  0.604375,\n",
              "  0.485625,\n",
              "  0.5108333333333334,\n",
              "  0.5022222222222221,\n",
              "  0.37916666666666665,\n",
              "  0.48500000000000004,\n",
              "  0.6016666666666667,\n",
              "  0.4375,\n",
              "  0.5,\n",
              "  0.26249999999999996,\n",
              "  0.3266666666666667,\n",
              "  0.495,\n",
              "  0.4794444444444444,\n",
              "  0.6411111111111112,\n",
              "  0.6211111111111112,\n",
              "  0.28555555555555556,\n",
              "  0.5538888888888889,\n",
              "  0.6844444444444444,\n",
              "  0.6331249999999999,\n",
              "  0.5811111111111111,\n",
              "  0.5571428571428572,\n",
              "  0.5044444444444445,\n",
              "  0.40125,\n",
              "  0.5205555555555555,\n",
              "  0.5543750000000001,\n",
              "  0.4205555555555555,\n",
              "  0.315,\n",
              "  0.5266666666666666,\n",
              "  0.45214285714285707,\n",
              "  0.5205555555555555,\n",
              "  0.489375,\n",
              "  0.52,\n",
              "  0.3575,\n",
              "  0.5127777777777777,\n",
              "  0.413,\n",
              "  0.37,\n",
              "  0.635,\n",
              "  0.5638888888888889,\n",
              "  0.4011111111111111,\n",
              "  0.39166666666666666,\n",
              "  0.48055555555555557,\n",
              "  0.610625,\n",
              "  0.5827777777777778,\n",
              "  0.4044444444444444,\n",
              "  0.3707142857142857,\n",
              "  0.5607142857142857,\n",
              "  0.548125,\n",
              "  0.38687499999999997,\n",
              "  0.37375,\n",
              "  0.4855555555555556,\n",
              "  0.49944444444444436,\n",
              "  0.558125,\n",
              "  0.42875,\n",
              "  0.34111111111111114,\n",
              "  0.5672222222222222,\n",
              "  0.5005555555555555,\n",
              "  0.42500000000000004,\n",
              "  0.21722222222222223,\n",
              "  0.364375,\n",
              "  0.5066666666666667,\n",
              "  0.47714285714285715,\n",
              "  0.405,\n",
              "  0.4316666666666667,\n",
              "  0.565,\n",
              "  0.48600000000000004,\n",
              "  0.5549999999999999,\n",
              "  0.6383333333333333,\n",
              "  0.505,\n",
              "  0.405,\n",
              "  0.43888888888888883,\n",
              "  0.46111111111111114,\n",
              "  0.278,\n",
              "  0.3216666666666667,\n",
              "  0.48750000000000004,\n",
              "  0.48250000000000004,\n",
              "  0.41555555555555557,\n",
              "  0.5387500000000001,\n",
              "  0.464375,\n",
              "  0.32,\n",
              "  0.4905555555555556,\n",
              "  0.6122222222222222,\n",
              "  0.30874999999999997,\n",
              "  0.3475,\n",
              "  0.47277777777777774,\n",
              "  0.4008333333333334,\n",
              "  0.5722222222222223,\n",
              "  0.32,\n",
              "  0.3114285714285714,\n",
              "  0.4488888888888889,\n",
              "  0.52,\n",
              "  0.449375,\n",
              "  0.5228571428571429,\n",
              "  0.35111111111111115,\n",
              "  0.33,\n",
              "  0.6000000000000001,\n",
              "  0.44333333333333336,\n",
              "  0.5388888888888889,\n",
              "  0.4272222222222222,\n",
              "  0.556875,\n",
              "  0.37555555555555553,\n",
              "  0.5972222222222222,\n",
              "  0.6791666666666667,\n",
              "  0.28055555555555556,\n",
              "  0.586875,\n",
              "  0.5888888888888889,\n",
              "  0.4961111111111111,\n",
              "  0.4927777777777778,\n",
              "  0.36812500000000004,\n",
              "  0.20428571428571426,\n",
              "  0.37277777777777776,\n",
              "  0.49250000000000005,\n",
              "  0.43277777777777776,\n",
              "  0.419375,\n",
              "  0.4511111111111112,\n",
              "  0.5155555555555555,\n",
              "  0.4427777777777778,\n",
              "  0.2488888888888889,\n",
              "  0.34714285714285714,\n",
              "  0.275,\n",
              "  0.5183333333333333,\n",
              "  0.533125,\n",
              "  0.40444444444444444,\n",
              "  0.5633333333333334,\n",
              "  0.5311111111111111,\n",
              "  0.4172222222222222,\n",
              "  0.51,\n",
              "  0.4,\n",
              "  0.41000000000000003,\n",
              "  0.29055555555555557,\n",
              "  0.32944444444444443,\n",
              "  0.49624999999999997,\n",
              "  0.42999999999999994,\n",
              "  0.60875,\n",
              "  0.35875,\n",
              "  0.39722222222222225,\n",
              "  0.5925,\n",
              "  0.34142857142857136,\n",
              "  0.4908333333333334,\n",
              "  0.4466666666666666,\n",
              "  0.53875,\n",
              "  0.3361111111111111,\n",
              "  0.52,\n",
              "  0.30437499999999995,\n",
              "  0.29750000000000004,\n",
              "  0.48277777777777775,\n",
              "  0.476875,\n",
              "  0.3494444444444444,\n",
              "  0.5316666666666667,\n",
              "  0.5638888888888889,\n",
              "  0.4325,\n",
              "  0.5735714285714285,\n",
              "  0.43071428571428566,\n",
              "  0.46111111111111114,\n",
              "  0.33125000000000004,\n",
              "  0.145625,\n",
              "  0.47562499999999996,\n",
              "  0.38375000000000004,\n",
              "  0.5164285714285713,\n",
              "  0.7011111111111111,\n",
              "  0.46214285714285713,\n",
              "  0.3942857142857143,\n",
              "  0.43999999999999995,\n",
              "  0.6483333333333333,\n",
              "  0.42357142857142854,\n",
              "  0.5811111111111111,\n",
              "  0.39428571428571424,\n",
              "  0.6014285714285714,\n",
              "  0.6361111111111112,\n",
              "  0.362,\n",
              "  0.6233333333333333,\n",
              "  0.46888888888888886,\n",
              "  0.49666666666666665,\n",
              "  0.6755555555555556,\n",
              "  0.3727777777777777,\n",
              "  0.5827777777777777,\n",
              "  0.55125,\n",
              "  0.38499999999999995,\n",
              "  0.448125,\n",
              "  0.5044444444444445,\n",
              "  0.4516666666666667,\n",
              "  0.305,\n",
              "  0.6449999999999999,\n",
              "  0.6108333333333333,\n",
              "  0.5114285714285715,\n",
              "  0.4694444444444444,\n",
              "  0.5099999999999999,\n",
              "  0.5055555555555556,\n",
              "  0.33722222222222226,\n",
              "  0.358125,\n",
              "  0.5016666666666667,\n",
              "  0.5977777777777776,\n",
              "  0.6033333333333333,\n",
              "  0.46857142857142847,\n",
              "  0.6427777777777778,\n",
              "  0.4228571428571429,\n",
              "  0.58,\n",
              "  0.3766666666666667,\n",
              "  0.46166666666666667,\n",
              "  0.360625,\n",
              "  0.5235714285714287,\n",
              "  0.4521428571428571,\n",
              "  0.49277777777777776,\n",
              "  0.3071428571428572,\n",
              "  0.46875,\n",
              "  0.5255555555555556,\n",
              "  0.319375,\n",
              "  0.5422222222222222,\n",
              "  0.36666666666666664,\n",
              "  0.44222222222222224,\n",
              "  0.24875,\n",
              "  0.36687499999999995,\n",
              "  0.445,\n",
              "  0.49944444444444447,\n",
              "  0.379375,\n",
              "  0.49944444444444447,\n",
              "  0.5933333333333333,\n",
              "  0.5694444444444445,\n",
              "  0.30562500000000004,\n",
              "  0.5183333333333333,\n",
              "  0.5337500000000001,\n",
              "  0.46888888888888897,\n",
              "  0.59625,\n",
              "  0.6877777777777777,\n",
              "  0.40875,\n",
              "  0.47,\n",
              "  0.48777777777777787,\n",
              "  0.406,\n",
              "  0.6288888888888889,\n",
              "  0.36888888888888893,\n",
              "  0.42375,\n",
              "  0.47875,\n",
              "  0.465,\n",
              "  0.43900000000000006,\n",
              "  0.44611111111111107,\n",
              "  0.5988888888888889,\n",
              "  0.3925,\n",
              "  0.49250000000000005,\n",
              "  0.4735714285714286,\n",
              "  0.5777777777777778,\n",
              "  0.4471428571428572,\n",
              "  0.66375,\n",
              "  0.5291666666666667,\n",
              "  0.7072222222222222,\n",
              "  0.6000000000000001,\n",
              "  0.43222222222222223,\n",
              "  0.5072222222222222,\n",
              "  0.6221428571428571,\n",
              "  0.43944444444444447,\n",
              "  0.42,\n",
              "  0.6507142857142857,\n",
              "  0.2783333333333334,\n",
              "  0.3007142857142857,\n",
              "  0.5018750000000001,\n",
              "  0.4377777777777777,\n",
              "  0.43875,\n",
              "  0.42444444444444446,\n",
              "  0.6328571428571429,\n",
              "  0.660625,\n",
              "  0.34428571428571425,\n",
              "  0.4338888888888888,\n",
              "  0.30000000000000004,\n",
              "  0.5940000000000001,\n",
              "  0.6222222222222222,\n",
              "  0.5475,\n",
              "  0.526875,\n",
              "  0.48562500000000003,\n",
              "  0.44062500000000004,\n",
              "  0.43833333333333335,\n",
              "  0.5261111111111112,\n",
              "  0.6327777777777778,\n",
              "  0.31,\n",
              "  0.2925,\n",
              "  0.5,\n",
              "  0.4211111111111111,\n",
              "  0.5075000000000001,\n",
              "  0.5792857142857143,\n",
              "  0.47714285714285715,\n",
              "  0.6675,\n",
              "  0.3777777777777778,\n",
              "  0.35055555555555556,\n",
              "  0.5175,\n",
              "  0.5100000000000001,\n",
              "  0.4855555555555556,\n",
              "  0.5894444444444444,\n",
              "  0.39312499999999995,\n",
              "  0.5738888888888888,\n",
              "  0.5116666666666667,\n",
              "  0.440625,\n",
              "  0.5311111111111111,\n",
              "  0.5375,\n",
              "  0.36125,\n",
              "  0.4783333333333334,\n",
              "  0.45062500000000005,\n",
              "  0.2575,\n",
              "  0.2292857142857143,\n",
              "  0.38187499999999996,\n",
              "  0.6483333333333333,\n",
              "  0.6627777777777778,\n",
              "  0.54125,\n",
              "  0.6392857142857143,\n",
              "  0.5278571428571429,\n",
              "  0.498125,\n",
              "  0.2792857142857143,\n",
              "  0.38333333333333336,\n",
              "  0.460625,\n",
              "  0.47555555555555556,\n",
              "  0.5039999999999999,\n",
              "  0.4778571428571428,\n",
              "  0.4927777777777778,\n",
              "  0.4025,\n",
              "  0.4675,\n",
              "  0.6177777777777778,\n",
              "  0.40055555555555555,\n",
              "  0.6077777777777778,\n",
              "  0.40611111111111114,\n",
              "  0.45687500000000003,\n",
              "  0.49166666666666664,\n",
              "  0.365,\n",
              "  0.43833333333333335,\n",
              "  0.6355555555555554,\n",
              "  0.37722222222222224,\n",
              "  0.3877777777777778,\n",
              "  0.6375,\n",
              "  0.38833333333333336,\n",
              "  0.38055555555555554,\n",
              "  0.42277777777777775,\n",
              "  0.3977777777777778,\n",
              "  0.35888888888888887,\n",
              "  0.5461111111111111,\n",
              "  0.6066666666666666,\n",
              "  0.21071428571428572,\n",
              "  0.48888888888888893,\n",
              "  0.5111111111111112,\n",
              "  0.45055555555555554,\n",
              "  0.36357142857142855,\n",
              "  0.531875,\n",
              "  0.194375,\n",
              "  0.606875,\n",
              "  0.40785714285714286,\n",
              "  0.3611111111111111,\n",
              "  0.4625,\n",
              "  0.4516666666666667,\n",
              "  0.6561111111111111,\n",
              "  0.5111111111111111,\n",
              "  0.34375,\n",
              "  0.3877777777777777,\n",
              "  0.29333333333333333,\n",
              "  0.5811111111111111,\n",
              "  0.435,\n",
              "  0.42166666666666663,\n",
              "  0.5357142857142858,\n",
              "  0.5788888888888889,\n",
              "  0.5505555555555556,\n",
              "  0.40055555555555555,\n",
              "  0.56375,\n",
              "  0.51125,\n",
              "  0.43937500000000007,\n",
              "  0.5922222222222223,\n",
              "  0.43722222222222223,\n",
              "  0.47611111111111115,\n",
              "  0.4344444444444444,\n",
              "  0.5406249999999999,\n",
              "  0.3908333333333333,\n",
              "  0.5844444444444445,\n",
              "  0.19214285714285714,\n",
              "  0.6294444444444444,\n",
              "  0.505,\n",
              "  0.3772222222222223,\n",
              "  0.20785714285714288,\n",
              "  0.325,\n",
              "  0.4975,\n",
              "  0.7377777777777779,\n",
              "  0.5227777777777778,\n",
              "  0.4911111111111111,\n",
              "  0.5022222222222222,\n",
              "  0.36166666666666664,\n",
              "  0.4183333333333333,\n",
              "  0.5133333333333332,\n",
              "  0.5594444444444444,\n",
              "  0.46125000000000005,\n",
              "  0.5744444444444444,\n",
              "  0.4407142857142857,\n",
              "  0.43166666666666664,\n",
              "  0.44375000000000003,\n",
              "  0.5633333333333334,\n",
              "  0.24,\n",
              "  0.505625,\n",
              "  0.33062500000000006,\n",
              "  0.5544444444444444,\n",
              "  0.44699999999999995,\n",
              "  0.44571428571428573,\n",
              "  0.441875,\n",
              "  0.40111111111111103,\n",
              "  0.5275,\n",
              "  0.5743750000000001,\n",
              "  0.32833333333333337,\n",
              "  0.4816666666666667,\n",
              "  0.4135714285714286,\n",
              "  0.44999999999999996,\n",
              "  0.301875,\n",
              "  0.46642857142857147,\n",
              "  0.5700000000000001,\n",
              "  0.525,\n",
              "  0.33944444444444444,\n",
              "  0.38833333333333336,\n",
              "  0.38571428571428573,\n",
              "  0.5006250000000001,\n",
              "  0.475,\n",
              "  0.3922222222222222,\n",
              "  0.5778571428571428,\n",
              "  0.5661111111111111,\n",
              "  0.52,\n",
              "  0.5249999999999999,\n",
              "  0.524,\n",
              "  0.325,\n",
              "  0.4033333333333333,\n",
              "  0.42999999999999994,\n",
              "  0.5675,\n",
              "  0.5085714285714287,\n",
              "  0.4083333333333333,\n",
              "  0.6214285714285713,\n",
              "  0.3722222222222223,\n",
              "  0.4378571428571429,\n",
              "  0.484375,\n",
              "  0.6261111111111111,\n",
              "  ...]}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_trainer._eval_manager = ImplicitEvalManager(evaluators=[auc_evaluator])\n",
        "model_trainer._num_negatives = 200\n",
        "model_trainer._exclude_positives([train_dataset, test_dataset_pos, test_dataset_neg])\n",
        "model_trainer._sample_negatives(seed=10)\n",
        "\n",
        "model_trainer._eval_save_prefix = folder_name+\"cml-yahoo-test-pos-unbiased\"\n",
        "model_trainer._evaluate_partial(test_dataset_pos)\n",
        "\n",
        "model_trainer._eval_save_prefix = folder_name+\"cml-yahoo-test-neg-unbiased\"\n",
        "model_trainer._evaluate_partial(test_dataset_neg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITJy3aCoc55W"
      },
      "source": [
        "# **DEFINE FUNCTION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PclrZeRwNWAm"
      },
      "outputs": [],
      "source": [
        "def eq(infilename, infilename_neg, trainfilename, gamma=1.0, K=1):\n",
        "\n",
        "    # Load pickles\n",
        "    infile = open(infilename, 'rb')\n",
        "    infile_neg = open(infilename_neg, 'rb')\n",
        "    P = pickle.load(infile)\n",
        "    infile.close()\n",
        "    P_neg = pickle.load(infile_neg)\n",
        "    infile_neg.close()\n",
        "    NUM_NEGATIVES = P[\"num_negatives\"]\n",
        "    \n",
        "    # Merge the two dictionaries\n",
        "    for theuser in P[\"users\"]:\n",
        "        neg_items = list(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:])\n",
        "        neg_scores = list(P_neg[\"results\"][theuser][NUM_NEGATIVES:])\n",
        "        P[\"user_items\"][theuser] = list(neg_items) + list(P[\"user_items\"][theuser][NUM_NEGATIVES:])\n",
        "        P[\"results\"][theuser] = list(neg_scores) + list(P[\"results\"][theuser][NUM_NEGATIVES:])\n",
        "    \n",
        "    Zui = dict()\n",
        "    Ni = dict()\n",
        "\n",
        "    # Count item frequencies in the training set\n",
        "    trainset = np.load(trainfilename)\n",
        "    for i in trainset['item_id']:\n",
        "        if i in Ni:\n",
        "            Ni[i] += 1\n",
        "        else:\n",
        "            Ni[i] = 1\n",
        "    del trainset\n",
        "\n",
        "    # Count the number of users with at least one positive item in the test set \n",
        "    # (not the smartest way)\n",
        "    nonzero_user_count = 0\n",
        "    for theuser in P[\"users\"]:\n",
        "        pos_items = P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]\n",
        "        for pos_item in pos_items:\n",
        "            if pos_item in Ni:\n",
        "                nonzero_user_count += 1\n",
        "                break\n",
        "\n",
        "    # Compute the recommendations for each user\n",
        "    for theuser in P[\"users\"]:\n",
        "        all_scores = np.array(P[\"results\"][theuser])\n",
        "        pos_items = P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]\n",
        "        pos_scores = P[\"results\"][theuser][len(P_neg[\"results\"][theuser][NUM_NEGATIVES:]):]\n",
        "        for i, pos_item in enumerate(pos_items):\n",
        "            pos_score = pos_scores[i]\n",
        "            Zui[(theuser, pos_item)] = float(np.sum(all_scores > pos_score))\n",
        "\n",
        "    sum_user_auc = 0.0\n",
        "    sum_user_recall = 0.0\n",
        "\n",
        "    # Compute the scores using AUC and compute the recall\n",
        "    for theuser in P[\"users\"]:\n",
        "        numerator_auc = 0.0\n",
        "        numerator_recall = 0.0\n",
        "        denominator = 0.0\n",
        "        for theitem in P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]:\n",
        "            if theitem not in Ni:\n",
        "                continue\n",
        "            pui = np.power(Ni[theitem], (gamma + 1) / 2.0)\n",
        "            numerator_auc += (1 - Zui[(theuser, theitem)] / len(P[\"user_items\"][theuser])) / pui\n",
        "            if Zui[(theuser, theitem)] < K:\n",
        "                numerator_recall += 1.0 / pui\n",
        "            denominator += 1 / pui\n",
        "        if denominator > 0:\n",
        "            sum_user_auc += numerator_auc / denominator\n",
        "            sum_user_recall += numerator_recall / denominator\n",
        "\n",
        "    return {\n",
        "        \"auc\"       : sum_user_auc / nonzero_user_count,\n",
        "        \"recall\"    : sum_user_recall / nonzero_user_count\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def aoa(infilename, infilename_neg, trainfilename, K=1):\n",
        "\n",
        "    # Load pickles\n",
        "    infile = open(infilename, 'rb')\n",
        "    infile_neg = open(infilename_neg, 'rb')\n",
        "    P = pickle.load(infile)\n",
        "    infile.close()\n",
        "    P_neg = pickle.load(infile_neg)\n",
        "    infile_neg.close()\n",
        "    NUM_NEGATIVES = P[\"num_negatives\"]\n",
        "    \n",
        "    # Merge the two dictionaries\n",
        "    for theuser in P[\"users\"]:\n",
        "        neg_items = list(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:])\n",
        "        neg_scores = list(P_neg[\"results\"][theuser][NUM_NEGATIVES:])\n",
        "        P[\"user_items\"][theuser] = list(neg_items) + list(P[\"user_items\"][theuser][NUM_NEGATIVES:])\n",
        "        P[\"results\"][theuser] = list(neg_scores) + list(P[\"results\"][theuser][NUM_NEGATIVES:])\n",
        "        \n",
        "    Zui = dict()\n",
        "    Ni = dict()\n",
        "    \n",
        "    # Count item frequencies in the training set\n",
        "    trainset = np.load(trainfilename)\n",
        "    for i in trainset['item_id']:\n",
        "        if i in Ni:\n",
        "            Ni[i] += 1\n",
        "        else:\n",
        "            Ni[i] = 1\n",
        "    del trainset\n",
        "    \n",
        "    # Count the number of users with at least one positive item in the test set \n",
        "    # (not the smartest way)\n",
        "    nonzero_user_count = 0\n",
        "    for theuser in P[\"users\"]:\n",
        "        pos_items = P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]\n",
        "        for pos_item in pos_items:\n",
        "            if pos_item in Ni:\n",
        "                nonzero_user_count += 1\n",
        "                break\n",
        "\n",
        "    # Compute the recommendations for each user\n",
        "    for theuser in P[\"users\"]:\n",
        "        all_scores = np.array(P[\"results\"][theuser])\n",
        "        pos_items = P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]\n",
        "        pos_scores = P[\"results\"][theuser][len(P_neg[\"results\"][theuser][NUM_NEGATIVES:]):]\n",
        "        for i, pos_item in enumerate(pos_items):\n",
        "            pos_score = pos_scores[i]\n",
        "            Zui[(theuser, pos_item)] = float(np.sum(all_scores > pos_score))\n",
        "            \n",
        "    sum_user_auc = 0.0\n",
        "    sum_user_recall = 0.0\n",
        "\n",
        "    # Compute the scores using AUC and compute the recall\n",
        "    for theuser in P[\"users\"]:\n",
        "        numerator_auc = 0.0\n",
        "        numerator_recall = 0.0\n",
        "        denominator = 0.0\n",
        "        for theitem in P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]:\n",
        "            if theitem not in Ni:\n",
        "                continue\n",
        "            numerator_auc += (1 - Zui[(theuser, theitem)] / len(P[\"user_items\"][theuser]))\n",
        "            if Zui[(theuser, theitem)] < K:\n",
        "                numerator_recall += 1.0\n",
        "            denominator += 1 \n",
        "        if denominator > 0:\n",
        "            sum_user_auc += numerator_auc / denominator\n",
        "            sum_user_recall += numerator_recall / denominator\n",
        "\n",
        "    return {\n",
        "        \"auc\"       : sum_user_auc / nonzero_user_count,\n",
        "        \"recall\"    : sum_user_recall / nonzero_user_count\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **TEST**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'auc': 0.8439872027026072, 'recall': 0.05204219465712629}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eq(folder_name+\"cml-yahoo-test-pos-biased_evaluate_partial.pickle\", folder_name+\"cml-yahoo-test-neg-biased_evaluate_partial.pickle\", folder_name+\"training_arr.npy\", gamma=1.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'auc': 0.8398511463738416, 'recall': 0.049855378908885875}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eq(folder_name+\"cml-yahoo-test-pos-biased_evaluate_partial.pickle\", folder_name+\"cml-yahoo-test-neg-biased_evaluate_partial.pickle\", folder_name+\"training_arr.npy\", gamma=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'auc': 0.8345355174867299, 'recall': 0.047191065066928835}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eq(folder_name+\"cml-yahoo-test-pos-biased_evaluate_partial.pickle\", folder_name+\"cml-yahoo-test-neg-biased_evaluate_partial.pickle\", folder_name+\"training_arr.npy\", gamma=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'auc': 0.7382109673137573, 'recall': 0.3108651692384276}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aoa(folder_name+\"cml-yahoo-test-pos-unbiased_evaluate_partial.pickle\", folder_name+\"cml-yahoo-test-neg-unbiased_evaluate_partial.pickle\", folder_name+\"training_arr.npy\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "RecSysEvaluation",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
