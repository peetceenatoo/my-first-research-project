{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>SongID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  SongID  Rating\n",
       "0       1      14       5\n",
       "1       1      35       1\n",
       "2       1      46       1\n",
       "3       1      83       1\n",
       "4       1      93       1\n",
       "5       1      94       1\n",
       "6       1     153       5\n",
       "7       1     170       4\n",
       "8       1     184       5\n",
       "9       1     194       5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace 'your_file.txt' with your file path\n",
    "file_path = 'Dataset/yahoo_ymusic_v1/ydata-ymusic-rating-study-v1_0-train.txt'\n",
    "\n",
    "# Load the file into a DataFrame\n",
    "df = pd.read_csv(file_path, sep='\\t',names=[\"UserID\",\"SongID\",\"Rating\"], header=None)  # sep='\\t' for tab-separated values\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_THRESHOLD = 4\n",
    "\n",
    "df['ImplicitRating'] = np.where(df['Rating'] >= POSITIVE_THRESHOLD, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>SongID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>ImplicitRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  SongID  Rating  ImplicitRating\n",
       "0       1      14       5               1\n",
       "1       1      35       1               0\n",
       "2       1      46       1               0\n",
       "3       1      83       1               0\n",
       "4       1      93       1               0\n",
       "5       1      94       1               0\n",
       "6       1     153       5               1\n",
       "7       1     170       4               1\n",
       "8       1     184       5               1\n",
       "9       1     194       5               1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Making IDs 0-based**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserID Count: 15400\n",
      "UserID Min: 1\n",
      "UserID Max: 15400\n"
     ]
    }
   ],
   "source": [
    "print(f\"UserID Count: {np.unique(df['UserID']).shape[0]}\")\n",
    "print(f\"UserID Min: {df['UserID'].min()}\")\n",
    "print(f\"UserID Max: {df['UserID'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserID Count: 15400\n",
      "UserID Min: 0\n",
      "UserID Max: 15399\n"
     ]
    }
   ],
   "source": [
    "df['UserID'] = df['UserID'] - 1\n",
    "print(f\"UserID Count: {np.unique(df['UserID']).shape[0]}\")\n",
    "print(f\"UserID Min: {df['UserID'].min()}\")\n",
    "print(f\"UserID Max: {df['UserID'].max()}\")\n",
    "max_user = df['UserID'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SongID Count: 1000\n",
      "SongID Min: 1\n",
      "SongID Max: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f\"SongID Count: {np.unique(df['SongID']).shape[0]}\")\n",
    "print(f\"SongID Min: {df['SongID'].min()}\")\n",
    "print(f\"SongID Max: {df['SongID'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SongID Count: 1000\n",
      "SongID Min: 0\n",
      "SongID Max: 999\n"
     ]
    }
   ],
   "source": [
    "df['SongID'] = df['SongID'] - 1\n",
    "print(f\"SongID Count: {np.unique(df['SongID']).shape[0]}\")\n",
    "print(f\"SongID Min: {df['SongID'].min()}\")\n",
    "print(f\"SongID Max: {df['SongID'].max()}\")\n",
    "max_item = df['SongID'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((311704,), (311704,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"ImplicitRating\"] = df[\"ImplicitRating\"].values.astype(np.float32)\n",
    "df['UserID'].shape, df['SongID'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Creating a URM coo format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "URM_all = sps.coo_matrix((df[\"ImplicitRating\"].values, \n",
    "                          (df[\"UserID\"].values, df[\"SongID\"].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<15400x1000 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 311704 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Try To Split Global Wise**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating array for OpenRec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive interactions: 125077\n",
      "Training sampled positive interactions: 87554\n",
      "Training indeces length: 87554\n",
      "Training validation+test length: 37523\n",
      "Validation sampled positive interactions: 18762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(87554, 18762, 18761)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_QUOTA = 0.7\n",
    "\n",
    "#Get relevant interactions indexes\n",
    "indicesRelevantInteractions = np.where(df[\"ImplicitRating\"] == 1)[0]\n",
    "\n",
    "print(f\"Total positive interactions: {indicesRelevantInteractions.shape[0]}\")\n",
    "\n",
    "#Shuffle them\n",
    "np.random.shuffle(indicesRelevantInteractions)\n",
    "n_train_interactions = round(indicesRelevantInteractions.shape[0] * TRAINING_QUOTA)\n",
    "\n",
    "print(f\"Training sampled positive interactions: {n_train_interactions}\")\n",
    "\n",
    "#Sample training indexes\n",
    "indices_for_train = indicesRelevantInteractions[0:n_train_interactions]\n",
    "indices_for_test_validation = indicesRelevantInteractions[n_train_interactions:]\n",
    "\n",
    "print(f\"Training indeces length: {indices_for_train.shape[0]}\")\n",
    "print(f\"Training validation+test length: {indices_for_test_validation.shape[0]}\")\n",
    "\n",
    "\n",
    "#Split remaining\n",
    "n_validation_interactions = round(len(indices_for_test_validation) / 2)\n",
    "\n",
    "print(f\"Validation sampled positive interactions: {n_validation_interactions}\")\n",
    "\n",
    "indices_for_validation = indices_for_test_validation[:n_validation_interactions]\n",
    "indices_for_test = indices_for_test_validation[n_validation_interactions:]\n",
    "\n",
    "assert len(indices_for_train) + len(indices_for_validation) + len(indices_for_test) == indicesRelevantInteractions.shape[0]\n",
    "len(indices_for_train), len(indices_for_validation), len(indices_for_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.ones(indices_for_train.shape[0], dtype={'names':('user_id', 'item_id'),\n",
    "                          'formats':('i4', 'i4')})\n",
    "train_data['user_id'] = df[\"UserID\"][indices_for_train]\n",
    "train_data['item_id'] = df[\"SongID\"][indices_for_train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = np.ones(indices_for_validation.shape[0], dtype={'names':('user_id', 'item_id'),\n",
    "                          'formats':('i4', 'i4')})\n",
    "validation_data['user_id'] = df[\"UserID\"][indices_for_validation]\n",
    "validation_data['item_id'] = df[\"SongID\"][indices_for_validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.ones(indices_for_test.shape[0], dtype={'names':('user_id', 'item_id'),\n",
    "                          'formats':('i4', 'i4')})\n",
    "test_data['user_id'] = df[\"UserID\"][indices_for_test]\n",
    "test_data['item_id'] = df[\"UserID\"][indices_for_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Splitting URM **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import DaCrema's function from \n",
    "def split_train_in_two_percentage_global_sample(URM_all, train_percentage = 0.1):\n",
    "    \"\"\"\n",
    "    The function splits an URM in two matrices selecting the number of interactions globally\n",
    "    :param URM_all:\n",
    "    :param train_percentage:\n",
    "    :param verbose:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    assert train_percentage >= 0.0 and train_percentage<=1.0, \"train_percentage must be a value between 0.0 and 1.0, provided was '{}'\".format(train_percentage)\n",
    "\n",
    "\n",
    "    from  MFDLib.IncrementalSparseMatrix import IncrementalSparseMatrix\n",
    "\n",
    "    num_users, num_items = URM_all.shape\n",
    "\n",
    "    URM_train_builder = IncrementalSparseMatrix(n_rows=num_users, n_cols=num_items, auto_create_col_mapper=False, auto_create_row_mapper=False)\n",
    "    URM_validation_builder = IncrementalSparseMatrix(n_rows=num_users, n_cols=num_items, auto_create_col_mapper=False, auto_create_row_mapper=False)\n",
    "\n",
    "\n",
    "    URM_train = sps.coo_matrix(URM_all)\n",
    "\n",
    "    indices_for_sampling = np.arange(0, URM_all.nnz, dtype=int)\n",
    "    np.random.shuffle(indices_for_sampling)\n",
    "\n",
    "    n_train_interactions = round(URM_all.nnz * train_percentage)\n",
    "\n",
    "    indices_for_train = indices_for_sampling[indices_for_sampling[0:n_train_interactions]]\n",
    "    indices_for_validation = indices_for_sampling[indices_for_sampling[n_train_interactions:]]\n",
    "\n",
    "\n",
    "    URM_train_builder.add_data_lists(URM_train.row[indices_for_train],\n",
    "                                     URM_train.col[indices_for_train],\n",
    "                                     URM_train.data[indices_for_train])\n",
    "\n",
    "    URM_validation_builder.add_data_lists(URM_train.row[indices_for_validation],\n",
    "                                          URM_train.col[indices_for_validation],\n",
    "                                          URM_train.data[indices_for_validation])\n",
    "\n",
    "\n",
    "    URM_train = URM_train_builder.get_SparseMatrix()\n",
    "    URM_validation = URM_validation_builder.get_SparseMatrix()\n",
    "\n",
    "    URM_train = sps.csr_matrix(URM_train)\n",
    "    URM_validation = sps.csr_matrix(URM_validation)\n",
    "\n",
    "    user_no_item_train = np.sum(np.ediff1d(URM_train.indptr) == 0)\n",
    "    user_no_item_validation = np.sum(np.ediff1d(URM_validation.indptr) == 0)\n",
    "\n",
    "    if user_no_item_train != 0:\n",
    "        print(\"Warning: {} ({:.2f} %) of {} users have no train items\".format(user_no_item_train, user_no_item_train/num_users*100, num_users))\n",
    "    if user_no_item_validation != 0:\n",
    "        print(\"Warning: {} ({:.2f} %) of {} users have no sampled items\".format(user_no_item_validation, user_no_item_validation/num_users*100, num_users))\n",
    "\n",
    "\n",
    "    return URM_train, URM_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 1520 (9.87 %) of 15400 users have no train items\n",
      "Warning: 3640 (23.64 %) of 15400 users have no sampled items\n",
      "Warning: 6419 (41.68 %) of 15400 users have no train items\n",
      "Warning: 6453 (41.90 %) of 15400 users have no sampled items\n"
     ]
    }
   ],
   "source": [
    "# Use 15% for Test and 15% for Validation\n",
    "\n",
    "urm_train, urm_test_validation = split_train_in_two_percentage_global_sample(URM_all, train_percentage = 0.7)\n",
    "urm_test, urm_validation = split_train_in_two_percentage_global_sample(urm_test_validation, train_percentage = 0.5)\n",
    "urm_train_validation = urm_train + urm_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lets USE openrec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the same libraries of the Section 4\n",
    "#openrec.legacy now moved to openrec.tf1.legacy\n",
    "from openrec.tf1.legacy import ImplicitModelTrainer\n",
    "from openrec.tf1.legacy.utils import ImplicitDataset\n",
    "from openrec.tf1.legacy.recommenders import PMF\n",
    "from openrec.tf1.legacy.utils.evaluators import AUC, Recall, Precision, NDCG\n",
    "from openrec.tf1.legacy.utils.samplers import PointwiseSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = dict()\n",
    "raw_data['train_data'] = train_data\n",
    "raw_data['val_data'] = validation_data\n",
    "raw_data['test_data'] = test_data\n",
    "raw_data['max_user'] = max_user + 1\n",
    "raw_data['max_item'] = max_item + 1\n",
    "batch_size = 8000\n",
    "test_batch_size = 200\n",
    "display_itr = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImplicitDataset(raw_data['train_data'], raw_data['max_user'], raw_data['max_item'], name='Train')\n",
    "val_dataset = ImplicitDataset(raw_data['val_data'], raw_data['max_user'], raw_data['max_item'], name='Val')\n",
    "test_dataset = ImplicitDataset(raw_data['test_data'], raw_data['max_user'], raw_data['max_item'], name='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/japo/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:391: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/japo/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:31: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/japo/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:41: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/japo/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:43: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/japo/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:33: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/japo/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/interactions/pointwise_mse.py:67: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /Users/japo/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/interactions/pointwise_mse.py:79: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/japo/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:596: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/japo/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:144: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/japo/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:365: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/japo/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:148: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-24 23:12:21.696397: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2023-12-24 23:12:21.713383: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fba922c2220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-24 23:12:21.713399: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.reset_default_graph()\n",
    "model = PMF(batch_size=batch_size, max_user=train_dataset.max_user(), max_item=train_dataset.max_item(), \n",
    "            dim_embed=50, opt='Adam', sess_config=None, l2_reg=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = PointwiseSampler(batch_size=batch_size, dataset=train_dataset, pos_ratio=0.2, num_process=5)\n",
    "model_trainer = ImplicitModelTrainer(batch_size=batch_size, test_batch_size=test_batch_size, \n",
    "    train_dataset=train_dataset, model=model, sampler=sampler, \n",
    "    eval_save_prefix=\"./pmf-yahoo\")\n",
    "auc_evaluator = AUC()\n",
    "recall_evaluator = Recall(recall_at=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "dcg_evaluator = NDCG(ndcg_at=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Subsampling negative items]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Start training with sampled evaluation, sample size: 200 ==\n",
      "[Itr 500] Finished\n",
      "[Itr 1000] Finished\n",
      "[Itr 1500] Finished\n",
      "[Itr 2000] Finished\n",
      "[Itr 2500] Finished\n",
      "[Itr 3000] Finished\n",
      "[Itr 3500] Finished\n",
      "[Itr 4000] Finished\n",
      "[Itr 4500] Finished\n",
      "[Itr 5000] Finished\n",
      "INFO:tensorflow:./pmf-yahoo-5000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 5000] loss: 219.112034\n",
      "..(dataset: Val) evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 954/8913 [00:00<00:05, 1474.83it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 999 is out of bounds for axis 0 with size 999",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kj/3wy9xr4j2vlcr59wg5_cqy200000gn/T/ipykernel_22222/4293112061.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model_trainer.train(num_itr=50001, display_itr=display_itr, eval_datasets=[val_dataset],\n\u001b[0;32m----> 2\u001b[0;31m                     evaluators=[auc_evaluator, recall_evaluator, dcg_evaluator], num_negatives=200)\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/implicit_model_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_itr, display_itr, eval_datasets, evaluators, num_negatives, seed)\u001b[0m\n\u001b[1;32m     93\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolored\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'..(dataset: %s) evaluation'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'green'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                     \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                         \u001b[0maverage_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/implicit_model_trainer.py\u001b[0m in \u001b[0;36m_evaluate_partial\u001b[0;34m(self, eval_dataset)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampled_negatives\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_interactions_by_user_gb_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mto_be_saved\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"user_items\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_score_partial_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_negatives\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_negatives\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mto_be_saved\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"results\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/implicit_model_trainer.py\u001b[0m in \u001b[0;36m_score_partial_items\u001b[0;34m(self, user, items)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_item_serving_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             return self._model.serve({'user_id_input': [user],\n\u001b[0;32m--> 126\u001b[0;31m                                     'item_id_input': np.arange(self._max_item)})[0][np.array(items)]\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             return self._model.serve({'user_id_input': [user], \n",
      "\u001b[0;31mIndexError\u001b[0m: index 999 is out of bounds for axis 0 with size 999"
     ]
    }
   ],
   "source": [
    "model_trainer.train(num_itr=50001, display_itr=display_itr, eval_datasets=[val_dataset],\n",
    "                    evaluators=[auc_evaluator, recall_evaluator, dcg_evaluator], num_negatives=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecommenderEvaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
