{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IMPORT LIBS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from openrec.tf1.legacy import ImplicitModelTrainer\n",
    "from openrec.tf1.legacy.utils.evaluators import ImplicitEvalManager\n",
    "from openrec.tf1.legacy.utils import ImplicitDataset\n",
    "from openrec.tf1.legacy.recommenders import CML, BPR, PMF\n",
    "from openrec.tf1.legacy.utils.evaluators import AUC\n",
    "from openrec.tf1.legacy.utils.samplers import PairwiseSampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "import os\n",
    "import pickle\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GENERATE THE DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2384795\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "folder_name = f\"./Dataset/\"\n",
    "\n",
    "if os.path.exists(folder_name) == False:\n",
    "    os.makedirs(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>SongID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  SongID  Rating\n",
       "0       1      14       5\n",
       "1       1      35       1\n",
       "2       1      46       1\n",
       "3       1      83       1\n",
       "4       1      93       1\n",
       "5       1      94       1\n",
       "6       1     153       5\n",
       "7       1     170       4\n",
       "8       1     184       5\n",
       "9       1     194       5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'yahoo_ymusic_v1/ydata-ymusic-rating-study-v1_0-train.txt'\n",
    "\n",
    "# Load the training set into a DataFrame\n",
    "df_train = pd.read_csv(folder_name+file_path, sep='\\t',names=[\"UserID\",\"SongID\",\"Rating\"], header=None)  # sep='\\t' for tab-separated values\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"We treat items rated greater than or equal to 4 as relevant, and others as irrelevant, as suggested by prior literature.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>SongID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>ImplicitRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  SongID  Rating  ImplicitRating\n",
       "0       1      14       5               1\n",
       "1       1      35       1               0\n",
       "2       1      46       1               0\n",
       "3       1      83       1               0\n",
       "4       1      93       1               0\n",
       "5       1      94       1               0\n",
       "6       1     153       5               1\n",
       "7       1     170       4               1\n",
       "8       1     184       5               1\n",
       "9       1     194       5               1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POSITIVE_THRESHOLD = 4\n",
    "df_train['ImplicitRating'] = np.where(df_train['Rating'] >= POSITIVE_THRESHOLD, 1, 0)\n",
    "\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the number of users and items in the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The training set contains 300K ratings given by 15.4K users against 1K songs through natural interactions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 15400)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_user = df_train[\"UserID\"].min()\n",
    "max_user = df_train[\"UserID\"].max()\n",
    "\n",
    "min_item = df_train[\"SongID\"].min()\n",
    "max_item = df_train[\"SongID\"].max()\n",
    "\n",
    "max_item, max_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GET UNBIASED TESTSET**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the unbiased testset and convert it to implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>SongID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>ImplicitRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>177</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>268</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>511</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>587</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>772</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>941</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  SongID  Rating  ImplicitRating\n",
       "0       1      49       1               0\n",
       "1       1     126       1               0\n",
       "2       1     138       1               0\n",
       "3       1     141       1               0\n",
       "4       1     177       1               0\n",
       "5       1     268       3               0\n",
       "6       1     511       1               0\n",
       "7       1     587       1               0\n",
       "8       1     772       5               1\n",
       "9       1     941       1               0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'Dataset/yahoo_ymusic_v1/ydata-ymusic-rating-study-v1_0-test.txt'\n",
    "df_test = pd.read_csv(file_path, sep='\\t',names=[\"UserID\",\"SongID\",\"Rating\"], header=None)  # sep='\\t' for tab-separated values\n",
    "df_test['ImplicitRating'] = np.where(df_test['Rating'] >= POSITIVE_THRESHOLD, 1, 0)\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the number of users and items in the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The testing set is collected by asking a subset of 5.4K users to rate 10 randomly selected songs.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400, 1000, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"UserID\"].max(), df_test[\"SongID\"].max(), int(df_test.shape[0]/df_test[\"UserID\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter unbiased testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"We filter the testing set by retaining users who have at least a relevant and an irrelevant song in the testing set and two relevant songs in the training set.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select users with at least an irrelevant song in the unbiased testset\n",
    "usersWithNegativeInteractionInTest = df_test[df_test[\"ImplicitRating\"] == 0][\"UserID\"].unique()\n",
    "\n",
    "# Select UserID of users with at least a relevant song in testset\n",
    "usersWithPositiveInteractionInTest = df_test[df_test[\"ImplicitRating\"] == 1][\"UserID\"].unique()\n",
    "\n",
    "# Select UserID of users with at least two relevant song in trainset\n",
    "usersWithTwoPositiveInteractions = df_train[df_train[\"ImplicitRating\"] == 1].groupby(\"UserID\").filter(lambda x: len(x) >= 2)['UserID'].unique()\n",
    "\n",
    "# Compute the intersection\n",
    "set1 = set(usersWithNegativeInteractionInTest)\n",
    "set2 = set(usersWithPositiveInteractionInTest)\n",
    "set3 = set(usersWithTwoPositiveInteractions)\n",
    "valid_users_testset = set1 & set2 & set3\n",
    "\n",
    "# Filter the testset\n",
    "df_test_filtered = df_test[df_test[\"UserID\"].isin(valid_users_testset)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"2296 users satisfy these requirements.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2296"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_users_testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape the unbiased test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the dataframe, for each row where ImplicitRating is 1, append [userID, itemID] to unbiased_pos_test_set\n",
    "# and for each row where ImplicitRating is 0, append [userID, itemID] to unbiased_neg_test_set\n",
    "\n",
    "unbiased_pos_test_set = df_test_filtered[df_test_filtered[\"ImplicitRating\"] == 1][[\"UserID\", \"SongID\"]].values\n",
    "unbiased_neg_test_set = df_test_filtered[df_test_filtered[\"ImplicitRating\"] == 0][[\"UserID\", \"SongID\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save unbiased test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unbiased_pos_test_set_df = pd.DataFrame(unbiased_pos_test_set)\n",
    "unbiased_neg_test_set_df = pd.DataFrame(unbiased_neg_test_set)\n",
    "\n",
    "unbiased_pos_test_set_df.columns = [\"user_id\",\"item_id\"]\n",
    "unbiased_neg_test_set_df.columns = [\"user_id\",\"item_id\"]\n",
    "\n",
    "structured_data_pos_test_set_unbiased = unbiased_pos_test_set_df.to_records(index=False)\n",
    "structured_data_neg_test_set_unbiased = unbiased_neg_test_set_df.to_records(index=False)\n",
    "\n",
    "np.save(folder_name + \"unbiased-test_arr_pos.npy\", structured_data_pos_test_set_unbiased)\n",
    "np.save(folder_name + \"unbiased-test_arr_neg.npy\", structured_data_neg_test_set_unbiased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GET BIASED TESTSET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>SongID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  SongID  Rating\n",
       "0       1      14       5\n",
       "1       1      35       1\n",
       "2       1      46       1\n",
       "3       1      83       1\n",
       "4       1      93       1\n",
       "5       1      94       1\n",
       "6       1     153       5\n",
       "7       1     170       4\n",
       "8       1     184       5\n",
       "9       1     194       5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'yahoo_ymusic_v1/ydata-ymusic-rating-study-v1_0-train.txt'\n",
    "\n",
    "# Load the training set into a DataFrame\n",
    "df_train = pd.read_csv(folder_name+file_path, sep='\\t',names=[\"UserID\",\"SongID\",\"Rating\"], header=None)  # sep='\\t' for tab-separated values\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['ImplicitRating'] = np.where(df_train['Rating'] >= POSITIVE_THRESHOLD, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train[\"UserID\"].isin(valid_users_testset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 58799 entries, 0 to 129178\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   UserID          58799 non-null  int64\n",
      " 1   SongID          58799 non-null  int64\n",
      " 2   Rating          58799 non-null  int64\n",
      " 3   ImplicitRating  58799 non-null  int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the biased test set and shape it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"We additionally held out a biased testing set (biased-testing) from the training set by randomly sampling 300 songs for each user.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute, for each user, the list of songs with a relevant rating\n",
    "user_positive_ratings = df_train[df_train[\"ImplicitRating\"] == 1].groupby(\"UserID\")[\"SongID\"].apply(set)\n",
    "\n",
    "# Initialize the range of indexes for the items\n",
    "items_ids = np.arange(min_item, max_item + 1)\n",
    "# Set the number of songs for each user\n",
    "SONGS_FOR_BIASED_TEST = 300\n",
    "\n",
    "#IPOTESI MAN\n",
    "\n",
    "pos_test_set = []\n",
    "neg_test_set = []\n",
    "\n",
    "for user_id in valid_users_testset:\n",
    "    np.random.shuffle(items_ids)\n",
    "    test_items = set(items_ids[-SONGS_FOR_BIASED_TEST:])\n",
    "    pos_ids = user_positive_ratings.get(user_id, set()) & test_items\n",
    "\n",
    "    #set those to 0 so that they will no longer be used in training set\n",
    "    df_train.loc[(df_train['SongID'].isin(pos_ids)) & (df_train['UserID'] == user_id), 'ImplicitRating'] = 0\n",
    "\n",
    "    for id in test_items:\n",
    "        if id in pos_ids:\n",
    "            pos_test_set.append([user_id, id])\n",
    "        else:\n",
    "            neg_test_set.append([user_id, id])\n",
    "\n",
    "pos_test_set = np.array(pos_test_set)\n",
    "neg_test_set = np.array(neg_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the biased test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test_set_df = pd.DataFrame(pos_test_set)\n",
    "neg_test_set_df = pd.DataFrame(neg_test_set)\n",
    "\n",
    "pos_test_set_df.columns = [\"user_id\",\"item_id\"]\n",
    "neg_test_set_df.columns = [\"user_id\",\"item_id\"]\n",
    "\n",
    "structured_data_pos_test_set = pos_test_set_df.to_records(index=False)\n",
    "structured_data_neg_test_set = neg_test_set_df.to_records(index=False)\n",
    "\n",
    "np.save(folder_name + \"biased-test_arr_pos.npy\", structured_data_pos_test_set)\n",
    "np.save(folder_name + \"biased-test_arr_neg.npy\", structured_data_neg_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **STORE TRAINSET**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take couples user-item filtering out the irrelevant ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only take the couples (user, item) with relevant rating\n",
    "new_df = df_train[df_train['ImplicitRating'] != 0]\n",
    "new_df = new_df.drop(columns=['Rating', 'ImplicitRating'])\n",
    "\n",
    "# Define a dictionary for renaming columns\n",
    "rename_dict = {\n",
    "    'UserID': 'user_id',\n",
    "    'SongID': 'item_id'\n",
    "}\n",
    "\n",
    "# Rename the columns\n",
    "new_df = new_df.rename(columns=rename_dict)\n",
    "\n",
    "# Convert the DataFrame to a structured array\n",
    "structured_data = new_df.to_records(index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = structured_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(folder_name + \"training_arr.npy\", train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MODEL CHOICE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = dict()\n",
    "raw_data['train_data'] = np.load(folder_name + \"training_arr.npy\")\n",
    "raw_data['max_user'] = 15401\n",
    "raw_data['max_item'] = 1001\n",
    "batch_size = 8000\n",
    "test_batch_size = 1000\n",
    "display_itr = 1000\n",
    "\n",
    "train_dataset = ImplicitDataset(raw_data['train_data'], raw_data['max_user'], raw_data['max_item'], name='Train')\n",
    "\n",
    "MODEL_CLASS = CML\n",
    "MODEL_PREFIX = \"cml\"\n",
    "DATASET_NAME = \"yahoo\"\n",
    "OUTPUT_FOLDER = \"./Output/\"\n",
    "OUTPUT_PATH = OUTPUT_FOLDER + MODEL_PREFIX + \"-\" + DATASET_NAME + \"/\"\n",
    "OUTPUT_PREFIX = str(OUTPUT_PATH) + str(MODEL_PREFIX) + \"-\" + str(DATASET_NAME)\n",
    "\n",
    "\n",
    "if os.path.exists(OUTPUT_PATH) == False:\n",
    "    os.makedirs(OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TRAIN THE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/japo/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:391: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/japo/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:31: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/japo/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:41: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/japo/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:43: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/japo/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:33: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/japo/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/interactions/pairwise_eu_dist.py:71: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/japo/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:596: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/japo/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/japo/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:75: The name tf.scatter_update is deprecated. Please use tf.compat.v1.scatter_update instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/japo/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:144: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/japo/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:365: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/japo/miniconda3/envs/RecSysEvaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:148: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 16:03:05.544790: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2024-02-21 16:03:05.574947: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f79fc789140 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-21 16:03:05.574965: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "# Avoid tensorflow using cached embeddings\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "\n",
    "model = MODEL_CLASS(batch_size=batch_size, max_user=train_dataset.max_user(), max_item=train_dataset.max_item(), \n",
    "    dim_embed=50, l2_reg=0.001, opt='Adam', sess_config=None)\n",
    "sampler = PairwiseSampler(batch_size=batch_size, dataset=train_dataset, num_process=4)\n",
    "model_trainer = ImplicitModelTrainer(batch_size=batch_size, test_batch_size=test_batch_size,\n",
    "                                     train_dataset=train_dataset, model=model, sampler=sampler,\n",
    "                                     eval_save_prefix=OUTPUT_PATH + DATASET_NAME,\n",
    "                                     item_serving_size=500)\n",
    "auc_evaluator = AUC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Start training with FULL evaluation ==\n",
      "[Itr 100] Finished\n",
      "[Itr 200] Finished\n",
      "[Itr 300] Finished\n",
      "[Itr 400] Finished\n",
      "[Itr 500] Finished\n",
      "[Itr 600] Finished\n",
      "[Itr 700] Finished\n",
      "[Itr 800] Finished\n",
      "[Itr 900] Finished\n",
      "[Itr 1000] Finished\n",
      "INFO:tensorflow:./Output/cml-yahoo/yahoo-1000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 1000] loss: 1757.287755\n",
      "[Itr 1100] Finished\n",
      "[Itr 1200] Finished\n",
      "[Itr 1300] Finished\n",
      "[Itr 1400] Finished\n",
      "[Itr 1500] Finished\n",
      "[Itr 1600] Finished\n",
      "[Itr 1700] Finished\n",
      "[Itr 1800] Finished\n",
      "[Itr 1900] Finished\n",
      "[Itr 2000] Finished\n",
      "INFO:tensorflow:./Output/cml-yahoo/yahoo-2000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 2000] loss: 651.332310\n",
      "[Itr 2100] Finished\n",
      "[Itr 2200] Finished\n",
      "[Itr 2300] Finished\n",
      "[Itr 2400] Finished\n",
      "[Itr 2500] Finished\n",
      "[Itr 2600] Finished\n",
      "[Itr 2700] Finished\n",
      "[Itr 2800] Finished\n",
      "[Itr 2900] Finished\n",
      "[Itr 3000] Finished\n",
      "INFO:tensorflow:./Output/cml-yahoo/yahoo-3000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 3000] loss: 574.374786\n",
      "[Itr 3100] Finished\n",
      "[Itr 3200] Finished\n",
      "[Itr 3300] Finished\n",
      "[Itr 3400] Finished\n",
      "[Itr 3500] Finished\n",
      "[Itr 3600] Finished\n",
      "[Itr 3700] Finished\n",
      "[Itr 3800] Finished\n",
      "[Itr 3900] Finished\n",
      "[Itr 4000] Finished\n",
      "INFO:tensorflow:./Output/cml-yahoo/yahoo-4000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 4000] loss: 545.694535\n",
      "[Itr 4100] Finished\n",
      "[Itr 4200] Finished\n",
      "[Itr 4300] Finished\n",
      "[Itr 4400] Finished\n",
      "[Itr 4500] Finished\n",
      "[Itr 4600] Finished\n",
      "[Itr 4700] Finished\n",
      "[Itr 4800] Finished\n",
      "[Itr 4900] Finished\n",
      "[Itr 5000] Finished\n",
      "INFO:tensorflow:./Output/cml-yahoo/yahoo-5000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 5000] loss: 532.417934\n",
      "[Itr 5100] Finished\n",
      "[Itr 5200] Finished\n",
      "[Itr 5300] Finished\n",
      "[Itr 5400] Finished\n",
      "[Itr 5500] Finished\n",
      "[Itr 5600] Finished\n",
      "[Itr 5700] Finished\n",
      "[Itr 5800] Finished\n",
      "[Itr 5900] Finished\n",
      "[Itr 6000] Finished\n",
      "INFO:tensorflow:./Output/cml-yahoo/yahoo-6000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 6000] loss: 525.465477\n",
      "[Itr 6100] Finished\n",
      "[Itr 6200] Finished\n",
      "[Itr 6300] Finished\n",
      "[Itr 6400] Finished\n",
      "[Itr 6500] Finished\n",
      "[Itr 6600] Finished\n",
      "[Itr 6700] Finished\n",
      "[Itr 6800] Finished\n",
      "[Itr 6900] Finished\n",
      "[Itr 7000] Finished\n",
      "INFO:tensorflow:./Output/cml-yahoo/yahoo-7000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 7000] loss: 521.125554\n",
      "[Itr 7100] Finished\n",
      "[Itr 7200] Finished\n",
      "[Itr 7300] Finished\n",
      "[Itr 7400] Finished\n",
      "[Itr 7500] Finished\n",
      "[Itr 7600] Finished\n",
      "[Itr 7700] Finished\n",
      "[Itr 7800] Finished\n",
      "[Itr 7900] Finished\n",
      "[Itr 8000] Finished\n",
      "INFO:tensorflow:./Output/cml-yahoo/yahoo-8000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 8000] loss: 519.831375\n",
      "[Itr 8100] Finished\n",
      "[Itr 8200] Finished\n",
      "[Itr 8300] Finished\n",
      "[Itr 8400] Finished\n",
      "[Itr 8500] Finished\n",
      "[Itr 8600] Finished\n",
      "[Itr 8700] Finished\n",
      "[Itr 8800] Finished\n",
      "[Itr 8900] Finished\n",
      "[Itr 9000] Finished\n",
      "INFO:tensorflow:./Output/cml-yahoo/yahoo-9000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 9000] loss: 517.212094\n",
      "[Itr 9100] Finished\n",
      "[Itr 9200] Finished\n",
      "[Itr 9300] Finished\n",
      "[Itr 9400] Finished\n",
      "[Itr 9500] Finished\n",
      "[Itr 9600] Finished\n",
      "[Itr 9700] Finished\n",
      "[Itr 9800] Finished\n",
      "[Itr 9900] Finished\n",
      "[Itr 10000] Finished\n",
      "INFO:tensorflow:./Output/cml-yahoo/yahoo-10000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 10000] loss: 515.165876\n"
     ]
    }
   ],
   "source": [
    "model_trainer.train(num_itr=10001, display_itr=display_itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:./Output/cml-yahoo/ is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.save(OUTPUT_PATH,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Defining Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eq(infilename, infilename_neg, trainfilename, gamma=-1.0, K=1):\n",
    "    infile = open(infilename, 'rb')\n",
    "    infile_neg = open(infilename_neg, 'rb')\n",
    "    P = pickle.load(infile)\n",
    "    infile.close()\n",
    "    P_neg = pickle.load(infile_neg)\n",
    "    infile_neg.close()\n",
    "    NUM_NEGATIVES = P[\"num_negatives\"]\n",
    "    #\n",
    "    for theuser in P[\"users\"]:\n",
    "        neg_items = list(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:])\n",
    "        neg_scores = list(P_neg[\"results\"][theuser][NUM_NEGATIVES:])\n",
    "        P[\"user_items\"][theuser] = list(neg_items) + list(P[\"user_items\"][theuser][NUM_NEGATIVES:])\n",
    "        P[\"results\"][theuser] = list(neg_scores) + list(P[\"results\"][theuser][NUM_NEGATIVES:])\n",
    "    #\n",
    "    Zui = dict()\n",
    "    Ni = dict()\n",
    "    # fill in dictionary Ni\n",
    "    trainset = np.load(trainfilename)\n",
    "    for i in trainset['item_id']:\n",
    "        if i in Ni:\n",
    "            Ni[i] += 1\n",
    "        else:\n",
    "            Ni[i] = 1\n",
    "    del trainset\n",
    "\n",
    "    # count #users with non-zero item frequencies\n",
    "    nonzero_user_count = 0\n",
    "    for theuser in P[\"users\"]:\n",
    "        pos_items = P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]\n",
    "        for pos_item in pos_items:\n",
    "            if pos_item in Ni:\n",
    "                nonzero_user_count += 1\n",
    "                break\n",
    "    # fill in dictionary Zui\n",
    "    for theuser in P[\"users\"]:\n",
    "        all_scores = np.array(P[\"results\"][theuser])\n",
    "        pos_items = P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]\n",
    "        pos_scores = P[\"results\"][theuser][len(P_neg[\"results\"][theuser][NUM_NEGATIVES:]):]\n",
    "        for i, pos_item in enumerate(pos_items):\n",
    "            pos_score = pos_scores[i]\n",
    "            Zui[(theuser, pos_item)] = float(np.sum(all_scores > pos_score))\n",
    "    # calculate per-user scores\n",
    "    sum_user_auc = 0.0\n",
    "    sum_user_recall = 0.0\n",
    "\n",
    "    for theuser in P[\"users\"]:\n",
    "        numerator_auc = 0.0\n",
    "        numerator_recall = 0.0\n",
    "        denominator = 0.0\n",
    "        for theitem in P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]:\n",
    "            if theitem not in Ni:\n",
    "                continue\n",
    "            pui = np.power(Ni[theitem], (gamma + 1) / 2.0)\n",
    "\n",
    "            numerator_auc += (1 - Zui[(theuser, theitem)] / len(P[\"user_items\"][theuser])) / pui\n",
    "            # Calcolo il Recall a 1, vedi nota 6 paper\n",
    "            if Zui[(theuser, theitem)] < K:\n",
    "                numerator_recall += 1.0 / pui\n",
    "            denominator += 1 / pui\n",
    "                \n",
    "\n",
    "        if denominator > 0:\n",
    "            sum_user_auc += numerator_auc / denominator\n",
    "            sum_user_recall += numerator_recall / denominator \n",
    "\n",
    "    return {\n",
    "        \"auc\"       : sum_user_auc / nonzero_user_count,\n",
    "        \"recall\"    : sum_user_recall / nonzero_user_count\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aoa(infilename, infilename_neg, trainfilename, K=1):\n",
    "    infile = open(infilename, 'rb')\n",
    "    infile_neg = open(infilename_neg, 'rb')\n",
    "    P = pickle.load(infile)\n",
    "    infile.close()\n",
    "    P_neg = pickle.load(infile_neg)\n",
    "    infile_neg.close()\n",
    "    NUM_NEGATIVES = P[\"num_negatives\"]\n",
    "    #\n",
    "    for theuser in P[\"users\"]:\n",
    "        neg_items = list(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:])\n",
    "        neg_scores = list(P_neg[\"results\"][theuser][NUM_NEGATIVES:])\n",
    "        P[\"user_items\"][theuser] = list(neg_items) + list(P[\"user_items\"][theuser][NUM_NEGATIVES:])\n",
    "        P[\"results\"][theuser] = list(neg_scores) + list(P[\"results\"][theuser][NUM_NEGATIVES:])\n",
    "    #\n",
    "    Zui = dict()\n",
    "    Ni = dict()\n",
    "    # fill in dictionary Ni\n",
    "    trainset = np.load(trainfilename)\n",
    "    for i in trainset['item_id']:\n",
    "        if i in Ni:\n",
    "            Ni[i] += 1\n",
    "        else:\n",
    "            Ni[i] = 1\n",
    "    del trainset\n",
    "    # count #users with non-zero item frequencies\n",
    "    nonzero_user_count = 0\n",
    "    for theuser in P[\"users\"]:\n",
    "        pos_items = P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]\n",
    "        for pos_item in pos_items:\n",
    "            if pos_item in Ni:\n",
    "                nonzero_user_count += 1\n",
    "                break\n",
    "    # fill in dictionary Zui\n",
    "    for theuser in P[\"users\"]:\n",
    "        all_scores = np.array(P[\"results\"][theuser])\n",
    "        pos_items = P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]\n",
    "        pos_scores = P[\"results\"][theuser][len(P_neg[\"results\"][theuser][NUM_NEGATIVES:]):]\n",
    "        for i, pos_item in enumerate(pos_items):\n",
    "            pos_score = pos_scores[i]\n",
    "            Zui[(theuser, pos_item)] = float(np.sum(all_scores > pos_score))\n",
    "    # calculate per-user scores\n",
    "    sum_user_auc = 0.0\n",
    "    sum_user_recall = 0.0\n",
    "    for theuser in P[\"users\"]:\n",
    "        numerator_auc = 0.0\n",
    "        numerator_recall = 0.0\n",
    "        denominator = 0.0\n",
    "\n",
    "        for theitem in P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]:\n",
    "            if theitem not in Ni:\n",
    "                continue\n",
    "            numerator_auc += (1 - Zui[(theuser, theitem)] / len(P[\"user_items\"][theuser]))\n",
    "            # Calcolo il Recall a 30, vedi nota 6 paper\n",
    "            if Zui[(theuser, theitem)] < K:\n",
    "                numerator_recall += 1.0\n",
    "            denominator += 1 \n",
    "\n",
    "        if denominator > 0:\n",
    "            sum_user_auc += numerator_auc / denominator\n",
    "            sum_user_recall += numerator_recall / denominator\n",
    "\n",
    "    return {\n",
    "        \"auc\"       : sum_user_auc / nonzero_user_count,\n",
    "        \"recall\"    : sum_user_recall / nonzero_user_count\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified(infilename, infilename_neg, trainfilename, gamma=1.0, K=30, partition=10):\n",
    "\n",
    "    # Read pickles\n",
    "    infile = open(infilename, 'rb')\n",
    "    infile_neg = open(infilename_neg, 'rb')\n",
    "    P = pickle.load(infile)\n",
    "    infile.close()\n",
    "    P_neg = pickle.load(infile_neg)\n",
    "    infile_neg.close()\n",
    "    NUM_NEGATIVES = P[\"num_negatives\"]\n",
    "\n",
    "    # Merge P and P_neg\n",
    "    for theuser in P[\"users\"]:\n",
    "        neg_items = list(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:])\n",
    "        neg_scores = list(P_neg[\"results\"][theuser][NUM_NEGATIVES:])\n",
    "        P[\"user_items\"][theuser] = list(neg_items) + list(P[\"user_items\"][theuser][NUM_NEGATIVES:])\n",
    "        P[\"results\"][theuser] = list(neg_scores) + list(P[\"results\"][theuser][NUM_NEGATIVES:])\n",
    "\n",
    "    Zui = dict()\n",
    "    Ni = dict()\n",
    "\n",
    "    # Compute frequencies of items in the training set\n",
    "    trainset = np.load(trainfilename)\n",
    "    for i in trainset['item_id']:\n",
    "        if i in Ni:\n",
    "            Ni[i] += 1\n",
    "        else:\n",
    "            Ni[i] = 1\n",
    "    del trainset\n",
    "\n",
    "    # Compute recommendations for each user\n",
    "    for theuser in P[\"users\"]:\n",
    "        all_scores = np.array(P[\"results\"][theuser])\n",
    "        pos_items = P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]\n",
    "        pos_scores = P[\"results\"][theuser][len(P_neg[\"results\"][theuser][NUM_NEGATIVES:]):]\n",
    "        for i, pos_item in enumerate(pos_items):\n",
    "            pos_score = pos_scores[i]\n",
    "            Zui[(theuser, pos_item)] = float(np.sum(all_scores > pos_score))\n",
    "\n",
    "    pui = dict()\n",
    "    w = dict()\n",
    "\n",
    "    # Compute dictionary of propensity scores\n",
    "    for theuser in P[\"users\"]:\n",
    "        for theitem in P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]:\n",
    "            if theitem not in Ni:\n",
    "                continue\n",
    "            if theitem in pui:\n",
    "                continue\n",
    "            pui[theitem] = np.power(Ni[theitem], (gamma + 1) / 2.0)\n",
    "\n",
    "    # Take the list of items (not tuples) in pui sorted by value\n",
    "    items_sorted_by_value = sorted(pui, key=pui.get, reverse=True)\n",
    "\n",
    "    # Compute linspace between the pui[0] and pui[-1] \n",
    "    linspace = np.linspace(pui[items_sorted_by_value[0]], pui[items_sorted_by_value[-1]], partition+1)\n",
    "   \n",
    "    # Compute dictionary w, that is, for each item, assigns the average of the puis in the partition it belongs to\n",
    "    i=0\n",
    "    j = 0\n",
    "    while i < len(items_sorted_by_value):\n",
    "                            \n",
    "        avg = 0\n",
    "        start = i\n",
    "        end = i\n",
    "    \n",
    "        while i < len(items_sorted_by_value) and pui[items_sorted_by_value[i]] >= linspace[j+1]:\n",
    "            avg += 1.0 / pui[items_sorted_by_value[i]]\n",
    "            end = i\n",
    "            i += 1\n",
    "        \n",
    "        avg = avg / (end - start + 1)\n",
    "\n",
    "        for k in range(start, end+1):\n",
    "            w[items_sorted_by_value[k]] = avg\n",
    "\n",
    "\n",
    "        j += 1\n",
    "\n",
    "\n",
    "    nonzero_user_count = 0\n",
    "    sum_user_auc = 0.0\n",
    "    sum_user_recall = 0.0\n",
    "\n",
    "    # Compute score with AUC and compute Recall\n",
    "    for theuser in P[\"users\"]:\n",
    "        numerator_auc = 0.0\n",
    "        numerator_recall = 0.0\n",
    "        denominator = 0.0\n",
    "        for theitem in P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]:\n",
    "            # Skip items with null frequency\n",
    "            if  theitem not in Ni:\n",
    "                continue\n",
    "            # Add things to be summed for each item\n",
    "            numerator_auc += (1 - Zui[(theuser, theitem)] / len(P[\"user_items\"][theuser])) * w[theitem]\n",
    "            # Add things for recall\n",
    "            if Zui[(theuser, theitem)] < K:\n",
    "                numerator_recall += 1.0 * w[theitem] #spetta\n",
    "            # Increment denominator that the sum must be divided by \n",
    "            denominator += 1 / pui[theitem]\n",
    "\n",
    "\n",
    "        # If there was at least one item for the user, count the user and sum the results\n",
    "        if denominator > 0:\n",
    "            nonzero_user_count += 1\n",
    "            sum_user_auc += numerator_auc / denominator\n",
    "            sum_user_recall += numerator_recall / denominator \n",
    "\n",
    "    return {\n",
    "        \"auc\"       : sum_user_auc / nonzero_user_count, \n",
    "        \"recall\"    : sum_user_recall / nonzero_user_count\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **EVALUATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_results = []\n",
    "recall_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = dict()\n",
    "raw_data['train_data'] = np.load(folder_name + \"training_arr.npy\")\n",
    "raw_data['test_data_pos_biased'] = np.load(folder_name + \"biased-test_arr_pos.npy\")\n",
    "raw_data['test_data_neg_biased'] = np.load(folder_name + \"biased-test_arr_neg.npy\")\n",
    "raw_data['test_data_pos_unbiased'] = np.load(folder_name + \"unbiased-test_arr_pos.npy\")\n",
    "raw_data['test_data_neg_unbiased'] = np.load(folder_name + \"unbiased-test_arr_neg.npy\")\n",
    "raw_data['max_user'] = 15401\n",
    "raw_data['max_item'] = 1001\n",
    "batch_size = 8000\n",
    "test_batch_size = 1000\n",
    "display_itr = 1000\n",
    "\n",
    "train_dataset = ImplicitDataset(raw_data['train_data'], raw_data['max_user'], raw_data['max_item'], name='Train')\n",
    "test_dataset_pos_biased = ImplicitDataset(raw_data['test_data_pos_biased'], raw_data['max_user'], raw_data['max_item'])\n",
    "test_dataset_neg_biased = ImplicitDataset(raw_data['test_data_neg_biased'], raw_data['max_user'], raw_data['max_item'])\n",
    "test_dataset_pos_unbiased = ImplicitDataset(raw_data['test_data_pos_unbiased'], raw_data['max_user'], raw_data['max_item'])\n",
    "test_dataset_neg_unbiased = ImplicitDataset(raw_data['test_data_neg_unbiased'], raw_data['max_user'], raw_data['max_item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Output/cml-yahoo/\n"
     ]
    }
   ],
   "source": [
    "#Code to avoid tf using cached embeddings\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "model = MODEL_CLASS(batch_size=batch_size, max_user=train_dataset.max_user(), max_item=train_dataset.max_item(),\n",
    "    dim_embed=50, l2_reg=0.001, opt='Adam', sess_config=None)\n",
    "sampler = PairwiseSampler(batch_size=batch_size, dataset=train_dataset, num_process=4)\n",
    "model_trainer = ImplicitModelTrainer(batch_size=batch_size, test_batch_size=test_batch_size,\n",
    "                                     train_dataset=train_dataset, model=model, sampler=sampler,\n",
    "                                     eval_save_prefix=OUTPUT_PATH + DATASET_NAME,\n",
    "                                     item_serving_size=500)\n",
    "auc_evaluator = AUC()\n",
    "\n",
    "model.load(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Subsampling negative items]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    }
   ],
   "source": [
    "model_trainer._eval_manager = ImplicitEvalManager(evaluators=[auc_evaluator])\n",
    "model_trainer._num_negatives = 200\n",
    "model_trainer._exclude_positives([train_dataset, test_dataset_pos_biased, test_dataset_neg_biased])\n",
    "model_trainer._sample_negatives(seed=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biased Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2070/2070 [00:01<00:00, 1210.63it/s]\n",
      "100%|| 2296/2296 [00:53<00:00, 43.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AUC': [0.4963728813559322,\n",
       "  0.5134237288135594,\n",
       "  0.5159731543624161,\n",
       "  0.5055704697986578,\n",
       "  0.48094276094276095,\n",
       "  0.4898135593220339,\n",
       "  0.5140604026845638,\n",
       "  0.532195945945946,\n",
       "  0.517751677852349,\n",
       "  0.5065151515151515,\n",
       "  0.4971016949152543,\n",
       "  0.5110810810810811,\n",
       "  0.4826633165829145,\n",
       "  0.4831333333333333,\n",
       "  0.5284375,\n",
       "  0.4906543624161074,\n",
       "  0.5177257525083613,\n",
       "  0.46860544217687067,\n",
       "  0.49010067114093964,\n",
       "  0.5311784511784512,\n",
       "  0.5363210702341137,\n",
       "  0.5311643835616439,\n",
       "  0.5031772575250836,\n",
       "  0.46182885906040266,\n",
       "  0.4894648829431438,\n",
       "  0.465,\n",
       "  0.4966494845360825,\n",
       "  0.4931772575250836,\n",
       "  0.4873639455782312,\n",
       "  0.5328787878787878,\n",
       "  0.46765100671140936,\n",
       "  0.48629629629629634,\n",
       "  0.5045833333333333,\n",
       "  0.5026086956521738,\n",
       "  0.48223154362416104,\n",
       "  0.5121644295302014,\n",
       "  0.5471571906354515,\n",
       "  0.4615136054421769,\n",
       "  0.49479865771812076,\n",
       "  0.48706081081081076,\n",
       "  0.48559121621621626,\n",
       "  0.45058620689655177,\n",
       "  0.543174061433447,\n",
       "  0.49643097643097645,\n",
       "  0.4729362416107383,\n",
       "  0.49094276094276096,\n",
       "  0.526986531986532,\n",
       "  0.53235,\n",
       "  0.49867449664429525,\n",
       "  0.4776421404682274,\n",
       "  0.5076,\n",
       "  0.5022895622895623,\n",
       "  0.515864406779661,\n",
       "  0.4960402684563759,\n",
       "  0.4941095890410959,\n",
       "  0.49088926174496655,\n",
       "  0.48309764309764314,\n",
       "  0.49218965517241386,\n",
       "  0.4732718120805369,\n",
       "  0.555,\n",
       "  0.47769360269360267,\n",
       "  0.522986577181208,\n",
       "  0.4839795918367348,\n",
       "  0.48501683501683496,\n",
       "  0.4619397993311037,\n",
       "  0.5031543624161073,\n",
       "  0.47050505050505054,\n",
       "  0.4840436241610738,\n",
       "  0.4909833333333334,\n",
       "  0.49954849498327764,\n",
       "  0.5128260869565217,\n",
       "  0.5271404682274248,\n",
       "  0.4452020202020202,\n",
       "  0.48880136986301376,\n",
       "  0.4813682432432433,\n",
       "  0.5066779661016949,\n",
       "  0.4642281879194631,\n",
       "  0.48501666666666665,\n",
       "  0.48446308724832216,\n",
       "  0.4857070707070707,\n",
       "  0.4657575757575757,\n",
       "  0.4739455782312925,\n",
       "  0.5033053691275168,\n",
       "  0.5098489932885907,\n",
       "  0.4858754208754208,\n",
       "  0.5030134680134679,\n",
       "  0.4636486486486487,\n",
       "  0.4963745704467354,\n",
       "  0.5567229729729729,\n",
       "  0.5235304054054054,\n",
       "  0.48538720538720537,\n",
       "  0.52251677852349,\n",
       "  0.4316554054054054,\n",
       "  0.49073825503355706,\n",
       "  0.5312121212121211,\n",
       "  0.4785102739726028,\n",
       "  0.5136912751677852,\n",
       "  0.5041471571906355,\n",
       "  0.4889358108108108,\n",
       "  0.5582214765100671,\n",
       "  0.47087837837837837,\n",
       "  0.5082876712328768,\n",
       "  0.5023129251700681,\n",
       "  0.5197202797202798,\n",
       "  0.5122666666666666,\n",
       "  0.49801694915254247,\n",
       "  0.4814046822742475,\n",
       "  0.49350671140939595,\n",
       "  0.5211499999999999,\n",
       "  0.4900673400673401,\n",
       "  0.4738422818791946,\n",
       "  0.5117171717171718,\n",
       "  0.4945117845117845,\n",
       "  0.4906632653061224,\n",
       "  0.49670033670033664,\n",
       "  0.5164,\n",
       "  0.503523489932886,\n",
       "  0.5060774410774411,\n",
       "  0.5049491525423729,\n",
       "  0.46691666666666665,\n",
       "  0.46234006734006733,\n",
       "  0.5016835016835017,\n",
       "  0.5653344481605352,\n",
       "  0.49590604026845636,\n",
       "  0.5007457627118644,\n",
       "  0.5018181818181818,\n",
       "  0.5393771043771044,\n",
       "  0.5256228956228955,\n",
       "  0.5319463087248323,\n",
       "  0.5389093959731542,\n",
       "  0.49842281879194633,\n",
       "  0.4733676975945017,\n",
       "  0.5038983050847456,\n",
       "  0.5015331010452961,\n",
       "  0.5666778523489933,\n",
       "  0.5015268456375839,\n",
       "  0.5076689189189189,\n",
       "  0.5081208053691275,\n",
       "  0.4922315436241611,\n",
       "  0.4876190476190477,\n",
       "  0.5250337837837837,\n",
       "  0.5356632653061225,\n",
       "  0.5244915254237288,\n",
       "  0.53155,\n",
       "  0.5048287671232876,\n",
       "  0.5117892976588629,\n",
       "  0.5135953177257525,\n",
       "  0.4986655405405406,\n",
       "  0.5268456375838926,\n",
       "  0.46525167785234894,\n",
       "  0.49135416666666665,\n",
       "  0.487876254180602,\n",
       "  0.5306375838926174,\n",
       "  0.5048116438356165,\n",
       "  0.48221666666666674,\n",
       "  0.53465,\n",
       "  0.4927516778523491,\n",
       "  0.5055892255892256,\n",
       "  0.5117171717171718,\n",
       "  0.4624324324324324,\n",
       "  0.502996632996633,\n",
       "  0.4725337837837838,\n",
       "  0.49001689189189196,\n",
       "  0.4383892617449664,\n",
       "  0.4913571428571429,\n",
       "  0.5649158249158248,\n",
       "  0.5198489932885907,\n",
       "  0.5097118644067797,\n",
       "  0.5044648829431438,\n",
       "  0.5088926174496645,\n",
       "  0.456554054054054,\n",
       "  0.4699659863945578,\n",
       "  0.5287585034013605,\n",
       "  0.4705574324324324,\n",
       "  0.4691047297297298,\n",
       "  0.47031772575250835,\n",
       "  0.47412751677852344,\n",
       "  0.514010067114094,\n",
       "  0.5371812080536912,\n",
       "  0.4939966555183946,\n",
       "  0.4277288135593221,\n",
       "  0.47861952861952856,\n",
       "  0.5460677966101695,\n",
       "  0.5155723905723906,\n",
       "  0.49567114093959735,\n",
       "  0.49066889632107025,\n",
       "  0.5039261744966443,\n",
       "  0.510721476510067,\n",
       "  0.44488333333333335,\n",
       "  0.4535,\n",
       "  0.5503030303030303,\n",
       "  0.5624581939799331,\n",
       "  0.4576430976430976,\n",
       "  0.5007288135593221,\n",
       "  0.4383047945205479,\n",
       "  0.5115488215488215,\n",
       "  0.49491467576791803,\n",
       "  0.5066610738255034,\n",
       "  0.5089130434782609,\n",
       "  0.5084459459459459,\n",
       "  0.5268456375838926,\n",
       "  0.5513255033557047,\n",
       "  0.5129865771812081,\n",
       "  0.49784999999999996,\n",
       "  0.4612881355932204,\n",
       "  0.49664983164983173,\n",
       "  0.4796790540540541,\n",
       "  0.4905555555555555,\n",
       "  0.4832333333333334,\n",
       "  0.5407939189189189,\n",
       "  0.44935810810810806,\n",
       "  0.4985785953177257,\n",
       "  0.4397491638795987,\n",
       "  0.5003367003367003,\n",
       "  0.5096296296296297,\n",
       "  0.45071906354515046,\n",
       "  0.49131313131313126,\n",
       "  0.5077777777777778,\n",
       "  0.5104391891891891,\n",
       "  0.508271812080537,\n",
       "  0.4885135135135135,\n",
       "  0.5005016722408028,\n",
       "  0.4858499999999999,\n",
       "  0.5078428093645485,\n",
       "  0.5595805369127517,\n",
       "  0.5073986486486486,\n",
       "  0.5247818791946308,\n",
       "  0.5118288590604027,\n",
       "  0.48595238095238097,\n",
       "  0.48545454545454536,\n",
       "  0.4608020477815699,\n",
       "  0.486476510067114,\n",
       "  0.48886287625418057,\n",
       "  0.5091107382550336,\n",
       "  0.5207692307692307,\n",
       "  0.445251677852349,\n",
       "  0.5316053511705685,\n",
       "  0.48328178694158075,\n",
       "  0.49780201342281877,\n",
       "  0.4942592592592593,\n",
       "  0.5209563758389262,\n",
       "  0.4890833333333333,\n",
       "  0.5268166666666667,\n",
       "  0.5122986577181209,\n",
       "  0.5095500000000001,\n",
       "  0.5368561872909698,\n",
       "  0.45582758620689656,\n",
       "  0.4504530201342282,\n",
       "  0.48394295302013424,\n",
       "  0.5272053872053871,\n",
       "  0.5248983050847457,\n",
       "  0.5221062271062272,\n",
       "  0.5264429530201342,\n",
       "  0.5058361204013379,\n",
       "  0.5274567474048443,\n",
       "  0.4999,\n",
       "  0.45738333333333336,\n",
       "  0.5203344481605352,\n",
       "  0.4826013513513514,\n",
       "  0.49826086956521737,\n",
       "  0.47180000000000005,\n",
       "  0.46843537414965986,\n",
       "  0.49848484848484853,\n",
       "  0.49215488215488223,\n",
       "  0.491979865771812,\n",
       "  0.5375838926174497,\n",
       "  0.49615,\n",
       "  0.5053691275167785,\n",
       "  0.5515254237288135,\n",
       "  0.5507214765100672,\n",
       "  0.48920875420875426,\n",
       "  0.4745000000000001,\n",
       "  0.5391021126760565,\n",
       "  0.5008952702702703,\n",
       "  0.5242542372881355,\n",
       "  0.5354882154882156,\n",
       "  0.5166778523489933,\n",
       "  0.5149832214765101,\n",
       "  0.4859106529209622,\n",
       "  0.5283505154639175,\n",
       "  0.4512074829931972,\n",
       "  0.4804333333333333,\n",
       "  0.50335,\n",
       "  0.4649163879598662,\n",
       "  0.4918729096989966,\n",
       "  0.47020066889632106,\n",
       "  0.5253198653198654,\n",
       "  0.46624579124579124,\n",
       "  0.4808585858585859,\n",
       "  0.5298648648648648,\n",
       "  0.4574916387959867,\n",
       "  0.46679180887372007,\n",
       "  0.5479333333333333,\n",
       "  0.48334459459459456,\n",
       "  0.46080267558528426,\n",
       "  0.4570401337792642,\n",
       "  0.482768456375839,\n",
       "  0.520066889632107,\n",
       "  0.5078498293515359,\n",
       "  0.5474581939799331,\n",
       "  0.5247288135593221,\n",
       "  0.5303523489932885,\n",
       "  0.5231587837837838,\n",
       "  0.5333389261744966,\n",
       "  0.4547635135135136,\n",
       "  0.5183333333333333,\n",
       "  0.526184668989547,\n",
       "  0.5042642140468226,\n",
       "  0.46374999999999994,\n",
       "  0.4653741496598639,\n",
       "  0.4923166666666666,\n",
       "  0.5048993288590603,\n",
       "  0.5314882943143813,\n",
       "  0.5012541806020067,\n",
       "  0.5276510067114094,\n",
       "  0.4407885906040269,\n",
       "  0.5208391608391608,\n",
       "  0.5214478114478115,\n",
       "  0.46815517241379306,\n",
       "  0.5200510204081634,\n",
       "  0.509271186440678,\n",
       "  0.48919732441471564,\n",
       "  0.4777891156462585,\n",
       "  0.4793311036789297,\n",
       "  0.5166161616161616,\n",
       "  0.5111317567567568,\n",
       "  0.5202693602693603,\n",
       "  0.5101170568561874,\n",
       "  0.548,\n",
       "  0.497820945945946,\n",
       "  0.5240939597315436,\n",
       "  0.466304347826087,\n",
       "  0.530765306122449,\n",
       "  0.52,\n",
       "  0.5405272108843537,\n",
       "  0.5104639175257731,\n",
       "  0.46465909090909085,\n",
       "  0.530976430976431,\n",
       "  0.5318896321070234,\n",
       "  0.47875420875420877,\n",
       "  0.5181525423728814,\n",
       "  0.4929280821917808,\n",
       "  0.47138047138047146,\n",
       "  0.467638036809816,\n",
       "  0.4862040133779264,\n",
       "  0.47000000000000003,\n",
       "  0.4579026845637583,\n",
       "  0.46913333333333335,\n",
       "  0.5241946308724833,\n",
       "  0.5169295302013422,\n",
       "  0.5121790540540541,\n",
       "  0.5056499999999999,\n",
       "  0.527206896551724,\n",
       "  0.4820066889632107,\n",
       "  0.5258724832214764,\n",
       "  0.5435344827586207,\n",
       "  0.4976530612244898,\n",
       "  0.48113175675675673,\n",
       "  0.5023244147157191,\n",
       "  0.47758333333333325,\n",
       "  0.483428093645485,\n",
       "  0.5549496644295302,\n",
       "  0.5844276094276094,\n",
       "  0.5212541806020067,\n",
       "  0.5074915254237288,\n",
       "  0.5118474576271187,\n",
       "  0.4996822742474916,\n",
       "  0.47248322147651,\n",
       "  0.5031972789115646,\n",
       "  0.5030434782608695,\n",
       "  0.4858922558922559,\n",
       "  0.5052341137123746,\n",
       "  0.5091000000000001,\n",
       "  0.5154377104377105,\n",
       "  0.5208053691275167,\n",
       "  0.5374074074074074,\n",
       "  0.5055351170568562,\n",
       "  0.5209866220735786,\n",
       "  0.5000513698630137,\n",
       "  0.4751170568561873,\n",
       "  0.5280388692579505,\n",
       "  0.5899812734082397,\n",
       "  0.5028114478114478,\n",
       "  0.5266666666666667,\n",
       "  0.5411912751677852,\n",
       "  0.49358391608391605,\n",
       "  0.5086993243243243,\n",
       "  0.4717905405405405,\n",
       "  0.5115816326530613,\n",
       "  0.4842255892255892,\n",
       "  0.45310810810810814,\n",
       "  0.4903666666666666,\n",
       "  0.5088333333333334,\n",
       "  0.5426450511945393,\n",
       "  0.4752508361204014,\n",
       "  0.4758026755852842,\n",
       "  0.4622297297297297,\n",
       "  0.4954347826086956,\n",
       "  0.5236148648648649,\n",
       "  0.5018060200668896,\n",
       "  0.4804391891891891,\n",
       "  0.4980742049469965,\n",
       "  0.5278859060402684,\n",
       "  0.5074333333333334,\n",
       "  0.5031649831649831,\n",
       "  0.527030201342282,\n",
       "  0.5462040133779265,\n",
       "  0.5158193979933111,\n",
       "  0.4717171717171718,\n",
       "  0.4950168918918919,\n",
       "  0.4752372881355932,\n",
       "  0.4640338983050848,\n",
       "  0.4703898305084746,\n",
       "  0.41732441471571907,\n",
       "  0.5223166666666667,\n",
       "  0.4988305084745763,\n",
       "  0.5270134228187919,\n",
       "  0.44081034482758624,\n",
       "  0.49617056856187297,\n",
       "  0.4858135593220339,\n",
       "  0.5334931506849316,\n",
       "  0.510642361111111,\n",
       "  0.5443097643097643,\n",
       "  0.5270134228187919,\n",
       "  0.519847972972973,\n",
       "  0.5126086956521738,\n",
       "  0.493238255033557,\n",
       "  0.5009395973154362,\n",
       "  0.48077181208053704,\n",
       "  0.5583728813559322,\n",
       "  0.5095892857142857,\n",
       "  0.5174080267558527,\n",
       "  0.4797138047138046,\n",
       "  0.5157407407407408,\n",
       "  0.4739999999999999,\n",
       "  0.4583101045296168,\n",
       "  0.46867892976588627,\n",
       "  0.5356785714285714,\n",
       "  0.49081355932203397,\n",
       "  0.5255050505050505,\n",
       "  0.5199131944444444,\n",
       "  0.5061224489795919,\n",
       "  0.5304898648648648,\n",
       "  0.4985016835016835,\n",
       "  0.47943143812709027,\n",
       "  0.4920637583892617,\n",
       "  0.4547972972972973,\n",
       "  0.538993288590604,\n",
       "  0.47067340067340074,\n",
       "  0.5489965397923875,\n",
       "  0.5092953020134229,\n",
       "  0.47593645484949837,\n",
       "  0.4852013422818792,\n",
       "  0.49379251700680277,\n",
       "  0.49000000000000005,\n",
       "  0.503593220338983,\n",
       "  0.5060333333333333,\n",
       "  0.45362244897959186,\n",
       "  0.5330338983050847,\n",
       "  0.47026936026936034,\n",
       "  0.49785000000000007,\n",
       "  0.4849828767123288,\n",
       "  0.5033390410958904,\n",
       "  0.5098825503355704,\n",
       "  0.4755685618729097,\n",
       "  0.5050671140939598,\n",
       "  0.5055593220338983,\n",
       "  0.5055723905723905,\n",
       "  0.485942760942761,\n",
       "  0.5380574324324324,\n",
       "  0.5336073825503356,\n",
       "  0.48980496453900707,\n",
       "  0.5042801556420233,\n",
       "  0.5201170568561873,\n",
       "  0.49883838383838386,\n",
       "  0.4833732876712329,\n",
       "  0.5263255033557047,\n",
       "  0.4696610169491526,\n",
       "  0.5046321070234113,\n",
       "  0.5166833333333333,\n",
       "  0.5118013468013468,\n",
       "  0.4951672240802676,\n",
       "  0.45085284280936455,\n",
       "  0.5593265993265993,\n",
       "  0.5161224489795919,\n",
       "  0.5002033898305085,\n",
       "  0.5202551020408165,\n",
       "  0.4998648648648648,\n",
       "  0.5515333333333333,\n",
       "  0.4873244147157191,\n",
       "  0.5469063545150502,\n",
       "  0.49426369863013697,\n",
       "  0.5056565656565657,\n",
       "  0.5311912751677852,\n",
       "  0.48461538461538456,\n",
       "  0.45639455782312927,\n",
       "  0.49034999999999995,\n",
       "  0.5245286195286196,\n",
       "  0.5050668896321071,\n",
       "  0.49915000000000004,\n",
       "  0.4754013377926421,\n",
       "  0.55135,\n",
       "  0.49380067567567576,\n",
       "  0.5197818791946308,\n",
       "  0.4930769230769231,\n",
       "  0.5305201342281879,\n",
       "  0.5257912457912458,\n",
       "  0.47655290102389075,\n",
       "  0.5041304347826088,\n",
       "  0.5066946308724832,\n",
       "  0.49040404040404034,\n",
       "  0.5097269624573378,\n",
       "  0.5160702341137124,\n",
       "  0.5174493243243242,\n",
       "  0.5054362416107383,\n",
       "  0.4977013422818792,\n",
       "  0.5018835616438356,\n",
       "  0.5178523489932887,\n",
       "  0.5117508417508417,\n",
       "  0.5087370242214533,\n",
       "  0.47498333333333337,\n",
       "  0.5228666666666667,\n",
       "  0.49410000000000004,\n",
       "  0.5124833333333334,\n",
       "  0.48525337837837834,\n",
       "  0.5295986622073579,\n",
       "  0.5228020134228188,\n",
       "  0.4764381270903009,\n",
       "  0.496996644295302,\n",
       "  0.5061409395973154,\n",
       "  0.5112975778546712,\n",
       "  0.5311054421768707,\n",
       "  0.46203333333333335,\n",
       "  0.4406632653061225,\n",
       "  0.5139057239057239,\n",
       "  0.49238255033557055,\n",
       "  0.5178523489932887,\n",
       "  0.4538368055555555,\n",
       "  0.4714334470989761,\n",
       "  0.4957046979865773,\n",
       "  0.5013006756756756,\n",
       "  0.5029026845637583,\n",
       "  0.4734563758389261,\n",
       "  0.5586868686868687,\n",
       "  0.5361241610738255,\n",
       "  0.4949322033898305,\n",
       "  0.5057525083612041,\n",
       "  0.45427118644067804,\n",
       "  0.4354013377926422,\n",
       "  0.5446822742474917,\n",
       "  0.5015217391304347,\n",
       "  0.44483108108108116,\n",
       "  0.4937248322147651,\n",
       "  0.5274080267558529,\n",
       "  0.473036912751678,\n",
       "  0.5191414141414141,\n",
       "  0.4779898648648649,\n",
       "  0.4816161616161616,\n",
       "  0.48653198653198654,\n",
       "  0.4757849829351536,\n",
       "  0.46962837837837834,\n",
       "  0.48738095238095247,\n",
       "  0.5018013468013468,\n",
       "  0.4819966442953021,\n",
       "  0.47463917525773197,\n",
       "  0.5213879598662208,\n",
       "  0.5286912751677852,\n",
       "  0.5279026845637583,\n",
       "  0.5020819112627987,\n",
       "  0.4940436241610738,\n",
       "  0.4761148648648649,\n",
       "  0.5199829931972789,\n",
       "  0.47099326599326596,\n",
       "  0.47251677852348994,\n",
       "  0.4769727891156462,\n",
       "  0.5084395973154363,\n",
       "  0.47636518771331055,\n",
       "  0.47453125000000007,\n",
       "  0.4847466216216217,\n",
       "  0.5511262798634813,\n",
       "  0.46248333333333336,\n",
       "  0.5303177257525084,\n",
       "  0.5081103678929766,\n",
       "  0.5075919732441472,\n",
       "  0.49397959183673473,\n",
       "  0.5062331081081082,\n",
       "  0.48617056856187296,\n",
       "  0.4569932432432432,\n",
       "  0.5092642140468226,\n",
       "  0.5564882943143812,\n",
       "  0.48569727891156467,\n",
       "  0.5031986531986532,\n",
       "  0.47824324324324324,\n",
       "  0.5160992907801418,\n",
       "  0.5567617449664429,\n",
       "  0.536097972972973,\n",
       "  0.49567114093959724,\n",
       "  0.4708528428093645,\n",
       "  0.5334760273972602,\n",
       "  0.4921212121212121,\n",
       "  0.4744499999999999,\n",
       "  0.47958904109589046,\n",
       "  0.5015824915824916,\n",
       "  0.4598829431438127,\n",
       "  0.47043771043771043,\n",
       "  0.5154849498327759,\n",
       "  0.4969166666666666,\n",
       "  0.4371308724832214,\n",
       "  0.498741610738255,\n",
       "  0.5097128378378378,\n",
       "  0.5147306397306397,\n",
       "  0.5372742474916388,\n",
       "  0.5419166666666667,\n",
       "  0.4512709030100335,\n",
       "  0.5064548494983276,\n",
       "  0.5119565217391304,\n",
       "  0.5350836120401338,\n",
       "  0.4983053691275168,\n",
       "  0.468452380952381,\n",
       "  0.5153202846975089,\n",
       "  0.48533670033670034,\n",
       "  0.5353703703703704,\n",
       "  0.5203859060402685,\n",
       "  0.49863175675675686,\n",
       "  0.5288255033557047,\n",
       "  0.4883779264214047,\n",
       "  0.4726949152542373,\n",
       "  0.5312876254180603,\n",
       "  0.49303333333333343,\n",
       "  0.5532214765100671,\n",
       "  0.5219127516778524,\n",
       "  0.544070945945946,\n",
       "  0.5406902356902357,\n",
       "  0.47140939597315423,\n",
       "  0.5026048951048951,\n",
       "  0.5285284280936455,\n",
       "  0.47774999999999995,\n",
       "  0.5536394557823129,\n",
       "  0.5333277591973244,\n",
       "  0.5099494949494949,\n",
       "  0.49690235690235696,\n",
       "  0.47780821917808214,\n",
       "  0.4796153846153845,\n",
       "  0.5024827586206897,\n",
       "  0.4801672240802675,\n",
       "  0.45489999999999997,\n",
       "  0.49280612244897953,\n",
       "  0.4829322033898305,\n",
       "  0.5092203389830509,\n",
       "  0.5122635135135135,\n",
       "  0.4700501672240802,\n",
       "  0.5073050847457626,\n",
       "  0.5243097643097643,\n",
       "  0.5042255892255892,\n",
       "  0.48586148648648647,\n",
       "  0.5154109589041096,\n",
       "  0.4857744107744108,\n",
       "  0.5059440559440559,\n",
       "  0.5267558528428093,\n",
       "  0.4752203389830508,\n",
       "  0.5022525597269625,\n",
       "  0.5269387755102041,\n",
       "  0.5065656565656566,\n",
       "  0.5244798657718122,\n",
       "  0.5273639455782313,\n",
       "  0.477054794520548,\n",
       "  0.516418918918919,\n",
       "  0.48431438127090304,\n",
       "  0.4722881355932203,\n",
       "  0.5008080808080807,\n",
       "  0.4806333333333333,\n",
       "  0.4751190476190476,\n",
       "  0.5422895622895623,\n",
       "  0.49102040816326525,\n",
       "  0.4285785953177258,\n",
       "  0.5219732441471572,\n",
       "  0.5090133779264214,\n",
       "  0.49775510204081624,\n",
       "  0.5395101351351351,\n",
       "  0.5021070234113713,\n",
       "  0.48320469798657717,\n",
       "  0.49373333333333336,\n",
       "  0.5245973154362416,\n",
       "  0.5065306122448979,\n",
       "  0.4866053511705686,\n",
       "  0.5033445945945946,\n",
       "  0.5108361204013379,\n",
       "  0.5176297577854673,\n",
       "  0.5236073825503357,\n",
       "  0.5211409395973154,\n",
       "  0.5044166666666666,\n",
       "  0.5055536912751678,\n",
       "  0.5391077441077441,\n",
       "  0.511,\n",
       "  0.4844612794612794,\n",
       "  0.5168918918918919,\n",
       "  0.4707666666666667,\n",
       "  0.5204833333333333,\n",
       "  0.49859531772575244,\n",
       "  0.5133783783783784,\n",
       "  0.49465870307167237,\n",
       "  0.4856711409395973,\n",
       "  0.5128983050847458,\n",
       "  0.4925850340136054,\n",
       "  0.5252920962199312,\n",
       "  0.47076013513513515,\n",
       "  0.5098829431438127,\n",
       "  0.5024149659863946,\n",
       "  0.5361815068493151,\n",
       "  0.4734395973154363,\n",
       "  0.5057046979865771,\n",
       "  0.4244485294117647,\n",
       "  0.5470234113712374,\n",
       "  0.5046632996632996,\n",
       "  0.4712121212121212,\n",
       "  0.5061371237458194,\n",
       "  0.48622033898305084,\n",
       "  0.5014527027027027,\n",
       "  0.47443333333333326,\n",
       "  0.5193000000000001,\n",
       "  0.4572727272727273,\n",
       "  0.4940169491525424,\n",
       "  0.5033848797250859,\n",
       "  0.49807692307692314,\n",
       "  0.532820945945946,\n",
       "  0.5001355932203391,\n",
       "  0.5158614864864864,\n",
       "  0.5269999999999999,\n",
       "  0.5028305084745762,\n",
       "  0.47905821917808217,\n",
       "  0.5033333333333333,\n",
       "  0.4568149466192171,\n",
       "  0.43301724137931036,\n",
       "  0.4910738255033557,\n",
       "  0.5180267558528427,\n",
       "  0.518344709897611,\n",
       "  0.5177926421404682,\n",
       "  0.5507118644067797,\n",
       "  0.5304745762711864,\n",
       "  0.5052203389830509,\n",
       "  0.511040268456376,\n",
       "  0.5288963210702341,\n",
       "  0.4862794612794613,\n",
       "  0.4635254237288136,\n",
       "  0.44205000000000005,\n",
       "  0.49891304347826093,\n",
       "  0.47840604026845635,\n",
       "  0.5328813559322033,\n",
       "  0.5041016949152543,\n",
       "  0.4958445945945945,\n",
       "  0.47544368600682596,\n",
       "  0.5136254295532646,\n",
       "  0.504777397260274,\n",
       "  0.4918518518518518,\n",
       "  0.46684563758389264,\n",
       "  0.5187244897959183,\n",
       "  0.5111604095563139,\n",
       "  0.5332935153583618,\n",
       "  0.4577364864864865,\n",
       "  0.5024581939799331,\n",
       "  0.5079166666666667,\n",
       "  0.5150522648083623,\n",
       "  0.47807823129251703,\n",
       "  0.529486301369863,\n",
       "  0.49113712374581936,\n",
       "  0.4567627118644068,\n",
       "  0.4941107382550336,\n",
       "  0.49351916376306626,\n",
       "  0.4590833333333333,\n",
       "  0.4997703180212014,\n",
       "  0.4890989399293287,\n",
       "  0.5022881355932203,\n",
       "  0.5276421404682273,\n",
       "  0.49222408026755854,\n",
       "  0.5349831081081081,\n",
       "  0.5023076923076923,\n",
       "  0.5441638795986622,\n",
       "  0.5502702702702702,\n",
       "  0.5106249999999999,\n",
       "  0.48918644067796613,\n",
       "  0.5054545454545455,\n",
       "  0.4861418685121107,\n",
       "  0.48671666666666674,\n",
       "  0.43735785953177253,\n",
       "  0.4874659863945578,\n",
       "  0.5445862068965518,\n",
       "  0.47905723905723896,\n",
       "  0.4972372881355932,\n",
       "  0.5029292929292929,\n",
       "  0.49998327759197325,\n",
       "  0.5207692307692309,\n",
       "  0.5533389261744966,\n",
       "  0.48964765100671137,\n",
       "  0.5256949152542373,\n",
       "  0.5125503355704698,\n",
       "  0.5421644295302014,\n",
       "  0.5117617449664429,\n",
       "  0.5245652173913044,\n",
       "  0.5114309764309765,\n",
       "  0.48478114478114476,\n",
       "  0.5278282828282828,\n",
       "  0.5322525597269625,\n",
       "  0.519515050167224,\n",
       "  0.5269899665551839,\n",
       "  0.4941052631578947,\n",
       "  0.5319087837837838,\n",
       "  0.46711678832116793,\n",
       "  0.47317725752508366,\n",
       "  0.4723489932885906,\n",
       "  0.45575250836120396,\n",
       "  0.5312627986348123,\n",
       "  0.544695945945946,\n",
       "  0.47598662207357856,\n",
       "  0.4825856164383561,\n",
       "  0.5260702341137125,\n",
       "  0.5293027210884355,\n",
       "  0.5192560553633218,\n",
       "  0.5073559322033898,\n",
       "  0.49983108108108104,\n",
       "  0.46470000000000006,\n",
       "  0.5182432432432431,\n",
       "  0.48535234899328855,\n",
       "  0.530685618729097,\n",
       "  0.5128282828282829,\n",
       "  0.5060738255033557,\n",
       "  0.48836148648648653,\n",
       "  0.47947986577181206,\n",
       "  0.5112627986348123,\n",
       "  0.5158445945945946,\n",
       "  0.4616161616161616,\n",
       "  0.46178929765886284,\n",
       "  0.5200841750841751,\n",
       "  0.46503389830508474,\n",
       "  0.4853010033444817,\n",
       "  0.47104895104895106,\n",
       "  0.46494932432432434,\n",
       "  0.508238255033557,\n",
       "  0.48895,\n",
       "  0.4941216216216216,\n",
       "  0.484074074074074,\n",
       "  0.5390909090909092,\n",
       "  0.5184615384615384,\n",
       "  0.47668896321070237,\n",
       "  0.5107744107744108,\n",
       "  0.5079292929292928,\n",
       "  0.5050847457627119,\n",
       "  0.5258445945945946,\n",
       "  0.46846666666666664,\n",
       "  0.4880882352941176,\n",
       "  0.49052013422818797,\n",
       "  0.4768896321070234,\n",
       "  0.5239491525423728,\n",
       "  0.4716835016835017,\n",
       "  0.48406666666666676,\n",
       "  0.5088006756756757,\n",
       "  0.49664406779661013,\n",
       "  0.5071333333333333,\n",
       "  0.4876510067114094,\n",
       "  0.5321571906354515,\n",
       "  0.5223702422145329,\n",
       "  0.5397068965517241,\n",
       "  0.5269230769230769,\n",
       "  0.51061872909699,\n",
       "  0.5047811447811449,\n",
       "  0.4623630136986301,\n",
       "  0.5393791946308725,\n",
       "  0.5488305084745764,\n",
       "  0.49396610169491534,\n",
       "  0.4937842465753426,\n",
       "  0.4656711409395973,\n",
       "  0.47915,\n",
       "  0.5151864406779662,\n",
       "  0.4604377104377104,\n",
       "  0.5482363013698629,\n",
       "  0.5147166666666667,\n",
       "  0.5025335570469799,\n",
       "  0.5366551724137931,\n",
       "  0.5127533783783784,\n",
       "  0.45782312925170077,\n",
       "  0.5057885906040268,\n",
       "  0.5198322147651008,\n",
       "  0.48991408934707903,\n",
       "  0.5341326530612245,\n",
       "  0.46883838383838383,\n",
       "  0.47844481605351175,\n",
       "  0.5000673400673401,\n",
       "  0.49079391891891894,\n",
       "  0.47068561872909703,\n",
       "  0.521470588235294,\n",
       "  0.5140169491525424,\n",
       "  0.48971666666666674,\n",
       "  0.4985284280936455,\n",
       "  0.5244276094276095,\n",
       "  0.5136394557823128,\n",
       "  0.4748983050847458,\n",
       "  0.5056313993174062,\n",
       "  0.4711744966442953,\n",
       "  0.5682823129251701,\n",
       "  0.5113682432432433,\n",
       "  0.5111301369863014,\n",
       "  0.4607020547945206,\n",
       "  0.5319718309859154,\n",
       "  0.52925,\n",
       "  0.509847972972973,\n",
       "  0.49274410774410776,\n",
       "  0.5072852233676977,\n",
       "  0.4908,\n",
       "  0.5282833333333333,\n",
       "  0.502043918918919,\n",
       "  0.5073905723905724,\n",
       "  0.5142567567567567,\n",
       "  0.5405218855218855,\n",
       "  0.5093389830508475,\n",
       "  0.5164982578397213,\n",
       "  0.46912751677852355,\n",
       "  0.49926174496644293,\n",
       "  0.4962671232876712,\n",
       "  0.4738541666666667,\n",
       "  0.48734006734006735,\n",
       "  0.5155723905723906,\n",
       "  0.513758389261745,\n",
       "  0.5248648648648649,\n",
       "  0.4797483221476509,\n",
       "  0.5009491525423729,\n",
       "  0.5255119453924915,\n",
       "  0.5242087542087542,\n",
       "  0.48484999999999995,\n",
       "  0.4944349315068493,\n",
       "  0.5065762711864407,\n",
       "  0.46496632996632997,\n",
       "  0.4655851063829788,\n",
       "  0.48636824324324324,\n",
       "  0.5266666666666666,\n",
       "  0.5223166666666667,\n",
       "  0.5463545150501672,\n",
       "  0.46756711409395973,\n",
       "  0.47024999999999995,\n",
       "  0.49373287671232874,\n",
       "  0.5003678929765887,\n",
       "  0.48435153583617746,\n",
       "  0.5676342281879194,\n",
       "  0.5036317567567568,\n",
       "  0.49146666666666666,\n",
       "  0.445580204778157,\n",
       "  0.46134228187919457,\n",
       "  0.4320508474576271,\n",
       "  0.5110544217687075,\n",
       "  0.524247491638796,\n",
       "  0.5144781144781145,\n",
       "  0.4817171717171717,\n",
       "  0.4948154362416108,\n",
       "  0.5450838926174497,\n",
       "  0.49725423728813556,\n",
       "  0.4996296296296296,\n",
       "  0.45115517241379305,\n",
       "  0.4594798657718121,\n",
       "  0.5305743243243244,\n",
       "  0.48308333333333325,\n",
       "  0.4538006756756756,\n",
       "  0.5262333333333333,\n",
       "  0.4679241877256318,\n",
       "  0.51919795221843,\n",
       "  0.4558474576271187,\n",
       "  0.46244107744107743,\n",
       "  0.46166666666666667,\n",
       "  0.5040301003344481,\n",
       "  0.4932996632996633,\n",
       "  0.4963006756756756,\n",
       "  0.5123728813559322,\n",
       "  0.48952702702702705,\n",
       "  0.5053754266211604,\n",
       "  0.50685,\n",
       "  0.494933110367893,\n",
       "  0.5333838383838384,\n",
       "  0.4736363636363637,\n",
       "  0.4923648648648649,\n",
       "  0.516986531986532,\n",
       "  0.5361204013377927,\n",
       "  0.5136678200692041,\n",
       "  0.4660570469798657,\n",
       "  0.5034175084175083,\n",
       "  0.48769230769230765,\n",
       "  0.556184668989547,\n",
       "  0.4950844594594594,\n",
       "  0.4598489932885907,\n",
       "  0.5189212328767124,\n",
       "  0.5070408163265306,\n",
       "  0.5457407407407406,\n",
       "  0.5272619047619048,\n",
       "  0.5277551020408163,\n",
       "  0.5314597315436241,\n",
       "  0.4981925675675676,\n",
       "  0.4681099656357388,\n",
       "  0.45033898305084746,\n",
       "  0.4665371621621622,\n",
       "  0.5250510204081633,\n",
       "  0.4561092150170648,\n",
       "  0.5267999999999999,\n",
       "  0.5318581081081082,\n",
       "  0.5201510067114093,\n",
       "  ...]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trainer._eval_save_prefix = OUTPUT_PREFIX + \"-test-pos-biased\"\n",
    "model_trainer._evaluate_partial(test_dataset_pos_biased)\n",
    "\n",
    "model_trainer._eval_save_prefix = OUTPUT_PREFIX +  \"-test-neg-biased\"\n",
    "model_trainer._evaluate_partial(test_dataset_neg_biased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unbiased Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2296/2296 [00:01<00:00, 1876.94it/s]\n",
      "100%|| 2296/2296 [00:02<00:00, 875.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AUC': [0.5372222222222223,\n",
       "  0.5269999999999999,\n",
       "  0.4658333333333333,\n",
       "  0.5077777777777778,\n",
       "  0.45333333333333337,\n",
       "  0.4457142857142857,\n",
       "  0.33,\n",
       "  0.6021428571428571,\n",
       "  0.441875,\n",
       "  0.4816666666666667,\n",
       "  0.44500000000000006,\n",
       "  0.4807142857142857,\n",
       "  0.5521428571428572,\n",
       "  0.423125,\n",
       "  0.45125000000000004,\n",
       "  0.5100000000000001,\n",
       "  0.4227777777777778,\n",
       "  0.5575,\n",
       "  0.53,\n",
       "  0.5722222222222222,\n",
       "  0.48375,\n",
       "  0.43749999999999994,\n",
       "  0.33222222222222225,\n",
       "  0.45125000000000004,\n",
       "  0.7581249999999999,\n",
       "  0.304375,\n",
       "  0.67,\n",
       "  0.555625,\n",
       "  0.42125,\n",
       "  0.5505555555555556,\n",
       "  0.2557142857142857,\n",
       "  0.5388888888888889,\n",
       "  0.445,\n",
       "  0.5011111111111111,\n",
       "  0.44555555555555554,\n",
       "  0.6007142857142858,\n",
       "  0.610625,\n",
       "  0.4033333333333333,\n",
       "  0.44777777777777783,\n",
       "  0.32642857142857146,\n",
       "  0.528125,\n",
       "  0.38375000000000004,\n",
       "  0.61,\n",
       "  0.6219999999999999,\n",
       "  0.4027777777777778,\n",
       "  0.473125,\n",
       "  0.6128571428571428,\n",
       "  0.3916666666666666,\n",
       "  0.5572222222222223,\n",
       "  0.40555555555555556,\n",
       "  0.5433333333333334,\n",
       "  0.499,\n",
       "  0.4725,\n",
       "  0.4211111111111111,\n",
       "  0.34944444444444445,\n",
       "  0.4971428571428572,\n",
       "  0.669375,\n",
       "  0.615,\n",
       "  0.48500000000000004,\n",
       "  0.4130000000000001,\n",
       "  0.5644444444444444,\n",
       "  0.67,\n",
       "  0.5022222222222221,\n",
       "  0.4942857142857143,\n",
       "  0.47111111111111104,\n",
       "  0.6616666666666666,\n",
       "  0.4605555555555556,\n",
       "  0.610625,\n",
       "  0.4,\n",
       "  0.5408333333333333,\n",
       "  0.5394444444444444,\n",
       "  0.46062500000000006,\n",
       "  0.4405555555555556,\n",
       "  0.31833333333333336,\n",
       "  0.35500000000000004,\n",
       "  0.47611111111111104,\n",
       "  0.42999999999999994,\n",
       "  0.5116666666666667,\n",
       "  0.5472222222222222,\n",
       "  0.48000000000000004,\n",
       "  0.49562500000000004,\n",
       "  0.5888888888888889,\n",
       "  0.3375,\n",
       "  0.33687500000000004,\n",
       "  0.5833333333333334,\n",
       "  0.5077777777777778,\n",
       "  0.41888888888888887,\n",
       "  0.53125,\n",
       "  0.528125,\n",
       "  0.45999999999999996,\n",
       "  0.5255555555555556,\n",
       "  0.535,\n",
       "  0.42,\n",
       "  0.5222222222222223,\n",
       "  0.6575000000000001,\n",
       "  0.43111111111111117,\n",
       "  0.42,\n",
       "  0.658888888888889,\n",
       "  0.43555555555555553,\n",
       "  0.4585714285714286,\n",
       "  0.369375,\n",
       "  0.4211111111111111,\n",
       "  0.44833333333333336,\n",
       "  0.4644444444444445,\n",
       "  0.5683333333333334,\n",
       "  0.5922222222222222,\n",
       "  0.49333333333333335,\n",
       "  0.425,\n",
       "  0.636875,\n",
       "  0.5942857142857143,\n",
       "  0.4588888888888889,\n",
       "  0.4794444444444444,\n",
       "  0.33,\n",
       "  0.42125,\n",
       "  0.47687500000000005,\n",
       "  0.578125,\n",
       "  0.405625,\n",
       "  0.48277777777777786,\n",
       "  0.5225,\n",
       "  0.35714285714285715,\n",
       "  0.31888888888888883,\n",
       "  0.5788888888888889,\n",
       "  0.5388888888888889,\n",
       "  0.506875,\n",
       "  0.5055555555555555,\n",
       "  0.4799999999999999,\n",
       "  0.435,\n",
       "  0.4222222222222223,\n",
       "  0.435625,\n",
       "  0.3892857142857143,\n",
       "  0.6566666666666667,\n",
       "  0.40625,\n",
       "  0.4161111111111111,\n",
       "  0.504375,\n",
       "  0.5237499999999999,\n",
       "  0.3927777777777777,\n",
       "  0.4383333333333333,\n",
       "  0.559375,\n",
       "  0.4744444444444444,\n",
       "  0.5733333333333333,\n",
       "  0.5127777777777778,\n",
       "  0.568888888888889,\n",
       "  0.544,\n",
       "  0.58,\n",
       "  0.44222222222222224,\n",
       "  0.30625,\n",
       "  0.5483333333333333,\n",
       "  0.4883333333333333,\n",
       "  0.34875,\n",
       "  0.4222222222222223,\n",
       "  0.6077777777777778,\n",
       "  0.4605555555555556,\n",
       "  0.453125,\n",
       "  0.43374999999999997,\n",
       "  0.5488888888888889,\n",
       "  0.40285714285714286,\n",
       "  0.4055555555555555,\n",
       "  0.3894444444444444,\n",
       "  0.44250000000000006,\n",
       "  0.3933333333333333,\n",
       "  0.3138888888888889,\n",
       "  0.5075,\n",
       "  0.4633333333333333,\n",
       "  0.42388888888888887,\n",
       "  0.4538888888888889,\n",
       "  0.59375,\n",
       "  0.5171428571428571,\n",
       "  0.23625000000000002,\n",
       "  0.55,\n",
       "  0.270625,\n",
       "  0.5066666666666667,\n",
       "  0.5177777777777778,\n",
       "  0.411875,\n",
       "  0.34555555555555556,\n",
       "  0.6627777777777778,\n",
       "  0.45714285714285713,\n",
       "  0.39375,\n",
       "  0.495,\n",
       "  0.5222222222222223,\n",
       "  0.5427777777777778,\n",
       "  0.445,\n",
       "  0.6025,\n",
       "  0.4628571428571429,\n",
       "  0.6028571428571429,\n",
       "  0.4671428571428571,\n",
       "  0.39722222222222225,\n",
       "  0.49888888888888894,\n",
       "  0.58625,\n",
       "  0.52,\n",
       "  0.6427777777777778,\n",
       "  0.5187499999999999,\n",
       "  0.4655555555555556,\n",
       "  0.31562500000000004,\n",
       "  0.41833333333333333,\n",
       "  0.40714285714285714,\n",
       "  0.5487500000000001,\n",
       "  0.4166666666666667,\n",
       "  0.45375,\n",
       "  0.3227777777777778,\n",
       "  0.75125,\n",
       "  0.43888888888888883,\n",
       "  0.56125,\n",
       "  0.39444444444444443,\n",
       "  0.685,\n",
       "  0.4838888888888888,\n",
       "  0.42571428571428577,\n",
       "  0.3116666666666667,\n",
       "  0.5172222222222222,\n",
       "  0.5338888888888889,\n",
       "  0.625,\n",
       "  0.5183333333333333,\n",
       "  0.47888888888888886,\n",
       "  0.4075,\n",
       "  0.5918749999999999,\n",
       "  0.5427777777777778,\n",
       "  0.525625,\n",
       "  0.49444444444444446,\n",
       "  0.5027777777777778,\n",
       "  0.4816666666666667,\n",
       "  0.45333333333333337,\n",
       "  0.41000000000000003,\n",
       "  0.46888888888888886,\n",
       "  0.4872222222222223,\n",
       "  0.6522222222222224,\n",
       "  0.5172222222222221,\n",
       "  0.32888888888888895,\n",
       "  0.6277777777777778,\n",
       "  0.5194444444444444,\n",
       "  0.30500000000000005,\n",
       "  0.43500000000000005,\n",
       "  0.32833333333333337,\n",
       "  0.30000000000000004,\n",
       "  0.3733333333333333,\n",
       "  0.6327777777777777,\n",
       "  0.4666666666666667,\n",
       "  0.6075,\n",
       "  0.34444444444444444,\n",
       "  0.2842857142857143,\n",
       "  0.5712499999999999,\n",
       "  0.5055555555555554,\n",
       "  0.54,\n",
       "  0.41777777777777775,\n",
       "  0.7866666666666666,\n",
       "  0.434375,\n",
       "  0.5094444444444446,\n",
       "  0.6478571428571429,\n",
       "  0.41777777777777775,\n",
       "  0.31285714285714283,\n",
       "  0.5275000000000001,\n",
       "  0.437,\n",
       "  0.44499999999999995,\n",
       "  0.6027777777777776,\n",
       "  0.5527777777777778,\n",
       "  0.4744444444444444,\n",
       "  0.5566666666666668,\n",
       "  0.6244444444444445,\n",
       "  0.5822222222222222,\n",
       "  0.37888888888888883,\n",
       "  0.5521428571428572,\n",
       "  0.4033333333333333,\n",
       "  0.41000000000000003,\n",
       "  0.5835714285714285,\n",
       "  0.4875,\n",
       "  0.4772222222222222,\n",
       "  0.4083333333333333,\n",
       "  0.5655555555555556,\n",
       "  0.3422222222222222,\n",
       "  0.415,\n",
       "  0.5327777777777778,\n",
       "  0.4855555555555556,\n",
       "  0.39375000000000004,\n",
       "  0.29055555555555557,\n",
       "  0.32833333333333337,\n",
       "  0.4514285714285714,\n",
       "  0.43666666666666676,\n",
       "  0.3885714285714286,\n",
       "  0.719375,\n",
       "  0.6938888888888889,\n",
       "  0.4822222222222222,\n",
       "  0.6666666666666666,\n",
       "  0.5606249999999999,\n",
       "  0.4527777777777778,\n",
       "  0.5027777777777778,\n",
       "  0.515625,\n",
       "  0.32,\n",
       "  0.4311111111111111,\n",
       "  0.5225,\n",
       "  0.47624999999999995,\n",
       "  0.44999999999999996,\n",
       "  0.4133333333333334,\n",
       "  0.44499999999999995,\n",
       "  0.43111111111111117,\n",
       "  0.46222222222222226,\n",
       "  0.42333333333333334,\n",
       "  0.651875,\n",
       "  0.40388888888888885,\n",
       "  0.33625,\n",
       "  0.6907142857142857,\n",
       "  0.6633333333333334,\n",
       "  0.546875,\n",
       "  0.4157142857142858,\n",
       "  0.5606249999999999,\n",
       "  0.49499999999999994,\n",
       "  0.6933333333333332,\n",
       "  0.47624999999999995,\n",
       "  0.551875,\n",
       "  0.425,\n",
       "  0.6433333333333334,\n",
       "  0.515625,\n",
       "  0.46916666666666673,\n",
       "  0.5861111111111111,\n",
       "  0.6335714285714286,\n",
       "  0.596875,\n",
       "  0.559375,\n",
       "  0.27444444444444444,\n",
       "  0.3194444444444444,\n",
       "  0.39875,\n",
       "  0.5761111111111111,\n",
       "  0.3872222222222222,\n",
       "  0.3655555555555556,\n",
       "  0.604375,\n",
       "  0.37111111111111117,\n",
       "  0.29,\n",
       "  0.5264285714285715,\n",
       "  0.4828571428571428,\n",
       "  0.3941666666666667,\n",
       "  0.42444444444444446,\n",
       "  0.41812499999999997,\n",
       "  0.674375,\n",
       "  0.445,\n",
       "  0.46222222222222226,\n",
       "  0.47388888888888897,\n",
       "  0.5244444444444445,\n",
       "  0.5988888888888888,\n",
       "  0.6261111111111111,\n",
       "  0.5135714285714286,\n",
       "  0.262,\n",
       "  0.5831249999999999,\n",
       "  0.4422222222222222,\n",
       "  0.4083333333333334,\n",
       "  0.7050000000000001,\n",
       "  0.495,\n",
       "  0.39785714285714285,\n",
       "  0.6708333333333334,\n",
       "  0.46444444444444444,\n",
       "  0.44857142857142857,\n",
       "  0.4372222222222222,\n",
       "  0.4961111111111111,\n",
       "  0.46916666666666673,\n",
       "  0.6133333333333333,\n",
       "  0.5825,\n",
       "  0.5766666666666667,\n",
       "  0.545,\n",
       "  0.33722222222222226,\n",
       "  0.5688888888888889,\n",
       "  0.41124999999999995,\n",
       "  0.4511111111111112,\n",
       "  0.4361111111111111,\n",
       "  0.5033333333333334,\n",
       "  0.31562500000000004,\n",
       "  0.36375,\n",
       "  0.5344444444444444,\n",
       "  0.727,\n",
       "  0.34611111111111115,\n",
       "  0.6933333333333332,\n",
       "  0.5137499999999999,\n",
       "  0.34611111111111115,\n",
       "  0.6266666666666667,\n",
       "  0.3357142857142857,\n",
       "  0.47500000000000003,\n",
       "  0.3611111111111111,\n",
       "  0.5622222222222223,\n",
       "  0.4194444444444445,\n",
       "  0.4494444444444444,\n",
       "  0.3692857142857143,\n",
       "  0.38187499999999996,\n",
       "  0.36777777777777776,\n",
       "  0.302,\n",
       "  0.3411111111111111,\n",
       "  0.48055555555555557,\n",
       "  0.5975,\n",
       "  0.446,\n",
       "  0.5505555555555556,\n",
       "  0.48277777777777775,\n",
       "  0.3588888888888888,\n",
       "  0.5125000000000001,\n",
       "  0.5938888888888889,\n",
       "  0.5211111111111112,\n",
       "  0.33166666666666667,\n",
       "  0.6725,\n",
       "  0.39666666666666667,\n",
       "  0.6050000000000001,\n",
       "  0.48125,\n",
       "  0.5,\n",
       "  0.420625,\n",
       "  0.5938888888888889,\n",
       "  0.43374999999999997,\n",
       "  0.4005555555555555,\n",
       "  0.6622222222222223,\n",
       "  0.5711111111111111,\n",
       "  0.3771428571428571,\n",
       "  0.5650000000000001,\n",
       "  0.4561111111111111,\n",
       "  0.34611111111111115,\n",
       "  0.401875,\n",
       "  0.5422222222222222,\n",
       "  0.5193749999999999,\n",
       "  0.454375,\n",
       "  0.40611111111111114,\n",
       "  0.5618750000000001,\n",
       "  0.33599999999999997,\n",
       "  0.45687500000000003,\n",
       "  0.4735714285714286,\n",
       "  0.5516666666666666,\n",
       "  0.5921428571428572,\n",
       "  0.4161111111111111,\n",
       "  0.4933333333333334,\n",
       "  0.5083333333333333,\n",
       "  0.5405555555555555,\n",
       "  0.44222222222222224,\n",
       "  0.5642857142857143,\n",
       "  0.5283333333333334,\n",
       "  0.6311111111111111,\n",
       "  0.4244444444444444,\n",
       "  0.4444444444444444,\n",
       "  0.4335714285714286,\n",
       "  0.5341666666666667,\n",
       "  0.39,\n",
       "  0.3977777777777778,\n",
       "  0.6428571428571429,\n",
       "  0.4692857142857143,\n",
       "  0.4433333333333333,\n",
       "  0.4066666666666667,\n",
       "  0.526875,\n",
       "  0.4316666666666667,\n",
       "  0.3794444444444445,\n",
       "  0.43285714285714294,\n",
       "  0.5308333333333334,\n",
       "  0.334375,\n",
       "  0.5555555555555556,\n",
       "  0.4288888888888889,\n",
       "  0.48928571428571427,\n",
       "  0.5525,\n",
       "  0.35250000000000004,\n",
       "  0.3266666666666667,\n",
       "  0.43,\n",
       "  0.36083333333333334,\n",
       "  0.5471428571428572,\n",
       "  0.6268750000000001,\n",
       "  0.4161111111111111,\n",
       "  0.43125,\n",
       "  0.4575,\n",
       "  0.41833333333333333,\n",
       "  0.441875,\n",
       "  0.375,\n",
       "  0.41444444444444445,\n",
       "  0.485625,\n",
       "  0.4961111111111111,\n",
       "  0.5,\n",
       "  0.4677777777777778,\n",
       "  0.5231250000000001,\n",
       "  0.38625,\n",
       "  0.43111111111111117,\n",
       "  0.42944444444444446,\n",
       "  0.4511111111111111,\n",
       "  0.41666666666666674,\n",
       "  0.44166666666666665,\n",
       "  0.485,\n",
       "  0.4716666666666667,\n",
       "  0.44250000000000006,\n",
       "  0.5544444444444445,\n",
       "  0.395,\n",
       "  0.45500000000000007,\n",
       "  0.3938888888888889,\n",
       "  0.4905555555555556,\n",
       "  0.4714285714285714,\n",
       "  0.48062499999999997,\n",
       "  0.496875,\n",
       "  0.5327777777777779,\n",
       "  0.5772222222222222,\n",
       "  0.4494444444444444,\n",
       "  0.4855555555555556,\n",
       "  0.57875,\n",
       "  0.441875,\n",
       "  0.34687500000000004,\n",
       "  0.6287499999999999,\n",
       "  0.47000000000000003,\n",
       "  0.18055555555555555,\n",
       "  0.6022222222222222,\n",
       "  0.322,\n",
       "  0.2966666666666667,\n",
       "  0.6187499999999999,\n",
       "  0.695,\n",
       "  0.5944444444444446,\n",
       "  0.375625,\n",
       "  0.505,\n",
       "  0.5018750000000001,\n",
       "  0.37777777777777777,\n",
       "  0.355625,\n",
       "  0.5444444444444445,\n",
       "  0.5733333333333334,\n",
       "  0.568125,\n",
       "  0.6900000000000001,\n",
       "  0.2416666666666667,\n",
       "  0.3711111111111111,\n",
       "  0.6083333333333333,\n",
       "  0.316875,\n",
       "  0.3383333333333334,\n",
       "  0.572857142857143,\n",
       "  0.5794444444444444,\n",
       "  0.6368750000000001,\n",
       "  0.5716666666666667,\n",
       "  0.4266666666666667,\n",
       "  0.4942857142857143,\n",
       "  0.49944444444444447,\n",
       "  0.42722222222222217,\n",
       "  0.44166666666666665,\n",
       "  0.4600000000000001,\n",
       "  0.7255555555555556,\n",
       "  0.34249999999999997,\n",
       "  0.39,\n",
       "  0.52,\n",
       "  0.38312500000000005,\n",
       "  0.565,\n",
       "  0.40055555555555555,\n",
       "  0.703125,\n",
       "  0.469375,\n",
       "  0.45562499999999995,\n",
       "  0.5411111111111111,\n",
       "  0.5905555555555556,\n",
       "  0.38166666666666665,\n",
       "  0.39875,\n",
       "  0.4627777777777778,\n",
       "  0.40388888888888885,\n",
       "  0.6507142857142857,\n",
       "  0.445,\n",
       "  0.525,\n",
       "  0.42250000000000004,\n",
       "  0.6305555555555555,\n",
       "  0.5288888888888889,\n",
       "  0.476,\n",
       "  0.4683333333333333,\n",
       "  0.3811111111111111,\n",
       "  0.4178571428571428,\n",
       "  0.6133333333333333,\n",
       "  0.4094444444444444,\n",
       "  0.3788888888888889,\n",
       "  0.39666666666666667,\n",
       "  0.5594444444444444,\n",
       "  0.31214285714285717,\n",
       "  0.46375000000000005,\n",
       "  0.29214285714285715,\n",
       "  0.59375,\n",
       "  0.5227777777777778,\n",
       "  0.015,\n",
       "  0.5418750000000001,\n",
       "  0.3572222222222222,\n",
       "  0.4028571428571429,\n",
       "  0.38888888888888895,\n",
       "  0.5072222222222222,\n",
       "  0.4666666666666667,\n",
       "  0.4066666666666667,\n",
       "  0.6666666666666666,\n",
       "  0.5925,\n",
       "  0.3394444444444445,\n",
       "  0.6122222222222222,\n",
       "  0.4999999999999999,\n",
       "  0.48285714285714276,\n",
       "  0.6528571428571429,\n",
       "  0.7270000000000001,\n",
       "  0.298,\n",
       "  0.5783333333333334,\n",
       "  0.5138888888888888,\n",
       "  0.49166666666666675,\n",
       "  0.7285714285714286,\n",
       "  0.514375,\n",
       "  0.521875,\n",
       "  0.3591666666666667,\n",
       "  0.5905555555555555,\n",
       "  0.365,\n",
       "  0.3794444444444445,\n",
       "  0.49944444444444447,\n",
       "  0.45062499999999994,\n",
       "  0.4605555555555555,\n",
       "  0.41125,\n",
       "  0.35833333333333334,\n",
       "  0.4407142857142857,\n",
       "  0.5172222222222221,\n",
       "  0.5777777777777777,\n",
       "  0.5655555555555556,\n",
       "  0.43,\n",
       "  0.713888888888889,\n",
       "  0.6188888888888889,\n",
       "  0.579375,\n",
       "  0.5266666666666667,\n",
       "  0.6507142857142857,\n",
       "  0.6594444444444444,\n",
       "  0.33499999999999996,\n",
       "  0.43722222222222223,\n",
       "  0.604375,\n",
       "  0.44777777777777783,\n",
       "  0.29928571428571427,\n",
       "  0.44833333333333336,\n",
       "  0.5021428571428572,\n",
       "  0.5127777777777777,\n",
       "  0.613125,\n",
       "  0.5855555555555555,\n",
       "  0.366875,\n",
       "  0.5155555555555555,\n",
       "  0.422,\n",
       "  0.3877777777777778,\n",
       "  0.6268750000000001,\n",
       "  0.4783333333333333,\n",
       "  0.4577777777777778,\n",
       "  0.4855555555555556,\n",
       "  0.5805555555555555,\n",
       "  0.49250000000000005,\n",
       "  0.5444444444444445,\n",
       "  0.4672222222222222,\n",
       "  0.45357142857142857,\n",
       "  0.6,\n",
       "  0.52875,\n",
       "  0.320625,\n",
       "  0.635,\n",
       "  0.545,\n",
       "  0.5933333333333333,\n",
       "  0.40875000000000006,\n",
       "  0.41437500000000005,\n",
       "  0.2638888888888889,\n",
       "  0.6122222222222222,\n",
       "  0.44166666666666665,\n",
       "  0.39375,\n",
       "  0.36944444444444446,\n",
       "  0.48374999999999996,\n",
       "  0.2966666666666667,\n",
       "  0.5614285714285714,\n",
       "  0.49444444444444446,\n",
       "  0.3877777777777778,\n",
       "  0.515,\n",
       "  0.42699999999999994,\n",
       "  0.506875,\n",
       "  0.6055555555555555,\n",
       "  0.3711111111111111,\n",
       "  0.4372222222222222,\n",
       "  0.3844444444444444,\n",
       "  0.4038888888888889,\n",
       "  0.303,\n",
       "  0.43222222222222223,\n",
       "  0.6212500000000001,\n",
       "  0.63,\n",
       "  0.41500000000000004,\n",
       "  0.519375,\n",
       "  0.5725,\n",
       "  0.4016666666666666,\n",
       "  0.4566666666666667,\n",
       "  0.5694444444444444,\n",
       "  0.3525,\n",
       "  0.405,\n",
       "  0.49888888888888894,\n",
       "  0.3383333333333333,\n",
       "  0.5605555555555556,\n",
       "  0.2671428571428572,\n",
       "  0.42857142857142866,\n",
       "  0.5022222222222222,\n",
       "  0.5194444444444444,\n",
       "  0.578125,\n",
       "  0.5,\n",
       "  0.4,\n",
       "  0.4033333333333333,\n",
       "  0.649375,\n",
       "  0.5133333333333333,\n",
       "  0.5827777777777777,\n",
       "  0.4972222222222222,\n",
       "  0.44562499999999994,\n",
       "  0.2627777777777778,\n",
       "  0.4538888888888888,\n",
       "  0.29833333333333334,\n",
       "  0.3338888888888889,\n",
       "  0.45562500000000006,\n",
       "  0.6272222222222222,\n",
       "  0.40055555555555555,\n",
       "  0.4633333333333333,\n",
       "  0.41875000000000007,\n",
       "  0.2671428571428572,\n",
       "  0.6511111111111111,\n",
       "  0.7324999999999999,\n",
       "  0.48277777777777775,\n",
       "  0.39437500000000003,\n",
       "  0.38722222222222225,\n",
       "  0.41888888888888887,\n",
       "  0.5622222222222223,\n",
       "  0.35888888888888887,\n",
       "  0.5142857142857143,\n",
       "  0.3688888888888889,\n",
       "  0.30111111111111116,\n",
       "  0.514375,\n",
       "  0.4977777777777777,\n",
       "  0.6944444444444443,\n",
       "  0.668888888888889,\n",
       "  0.42388888888888887,\n",
       "  0.41,\n",
       "  0.29312499999999997,\n",
       "  0.5549999999999999,\n",
       "  0.36444444444444446,\n",
       "  0.45499999999999996,\n",
       "  0.51875,\n",
       "  0.48944444444444446,\n",
       "  0.56875,\n",
       "  0.438125,\n",
       "  0.435,\n",
       "  0.6425,\n",
       "  0.3464285714285714,\n",
       "  0.6383333333333333,\n",
       "  0.39055555555555554,\n",
       "  0.41750000000000004,\n",
       "  0.33944444444444444,\n",
       "  0.48124999999999996,\n",
       "  0.5975,\n",
       "  0.365625,\n",
       "  0.5266666666666667,\n",
       "  0.505625,\n",
       "  0.45611111111111113,\n",
       "  0.5383333333333333,\n",
       "  0.515,\n",
       "  0.49249999999999994,\n",
       "  0.6471428571428571,\n",
       "  0.7142857142857143,\n",
       "  0.43944444444444447,\n",
       "  0.338125,\n",
       "  0.26937500000000003,\n",
       "  0.55,\n",
       "  0.429375,\n",
       "  0.46499999999999997,\n",
       "  0.5444444444444445,\n",
       "  0.3464285714285714,\n",
       "  0.48071428571428576,\n",
       "  0.544375,\n",
       "  0.6283333333333334,\n",
       "  0.4692857142857143,\n",
       "  0.5127777777777778,\n",
       "  0.44571428571428573,\n",
       "  0.4107142857142857,\n",
       "  0.4355555555555556,\n",
       "  0.326,\n",
       "  0.5927777777777777,\n",
       "  0.48055555555555557,\n",
       "  0.49444444444444435,\n",
       "  0.6911111111111111,\n",
       "  0.45000000000000007,\n",
       "  0.611111111111111,\n",
       "  0.43000000000000005,\n",
       "  0.43142857142857144,\n",
       "  0.38125,\n",
       "  0.4861111111111111,\n",
       "  0.2872222222222222,\n",
       "  0.5018750000000001,\n",
       "  0.4871428571428571,\n",
       "  0.41833333333333345,\n",
       "  0.4857142857142857,\n",
       "  0.31722222222222224,\n",
       "  0.6255555555555556,\n",
       "  0.4361111111111111,\n",
       "  0.3288888888888889,\n",
       "  0.396875,\n",
       "  0.4722222222222222,\n",
       "  0.5405555555555557,\n",
       "  0.5005555555555555,\n",
       "  0.3842857142857143,\n",
       "  0.6133333333333334,\n",
       "  0.5142857142857143,\n",
       "  0.438125,\n",
       "  0.5766666666666667,\n",
       "  0.6141666666666667,\n",
       "  0.524375,\n",
       "  0.49642857142857144,\n",
       "  0.5021428571428571,\n",
       "  0.47611111111111115,\n",
       "  0.3,\n",
       "  0.48062499999999997,\n",
       "  0.528888888888889,\n",
       "  0.36812500000000004,\n",
       "  0.5011111111111112,\n",
       "  0.36388888888888893,\n",
       "  0.34944444444444445,\n",
       "  0.315,\n",
       "  0.333125,\n",
       "  0.39055555555555554,\n",
       "  0.5477777777777777,\n",
       "  0.34687500000000004,\n",
       "  0.4905555555555556,\n",
       "  0.7461111111111111,\n",
       "  0.5311111111111111,\n",
       "  0.446875,\n",
       "  0.49944444444444447,\n",
       "  0.53125,\n",
       "  0.41277777777777774,\n",
       "  0.39625,\n",
       "  0.57,\n",
       "  0.395625,\n",
       "  0.46,\n",
       "  0.48888888888888893,\n",
       "  0.35,\n",
       "  0.5377777777777778,\n",
       "  0.49222222222222217,\n",
       "  0.5,\n",
       "  0.48624999999999996,\n",
       "  0.358125,\n",
       "  0.36400000000000005,\n",
       "  0.3061111111111111,\n",
       "  0.3961111111111111,\n",
       "  0.38749999999999996,\n",
       "  0.6443749999999999,\n",
       "  0.41857142857142865,\n",
       "  0.49,\n",
       "  0.3992857142857143,\n",
       "  0.5075,\n",
       "  0.57,\n",
       "  0.6177777777777779,\n",
       "  0.5711111111111111,\n",
       "  0.3561111111111111,\n",
       "  0.44166666666666665,\n",
       "  0.5671428571428571,\n",
       "  0.2327777777777778,\n",
       "  0.39571428571428563,\n",
       "  0.5271428571428572,\n",
       "  0.27499999999999997,\n",
       "  0.20214285714285715,\n",
       "  0.50375,\n",
       "  0.5677777777777777,\n",
       "  0.389375,\n",
       "  0.46611111111111114,\n",
       "  0.5621428571428572,\n",
       "  0.52625,\n",
       "  0.38571428571428573,\n",
       "  0.4672222222222222,\n",
       "  0.43777777777777777,\n",
       "  0.43600000000000005,\n",
       "  0.7611111111111111,\n",
       "  0.53125,\n",
       "  0.5974999999999999,\n",
       "  0.414375,\n",
       "  0.426875,\n",
       "  0.4961111111111111,\n",
       "  0.5683333333333332,\n",
       "  0.4749999999999999,\n",
       "  0.30999999999999994,\n",
       "  0.313125,\n",
       "  0.5183333333333333,\n",
       "  0.46611111111111114,\n",
       "  0.60125,\n",
       "  0.49071428571428566,\n",
       "  0.3528571428571428,\n",
       "  0.47500000000000003,\n",
       "  0.35055555555555556,\n",
       "  0.45222222222222214,\n",
       "  0.581875,\n",
       "  0.5227777777777778,\n",
       "  0.48055555555555557,\n",
       "  0.5216666666666667,\n",
       "  0.565625,\n",
       "  0.5027777777777778,\n",
       "  0.3,\n",
       "  0.4625,\n",
       "  0.3772222222222222,\n",
       "  0.6475000000000001,\n",
       "  0.5418749999999999,\n",
       "  0.6294444444444444,\n",
       "  0.31437499999999996,\n",
       "  0.4912500000000001,\n",
       "  0.2571428571428572,\n",
       "  0.524375,\n",
       "  0.6358333333333334,\n",
       "  0.49555555555555547,\n",
       "  0.5706249999999999,\n",
       "  0.6735714285714286,\n",
       "  0.5828571428571429,\n",
       "  0.50125,\n",
       "  0.3757142857142857,\n",
       "  0.5633333333333334,\n",
       "  0.45375,\n",
       "  0.6416666666666666,\n",
       "  0.45099999999999996,\n",
       "  0.5457142857142857,\n",
       "  0.6622222222222222,\n",
       "  0.6187499999999999,\n",
       "  0.40750000000000003,\n",
       "  0.5738888888888888,\n",
       "  0.5455555555555556,\n",
       "  0.6022222222222223,\n",
       "  0.5416666666666666,\n",
       "  0.61375,\n",
       "  0.49888888888888894,\n",
       "  0.44,\n",
       "  0.47,\n",
       "  0.6077777777777779,\n",
       "  0.41111111111111115,\n",
       "  0.435,\n",
       "  0.515,\n",
       "  0.3566666666666667,\n",
       "  0.39222222222222225,\n",
       "  0.3238888888888889,\n",
       "  0.42055555555555557,\n",
       "  0.5183333333333333,\n",
       "  0.5083333333333333,\n",
       "  0.33,\n",
       "  0.23857142857142857,\n",
       "  0.3722222222222223,\n",
       "  0.5622222222222222,\n",
       "  0.605,\n",
       "  0.32714285714285724,\n",
       "  0.48062499999999997,\n",
       "  0.333125,\n",
       "  0.470625,\n",
       "  0.30642857142857144,\n",
       "  0.33666666666666667,\n",
       "  0.415,\n",
       "  0.29277777777777775,\n",
       "  0.4744444444444445,\n",
       "  0.5938888888888889,\n",
       "  0.415,\n",
       "  0.4238888888888888,\n",
       "  0.4458333333333333,\n",
       "  0.5172222222222222,\n",
       "  0.48888888888888893,\n",
       "  0.3988888888888889,\n",
       "  0.5442857142857143,\n",
       "  0.6711111111111111,\n",
       "  0.4633333333333333,\n",
       "  0.5655555555555556,\n",
       "  0.483125,\n",
       "  0.5625,\n",
       "  0.303125,\n",
       "  0.6166666666666667,\n",
       "  0.38833333333333336,\n",
       "  0.3738888888888889,\n",
       "  0.1988888888888889,\n",
       "  0.511875,\n",
       "  0.5116666666666666,\n",
       "  0.6655555555555555,\n",
       "  0.44142857142857145,\n",
       "  0.515,\n",
       "  0.4655555555555555,\n",
       "  0.47555555555555556,\n",
       "  0.27071428571428574,\n",
       "  0.43374999999999997,\n",
       "  0.5108333333333334,\n",
       "  0.6005555555555556,\n",
       "  0.5272222222222221,\n",
       "  0.541111111111111,\n",
       "  0.5394444444444445,\n",
       "  0.3775,\n",
       "  0.4855555555555557,\n",
       "  0.39222222222222225,\n",
       "  0.5161111111111112,\n",
       "  0.47625000000000006,\n",
       "  0.5416666666666666,\n",
       "  0.3392857142857143,\n",
       "  0.47000000000000003,\n",
       "  0.40625,\n",
       "  0.5988888888888888,\n",
       "  0.5875,\n",
       "  0.5825,\n",
       "  0.361875,\n",
       "  0.57,\n",
       "  0.514,\n",
       "  0.4721428571428571,\n",
       "  0.31937499999999996,\n",
       "  0.5544444444444445,\n",
       "  0.6275,\n",
       "  0.5231250000000001,\n",
       "  0.3633333333333333,\n",
       "  0.38666666666666666,\n",
       "  0.6814285714285715,\n",
       "  0.5755555555555555,\n",
       "  0.41125,\n",
       "  0.5235714285714286,\n",
       "  0.6400000000000001,\n",
       "  0.43444444444444447,\n",
       "  0.37722222222222235,\n",
       "  0.6222222222222222,\n",
       "  0.48142857142857143,\n",
       "  0.49624999999999997,\n",
       "  0.45499999999999996,\n",
       "  0.245,\n",
       "  0.45142857142857146,\n",
       "  0.505,\n",
       "  0.4225,\n",
       "  0.4961111111111111,\n",
       "  0.518,\n",
       "  0.3875,\n",
       "  0.5622222222222222,\n",
       "  0.48500000000000004,\n",
       "  0.515625,\n",
       "  0.5535714285714285,\n",
       "  0.4016666666666666,\n",
       "  0.6807142857142857,\n",
       "  0.44222222222222224,\n",
       "  0.6157142857142857,\n",
       "  0.48,\n",
       "  0.65,\n",
       "  ...]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trainer._eval_save_prefix = OUTPUT_PREFIX + \"-test-pos-unbiased\"\n",
    "model_trainer._evaluate_partial(test_dataset_pos_unbiased)\n",
    "\n",
    "model_trainer._eval_save_prefix = OUTPUT_PREFIX +  \"-test-neg-unbiased\"\n",
    "model_trainer._evaluate_partial(test_dataset_neg_unbiased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calclate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "biased_results = dict()\n",
    "\n",
    "biased_results[\"STRATIFIED\"] = stratified(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", folder_name+\"training_arr.npy\", gamma=1.5, K=30)\n",
    "biased_results[\"AOA\"] = aoa(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", folder_name+\"training_arr.npy\", K=30)\n",
    "biased_results[\"UB_15\"] = eq(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", folder_name+\"training_arr.npy\", gamma=1.5, K=30)\n",
    "biased_results[\"UB_2\"] =  eq(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", folder_name+\"training_arr.npy\", gamma=2, K=30)\n",
    "biased_results[\"UB_25\"] =  eq(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", folder_name+\"training_arr.npy\", gamma=2.5, K=30)\n",
    "biased_results[\"UB_3\"] =  eq(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", folder_name+\"training_arr.npy\", gamma=3, K=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "unbiased_results = dict()\n",
    "\n",
    "unbiased_results[\"STRATIFIED\"] = stratified(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", folder_name+\"training_arr.npy\", gamma=1.5, K=1)\n",
    "unbiased_results[\"AOA\"] = aoa(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", folder_name+\"training_arr.npy\", K=1)\n",
    "unbiased_results[\"UB_15\"] = eq(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", folder_name+\"training_arr.npy\", gamma=1.5, K=1)\n",
    "unbiased_results[\"UB_2\"] =  eq(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", folder_name+\"training_arr.npy\", gamma=2, K=1)\n",
    "unbiased_results[\"UB_25\"] =  eq(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", folder_name+\"training_arr.npy\", gamma=2.5, K=1)\n",
    "unbiased_results[\"UB_3\"] =  eq(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", folder_name+\"training_arr.npy\", gamma=3, K=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, value = random.choice(list(biased_results.items()))\n",
    "rows = len(list(value.keys()))\n",
    "columns = len(list(biased_results.items()))\n",
    "results_array = np.zeros((rows,columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_results = dict()\n",
    "\n",
    "list_biased_res = list(biased_results.keys())\n",
    "\n",
    "for i in range(len(list_biased_res)):\n",
    "    key = list_biased_res[i]\n",
    "\n",
    "    for j in range(len(list(biased_results[key].keys()))):\n",
    "        key_2 = list(biased_results[key].keys())[j]\n",
    "\n",
    "        results_array[j][i] = abs(biased_results[key][key_2] - unbiased_results[key][key_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35801915, 0.15199769, 0.12589556, 0.12254338, 0.11997702,\n",
       "        0.11800523],\n",
       "       [0.81875698, 0.38207103, 0.26575325, 0.25441333, 0.24601522,\n",
       "        0.23973634]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_df = pd.DataFrame(columns=list(biased_results.keys()), data=results_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_values = list(biased_results[list(biased_results.keys())[0]].keys())\n",
    "mae_df.insert(0, \"metric\", metric_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Showing the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>STRATIFIED</th>\n",
       "      <th>AOA</th>\n",
       "      <th>UB_15</th>\n",
       "      <th>UB_2</th>\n",
       "      <th>UB_25</th>\n",
       "      <th>UB_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.358019</td>\n",
       "      <td>0.151998</td>\n",
       "      <td>0.125896</td>\n",
       "      <td>0.122543</td>\n",
       "      <td>0.119977</td>\n",
       "      <td>0.118005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.818757</td>\n",
       "      <td>0.382071</td>\n",
       "      <td>0.265753</td>\n",
       "      <td>0.254413</td>\n",
       "      <td>0.246015</td>\n",
       "      <td>0.239736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   metric  STRATIFIED       AOA     UB_15      UB_2     UB_25      UB_3\n",
       "0     auc    0.358019  0.151998  0.125896  0.122543  0.119977  0.118005\n",
       "1  recall    0.818757  0.382071  0.265753  0.254413  0.246015  0.239736"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecSysEvaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
