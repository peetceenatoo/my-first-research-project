{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IMPORT LIBS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from openrec.tf1.legacy import ImplicitModelTrainer\n",
    "from openrec.tf1.legacy.utils.evaluators import ImplicitEvalManager\n",
    "from openrec.tf1.legacy.utils import ImplicitDataset\n",
    "from openrec.tf1.legacy.recommenders import CML, BPR, PMF\n",
    "from openrec.tf1.legacy.utils.evaluators import AUC\n",
    "from openrec.tf1.legacy.utils.samplers import PairwiseSampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "import os\n",
    "import pickle\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GENERATE THE DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2384795\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "output_name = f\"./generated_data/\"\n",
    "folder_name = f\"./original_files/\"\n",
    "\n",
    "if os.path.exists(output_name) == False:\n",
    "    os.makedirs(output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>play_duration</th>\n",
       "      <th>video_duration</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>watch_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3649</td>\n",
       "      <td>13838</td>\n",
       "      <td>10867</td>\n",
       "      <td>2020-07-05 00:08:23.438</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593879e+09</td>\n",
       "      <td>1.273397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>9598</td>\n",
       "      <td>13665</td>\n",
       "      <td>10984</td>\n",
       "      <td>2020-07-05 00:13:41.297</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593879e+09</td>\n",
       "      <td>1.244082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5262</td>\n",
       "      <td>851</td>\n",
       "      <td>7908</td>\n",
       "      <td>2020-07-05 00:16:06.687</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593879e+09</td>\n",
       "      <td>0.107613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1963</td>\n",
       "      <td>862</td>\n",
       "      <td>9590</td>\n",
       "      <td>2020-07-05 00:20:26.792</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593880e+09</td>\n",
       "      <td>0.089885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8234</td>\n",
       "      <td>858</td>\n",
       "      <td>11000</td>\n",
       "      <td>2020-07-05 00:43:05.128</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593881e+09</td>\n",
       "      <td>0.078000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>8228</td>\n",
       "      <td>13484</td>\n",
       "      <td>8576</td>\n",
       "      <td>2020-07-05 01:00:25.5</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593882e+09</td>\n",
       "      <td>1.572295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>6789</td>\n",
       "      <td>2327</td>\n",
       "      <td>13267</td>\n",
       "      <td>2020-07-05 03:28:02.32</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593891e+09</td>\n",
       "      <td>0.175398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>6812</td>\n",
       "      <td>23731</td>\n",
       "      <td>10728</td>\n",
       "      <td>2020-07-05 22:22:11.813</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593959e+09</td>\n",
       "      <td>2.212062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>796</td>\n",
       "      <td>6100</td>\n",
       "      <td>2020-07-06 00:14:06.245</td>\n",
       "      <td>20200706</td>\n",
       "      <td>1.593966e+09</td>\n",
       "      <td>0.130492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>13735</td>\n",
       "      <td>9767</td>\n",
       "      <td>2020-07-06 00:14:48.8</td>\n",
       "      <td>20200706</td>\n",
       "      <td>1.593966e+09</td>\n",
       "      <td>1.406266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  video_id  play_duration  video_duration                     time  \\\n",
       "0        0      3649          13838           10867  2020-07-05 00:08:23.438   \n",
       "1        0      9598          13665           10984  2020-07-05 00:13:41.297   \n",
       "2        0      5262            851            7908  2020-07-05 00:16:06.687   \n",
       "3        0      1963            862            9590  2020-07-05 00:20:26.792   \n",
       "4        0      8234            858           11000  2020-07-05 00:43:05.128   \n",
       "5        0      8228          13484            8576    2020-07-05 01:00:25.5   \n",
       "6        0      6789           2327           13267   2020-07-05 03:28:02.32   \n",
       "7        0      6812          23731           10728  2020-07-05 22:22:11.813   \n",
       "8        0       183            796            6100  2020-07-06 00:14:06.245   \n",
       "9        0       169          13735            9767    2020-07-06 00:14:48.8   \n",
       "\n",
       "       date     timestamp  watch_ratio  \n",
       "0  20200705  1.593879e+09     1.273397  \n",
       "1  20200705  1.593879e+09     1.244082  \n",
       "2  20200705  1.593879e+09     0.107613  \n",
       "3  20200705  1.593880e+09     0.089885  \n",
       "4  20200705  1.593881e+09     0.078000  \n",
       "5  20200705  1.593882e+09     1.572295  \n",
       "6  20200705  1.593891e+09     0.175398  \n",
       "7  20200705  1.593959e+09     2.212062  \n",
       "8  20200706  1.593966e+09     0.130492  \n",
       "9  20200706  1.593966e+09     1.406266  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'big_matrix.csv'\n",
    "# Load the training set into a DataFrame\n",
    "df_train = pd.read_csv(folder_name+file_path) \n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"We treat items with a watch_ratio greater than or equal to 2 as relevant, and others as irrelevant, as suggested by KuaiRec.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>play_duration</th>\n",
       "      <th>video_duration</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>watch_ratio</th>\n",
       "      <th>ImplicitRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3649</td>\n",
       "      <td>13838</td>\n",
       "      <td>10867</td>\n",
       "      <td>2020-07-05 00:08:23.438</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593879e+09</td>\n",
       "      <td>1.273397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>9598</td>\n",
       "      <td>13665</td>\n",
       "      <td>10984</td>\n",
       "      <td>2020-07-05 00:13:41.297</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593879e+09</td>\n",
       "      <td>1.244082</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5262</td>\n",
       "      <td>851</td>\n",
       "      <td>7908</td>\n",
       "      <td>2020-07-05 00:16:06.687</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593879e+09</td>\n",
       "      <td>0.107613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1963</td>\n",
       "      <td>862</td>\n",
       "      <td>9590</td>\n",
       "      <td>2020-07-05 00:20:26.792</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593880e+09</td>\n",
       "      <td>0.089885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8234</td>\n",
       "      <td>858</td>\n",
       "      <td>11000</td>\n",
       "      <td>2020-07-05 00:43:05.128</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593881e+09</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>8228</td>\n",
       "      <td>13484</td>\n",
       "      <td>8576</td>\n",
       "      <td>2020-07-05 01:00:25.5</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593882e+09</td>\n",
       "      <td>1.572295</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>6789</td>\n",
       "      <td>2327</td>\n",
       "      <td>13267</td>\n",
       "      <td>2020-07-05 03:28:02.32</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593891e+09</td>\n",
       "      <td>0.175398</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>6812</td>\n",
       "      <td>23731</td>\n",
       "      <td>10728</td>\n",
       "      <td>2020-07-05 22:22:11.813</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593959e+09</td>\n",
       "      <td>2.212062</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>796</td>\n",
       "      <td>6100</td>\n",
       "      <td>2020-07-06 00:14:06.245</td>\n",
       "      <td>20200706</td>\n",
       "      <td>1.593966e+09</td>\n",
       "      <td>0.130492</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>13735</td>\n",
       "      <td>9767</td>\n",
       "      <td>2020-07-06 00:14:48.8</td>\n",
       "      <td>20200706</td>\n",
       "      <td>1.593966e+09</td>\n",
       "      <td>1.406266</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  video_id  play_duration  video_duration                     time  \\\n",
       "0        0      3649          13838           10867  2020-07-05 00:08:23.438   \n",
       "1        0      9598          13665           10984  2020-07-05 00:13:41.297   \n",
       "2        0      5262            851            7908  2020-07-05 00:16:06.687   \n",
       "3        0      1963            862            9590  2020-07-05 00:20:26.792   \n",
       "4        0      8234            858           11000  2020-07-05 00:43:05.128   \n",
       "5        0      8228          13484            8576    2020-07-05 01:00:25.5   \n",
       "6        0      6789           2327           13267   2020-07-05 03:28:02.32   \n",
       "7        0      6812          23731           10728  2020-07-05 22:22:11.813   \n",
       "8        0       183            796            6100  2020-07-06 00:14:06.245   \n",
       "9        0       169          13735            9767    2020-07-06 00:14:48.8   \n",
       "\n",
       "       date     timestamp  watch_ratio  ImplicitRating  \n",
       "0  20200705  1.593879e+09     1.273397               0  \n",
       "1  20200705  1.593879e+09     1.244082               0  \n",
       "2  20200705  1.593879e+09     0.107613               0  \n",
       "3  20200705  1.593880e+09     0.089885               0  \n",
       "4  20200705  1.593881e+09     0.078000               0  \n",
       "5  20200705  1.593882e+09     1.572295               0  \n",
       "6  20200705  1.593891e+09     0.175398               0  \n",
       "7  20200705  1.593959e+09     2.212062               1  \n",
       "8  20200706  1.593966e+09     0.130492               0  \n",
       "9  20200706  1.593966e+09     1.406266               0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POSITIVE_THRESHOLD = 2.0 # Suggested on dataset webpage\n",
    "df_train['ImplicitRating'] = np.where(df_train['watch_ratio'] > POSITIVE_THRESHOLD, 1, 0)\n",
    "\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the number of users and items in the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The training set contains 12,530,806 ratings given by 7,176 users against 10,728 videos through natural interactions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10727, 7175)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_user = df_train[\"user_id\"].min()\n",
    "max_user = df_train[\"user_id\"].max()\n",
    "\n",
    "min_item = df_train[\"video_id\"].min()\n",
    "max_item = df_train[\"video_id\"].max()\n",
    "\n",
    "max_item, max_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GET UNBIASED TESTSET**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the unbiased testset and convert it to implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>play_duration</th>\n",
       "      <th>video_duration</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>watch_ratio</th>\n",
       "      <th>ImplicitRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>148</td>\n",
       "      <td>4381</td>\n",
       "      <td>6067</td>\n",
       "      <td>2020-07-05 05:27:48.378</td>\n",
       "      <td>20200705.0</td>\n",
       "      <td>1.593898e+09</td>\n",
       "      <td>0.722103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>183</td>\n",
       "      <td>11635</td>\n",
       "      <td>6100</td>\n",
       "      <td>2020-07-05 05:28:00.057</td>\n",
       "      <td>20200705.0</td>\n",
       "      <td>1.593898e+09</td>\n",
       "      <td>1.907377</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>3649</td>\n",
       "      <td>22422</td>\n",
       "      <td>10867</td>\n",
       "      <td>2020-07-05 05:29:09.479</td>\n",
       "      <td>20200705.0</td>\n",
       "      <td>1.593898e+09</td>\n",
       "      <td>2.063311</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>5262</td>\n",
       "      <td>4479</td>\n",
       "      <td>7908</td>\n",
       "      <td>2020-07-05 05:30:43.285</td>\n",
       "      <td>20200705.0</td>\n",
       "      <td>1.593898e+09</td>\n",
       "      <td>0.566388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>8234</td>\n",
       "      <td>4602</td>\n",
       "      <td>11000</td>\n",
       "      <td>2020-07-05 05:35:43.459</td>\n",
       "      <td>20200705.0</td>\n",
       "      <td>1.593899e+09</td>\n",
       "      <td>0.418364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>6789</td>\n",
       "      <td>8607</td>\n",
       "      <td>13267</td>\n",
       "      <td>2020-07-05 05:36:00.773</td>\n",
       "      <td>20200705.0</td>\n",
       "      <td>1.593899e+09</td>\n",
       "      <td>0.648753</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>1963</td>\n",
       "      <td>8613</td>\n",
       "      <td>9590</td>\n",
       "      <td>2020-07-05 05:36:47.741</td>\n",
       "      <td>20200705.0</td>\n",
       "      <td>1.593899e+09</td>\n",
       "      <td>0.898123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>175</td>\n",
       "      <td>11640</td>\n",
       "      <td>46514</td>\n",
       "      <td>2020-07-05 05:49:27.965</td>\n",
       "      <td>20200705.0</td>\n",
       "      <td>1.593899e+09</td>\n",
       "      <td>0.250247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>1973</td>\n",
       "      <td>4572</td>\n",
       "      <td>7400</td>\n",
       "      <td>2020-07-05 05:49:41.762</td>\n",
       "      <td>20200705.0</td>\n",
       "      <td>1.593899e+09</td>\n",
       "      <td>0.617838</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>171</td>\n",
       "      <td>8518</td>\n",
       "      <td>5217</td>\n",
       "      <td>2020-07-05 05:57:26.581</td>\n",
       "      <td>20200705.0</td>\n",
       "      <td>1.593900e+09</td>\n",
       "      <td>1.632739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  video_id  play_duration  video_duration                     time  \\\n",
       "0       14       148           4381            6067  2020-07-05 05:27:48.378   \n",
       "1       14       183          11635            6100  2020-07-05 05:28:00.057   \n",
       "2       14      3649          22422           10867  2020-07-05 05:29:09.479   \n",
       "3       14      5262           4479            7908  2020-07-05 05:30:43.285   \n",
       "4       14      8234           4602           11000  2020-07-05 05:35:43.459   \n",
       "5       14      6789           8607           13267  2020-07-05 05:36:00.773   \n",
       "6       14      1963           8613            9590  2020-07-05 05:36:47.741   \n",
       "7       14       175          11640           46514  2020-07-05 05:49:27.965   \n",
       "8       14      1973           4572            7400  2020-07-05 05:49:41.762   \n",
       "9       14       171           8518            5217  2020-07-05 05:57:26.581   \n",
       "\n",
       "         date     timestamp  watch_ratio  ImplicitRating  \n",
       "0  20200705.0  1.593898e+09     0.722103               0  \n",
       "1  20200705.0  1.593898e+09     1.907377               0  \n",
       "2  20200705.0  1.593898e+09     2.063311               1  \n",
       "3  20200705.0  1.593898e+09     0.566388               0  \n",
       "4  20200705.0  1.593899e+09     0.418364               0  \n",
       "5  20200705.0  1.593899e+09     0.648753               0  \n",
       "6  20200705.0  1.593899e+09     0.898123               0  \n",
       "7  20200705.0  1.593899e+09     0.250247               0  \n",
       "8  20200705.0  1.593899e+09     0.617838               0  \n",
       "9  20200705.0  1.593900e+09     1.632739               0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = folder_name + 'small_matrix.csv'\n",
    "df_test = pd.read_csv(file_path)  # sep='\\t' for tab-separated values\n",
    "df_test['ImplicitRating'] = np.where(df_test['watch_ratio'] > POSITIVE_THRESHOLD, 1, 0)\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the number of users and items in the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The testing set is collected by asking a subset of 1,411 users to rate 3,327 randomly selected songs.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1411, 3327, 0.9962024941648523)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['user_id'].unique().shape[0] , df_test[\"video_id\"].unique().shape[0], df_test.shape[0] / (df_test['user_id'].unique().shape[0] * df_test[\"video_id\"].unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape the unbiased test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the dataframe, for each row where ImplicitRating is 1, append [userID, itemID] to unbiased_pos_test_set\n",
    "# and for each row where ImplicitRating is 0, append [userID, itemID] to unbiased_neg_test_set\n",
    "\n",
    "unbiased_pos_test_set = df_test[df_test[\"ImplicitRating\"] == 1][[\"user_id\", \"video_id\"]].values\n",
    "unbiased_neg_test_set = df_test[df_test[\"ImplicitRating\"] == 0][[\"user_id\", \"video_id\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save unbiased test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unbiased_pos_test_set_df = pd.DataFrame(unbiased_pos_test_set)\n",
    "unbiased_neg_test_set_df = pd.DataFrame(unbiased_neg_test_set)\n",
    "\n",
    "unbiased_pos_test_set_df.columns = [\"user_id\",\"item_id\"]\n",
    "unbiased_neg_test_set_df.columns = [\"user_id\",\"item_id\"]\n",
    "\n",
    "structured_data_pos_test_set_unbiased = unbiased_pos_test_set_df.to_records(index=False)\n",
    "structured_data_neg_test_set_unbiased = unbiased_neg_test_set_df.to_records(index=False)\n",
    "\n",
    "np.save(output_name + \"unbiased-test_arr_pos.npy\", structured_data_pos_test_set_unbiased)\n",
    "np.save(output_name + \"unbiased-test_arr_neg.npy\", structured_data_neg_test_set_unbiased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GET BIASED TESTSET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>play_duration</th>\n",
       "      <th>video_duration</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>watch_ratio</th>\n",
       "      <th>ImplicitRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3649</td>\n",
       "      <td>13838</td>\n",
       "      <td>10867</td>\n",
       "      <td>2020-07-05 00:08:23.438</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593879e+09</td>\n",
       "      <td>1.273397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>9598</td>\n",
       "      <td>13665</td>\n",
       "      <td>10984</td>\n",
       "      <td>2020-07-05 00:13:41.297</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593879e+09</td>\n",
       "      <td>1.244082</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5262</td>\n",
       "      <td>851</td>\n",
       "      <td>7908</td>\n",
       "      <td>2020-07-05 00:16:06.687</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593879e+09</td>\n",
       "      <td>0.107613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1963</td>\n",
       "      <td>862</td>\n",
       "      <td>9590</td>\n",
       "      <td>2020-07-05 00:20:26.792</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593880e+09</td>\n",
       "      <td>0.089885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8234</td>\n",
       "      <td>858</td>\n",
       "      <td>11000</td>\n",
       "      <td>2020-07-05 00:43:05.128</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593881e+09</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>8228</td>\n",
       "      <td>13484</td>\n",
       "      <td>8576</td>\n",
       "      <td>2020-07-05 01:00:25.5</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593882e+09</td>\n",
       "      <td>1.572295</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>6789</td>\n",
       "      <td>2327</td>\n",
       "      <td>13267</td>\n",
       "      <td>2020-07-05 03:28:02.32</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593891e+09</td>\n",
       "      <td>0.175398</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>6812</td>\n",
       "      <td>23731</td>\n",
       "      <td>10728</td>\n",
       "      <td>2020-07-05 22:22:11.813</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593959e+09</td>\n",
       "      <td>2.212062</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>796</td>\n",
       "      <td>6100</td>\n",
       "      <td>2020-07-06 00:14:06.245</td>\n",
       "      <td>20200706</td>\n",
       "      <td>1.593966e+09</td>\n",
       "      <td>0.130492</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>13735</td>\n",
       "      <td>9767</td>\n",
       "      <td>2020-07-06 00:14:48.8</td>\n",
       "      <td>20200706</td>\n",
       "      <td>1.593966e+09</td>\n",
       "      <td>1.406266</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  video_id  play_duration  video_duration                     time  \\\n",
       "0        0      3649          13838           10867  2020-07-05 00:08:23.438   \n",
       "1        0      9598          13665           10984  2020-07-05 00:13:41.297   \n",
       "2        0      5262            851            7908  2020-07-05 00:16:06.687   \n",
       "3        0      1963            862            9590  2020-07-05 00:20:26.792   \n",
       "4        0      8234            858           11000  2020-07-05 00:43:05.128   \n",
       "5        0      8228          13484            8576    2020-07-05 01:00:25.5   \n",
       "6        0      6789           2327           13267   2020-07-05 03:28:02.32   \n",
       "7        0      6812          23731           10728  2020-07-05 22:22:11.813   \n",
       "8        0       183            796            6100  2020-07-06 00:14:06.245   \n",
       "9        0       169          13735            9767    2020-07-06 00:14:48.8   \n",
       "\n",
       "       date     timestamp  watch_ratio  ImplicitRating  \n",
       "0  20200705  1.593879e+09     1.273397               0  \n",
       "1  20200705  1.593879e+09     1.244082               0  \n",
       "2  20200705  1.593879e+09     0.107613               0  \n",
       "3  20200705  1.593880e+09     0.089885               0  \n",
       "4  20200705  1.593881e+09     0.078000               0  \n",
       "5  20200705  1.593882e+09     1.572295               0  \n",
       "6  20200705  1.593891e+09     0.175398               0  \n",
       "7  20200705  1.593959e+09     2.212062               1  \n",
       "8  20200706  1.593966e+09     0.130492               0  \n",
       "9  20200706  1.593966e+09     1.406266               0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12530806 entries, 0 to 12530805\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   user_id         int64  \n",
      " 1   video_id        int64  \n",
      " 2   play_duration   int64  \n",
      " 3   video_duration  int64  \n",
      " 4   time            object \n",
      " 5   date            int64  \n",
      " 6   timestamp       float64\n",
      " 7   watch_ratio     float64\n",
      " 8   ImplicitRating  int64  \n",
      "dtypes: float64(2), int64(6), object(1)\n",
      "memory usage: 860.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the biased test set and shape it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"We additionally held out a biased testing set (biased-testing) from the training set by randomly sampling 30% songs for each user.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute, for each user, the list of songs with a relevant rating\n",
    "user_positive_ratings = df_train[df_train[\"ImplicitRating\"] == 1].groupby(\"user_id\")[\"video_id\"].apply(set)\n",
    "\n",
    "# Initialize the range of indexes for the items\n",
    "items_ids = np.arange(min_item, max_item + 1)\n",
    "# Set the number of songs for each user\n",
    "\n",
    "#Using 3576, that is the 30% of the items in the biased set, to achieve a similar ratio with the Yahoo's dataset\n",
    "SONGS_FOR_BIASED_TEST = 3576 \n",
    "\n",
    "pos_test_set = []\n",
    "neg_test_set = []\n",
    "\n",
    "for user_id in range(min_user, max_user + 1):\n",
    "    np.random.shuffle(items_ids)\n",
    "    test_items = set(items_ids[-SONGS_FOR_BIASED_TEST:])\n",
    "    pos_ids = user_positive_ratings.get(user_id, set()) & test_items\n",
    "\n",
    "    #set those to 0 so that they will no longer be used in training set\n",
    "    df_train.loc[(df_train['video_id'].isin(pos_ids)) & (df_train['user_id'] == user_id), 'ImplicitRating'] = 0\n",
    "\n",
    "    for id in test_items:\n",
    "        if id in pos_ids:\n",
    "            pos_test_set.append([user_id, id])\n",
    "        else:\n",
    "            neg_test_set.append([user_id, id])\n",
    "\n",
    "pos_test_set = np.array(pos_test_set)\n",
    "neg_test_set = np.array(neg_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the biased test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test_set_df = pd.DataFrame(pos_test_set)\n",
    "neg_test_set_df = pd.DataFrame(neg_test_set)\n",
    "\n",
    "pos_test_set_df.columns = [\"user_id\",\"item_id\"]\n",
    "neg_test_set_df.columns = [\"user_id\",\"item_id\"]\n",
    "\n",
    "structured_data_pos_test_set = pos_test_set_df.to_records(index=False)\n",
    "structured_data_neg_test_set = neg_test_set_df.to_records(index=False)\n",
    "\n",
    "np.save(output_name + \"biased-test_arr_pos.npy\", structured_data_pos_test_set)\n",
    "np.save(output_name + \"biased-test_arr_neg.npy\", structured_data_neg_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **STORE TRAINSET**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take couples user-item filtering out the irrelevant ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only take the couples (user, item) with relevant rating\n",
    "new_df = df_train[df_train['ImplicitRating'] != 0]\n",
    "new_df = new_df.drop(columns=['watch_ratio', 'ImplicitRating','play_duration','video_duration','time','date','timestamp'])\n",
    "\n",
    "# Define a dictionary for renaming columns\n",
    "rename_dict = {\n",
    "    'user_id': 'user_id',\n",
    "    'video_id': 'item_id'\n",
    "}\n",
    "\n",
    "# Rename the columns\n",
    "new_df = new_df.rename(columns=rename_dict)\n",
    "\n",
    "# Convert the DataFrame to a structured array\n",
    "structured_data = new_df.to_records(index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = structured_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(output_name + \"training_arr.npy\", train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MODEL CHOICE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = dict()\n",
    "raw_data['train_data'] = np.load(output_name + \"training_arr.npy\")\n",
    "raw_data['max_user'] = 7177\n",
    "raw_data['max_item'] = 10729\n",
    "batch_size = 8000\n",
    "test_batch_size = 1000\n",
    "display_itr = 1000\n",
    "\n",
    "train_dataset = ImplicitDataset(raw_data['train_data'], raw_data['max_user'], raw_data['max_item'], name='Train')\n",
    "\n",
    "MODEL_CLASS = CML\n",
    "MODEL_PREFIX = \"cml\"\n",
    "DATASET_NAME = \"KuaiRec\"\n",
    "OUTPUT_FOLDER = output_name\n",
    "OUTPUT_PATH = OUTPUT_FOLDER + MODEL_PREFIX + \"-\" + DATASET_NAME + \"/\"\n",
    "OUTPUT_PREFIX = str(OUTPUT_PATH) + str(MODEL_PREFIX) + \"-\" + str(DATASET_NAME)\n",
    "\n",
    "\n",
    "if os.path.exists(OUTPUT_PATH) == False:\n",
    "    os.makedirs(OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TRAIN THE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:391: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:31: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:41: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:43: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:33: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/interactions/pairwise_eu_dist.py:71: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:596: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:75: The name tf.scatter_update is deprecated. Please use tf.compat.v1.scatter_update instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:144: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:365: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/japo/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:148: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 18:35:41.850505: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2024-05-06 18:35:41.856843: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 4192015000 Hz\n",
      "2024-05-06 18:35:41.857314: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558017e1f530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-06 18:35:41.857330: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "# Avoid tensorflow using cached embeddings\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "\n",
    "model = MODEL_CLASS(batch_size=batch_size, max_user=train_dataset.max_user(), max_item=train_dataset.max_item(), \n",
    "    dim_embed=50, l2_reg=0.001, opt='Adam', sess_config=None)\n",
    "sampler = PairwiseSampler(batch_size=batch_size, dataset=train_dataset, num_process=4)\n",
    "model_trainer = ImplicitModelTrainer(batch_size=batch_size, test_batch_size=test_batch_size,\n",
    "                                     train_dataset=train_dataset, model=model, sampler=sampler,\n",
    "                                     eval_save_prefix=OUTPUT_PATH + DATASET_NAME,\n",
    "                                     item_serving_size=500)\n",
    "auc_evaluator = AUC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Start training with FULL evaluation ==\n",
      "[Itr 100] Finished\n",
      "[Itr 200] Finished\n",
      "[Itr 300] Finished\n",
      "[Itr 400] Finished\n",
      "[Itr 500] Finished\n",
      "[Itr 600] Finished\n",
      "[Itr 700] Finished\n",
      "[Itr 800] Finished\n",
      "[Itr 900] Finished\n",
      "[Itr 1000] Finished\n",
      "INFO:tensorflow:./generated_data/cml-KuaiRec/KuaiRec-1000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 1000] loss: 3062.815696\n",
      "[Itr 1100] Finished\n",
      "[Itr 1200] Finished\n",
      "[Itr 1300] Finished\n",
      "[Itr 1400] Finished\n",
      "[Itr 1500] Finished\n",
      "[Itr 1600] Finished\n",
      "[Itr 1700] Finished\n",
      "[Itr 1800] Finished\n",
      "[Itr 1900] Finished\n",
      "[Itr 2000] Finished\n",
      "INFO:tensorflow:./generated_data/cml-KuaiRec/KuaiRec-2000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 2000] loss: 1642.643703\n",
      "[Itr 2100] Finished\n",
      "[Itr 2200] Finished\n",
      "[Itr 2300] Finished\n",
      "[Itr 2400] Finished\n",
      "[Itr 2500] Finished\n",
      "[Itr 2600] Finished\n",
      "[Itr 2700] Finished\n",
      "[Itr 2800] Finished\n",
      "[Itr 2900] Finished\n",
      "[Itr 3000] Finished\n",
      "INFO:tensorflow:./generated_data/cml-KuaiRec/KuaiRec-3000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 3000] loss: 1441.484522\n",
      "[Itr 3100] Finished\n",
      "[Itr 3200] Finished\n",
      "[Itr 3300] Finished\n",
      "[Itr 3400] Finished\n",
      "[Itr 3500] Finished\n",
      "[Itr 3600] Finished\n",
      "[Itr 3700] Finished\n",
      "[Itr 3800] Finished\n",
      "[Itr 3900] Finished\n",
      "[Itr 4000] Finished\n",
      "INFO:tensorflow:./generated_data/cml-KuaiRec/KuaiRec-4000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 4000] loss: 1355.029102\n",
      "[Itr 4100] Finished\n",
      "[Itr 4200] Finished\n",
      "[Itr 4300] Finished\n",
      "[Itr 4400] Finished\n",
      "[Itr 4500] Finished\n",
      "[Itr 4600] Finished\n",
      "[Itr 4700] Finished\n",
      "[Itr 4800] Finished\n",
      "[Itr 4900] Finished\n",
      "[Itr 5000] Finished\n",
      "INFO:tensorflow:./generated_data/cml-KuaiRec/KuaiRec-5000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 5000] loss: 1300.143782\n",
      "[Itr 5100] Finished\n",
      "[Itr 5200] Finished\n",
      "[Itr 5300] Finished\n",
      "[Itr 5400] Finished\n",
      "[Itr 5500] Finished\n",
      "[Itr 5600] Finished\n",
      "[Itr 5700] Finished\n",
      "[Itr 5800] Finished\n",
      "[Itr 5900] Finished\n",
      "[Itr 6000] Finished\n",
      "INFO:tensorflow:./generated_data/cml-KuaiRec/KuaiRec-6000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 6000] loss: 1266.289095\n",
      "[Itr 6100] Finished\n",
      "[Itr 6200] Finished\n",
      "[Itr 6300] Finished\n",
      "[Itr 6400] Finished\n",
      "[Itr 6500] Finished\n",
      "[Itr 6600] Finished\n",
      "[Itr 6700] Finished\n",
      "[Itr 6800] Finished\n",
      "[Itr 6900] Finished\n",
      "[Itr 7000] Finished\n",
      "INFO:tensorflow:./generated_data/cml-KuaiRec/KuaiRec-7000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 7000] loss: 1238.578194\n",
      "[Itr 7100] Finished\n",
      "[Itr 7200] Finished\n",
      "[Itr 7300] Finished\n",
      "[Itr 7400] Finished\n",
      "[Itr 7500] Finished\n",
      "[Itr 7600] Finished\n",
      "[Itr 7700] Finished\n",
      "[Itr 7800] Finished\n",
      "[Itr 7900] Finished\n",
      "[Itr 8000] Finished\n",
      "INFO:tensorflow:./generated_data/cml-KuaiRec/KuaiRec-8000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 8000] loss: 1217.622745\n",
      "[Itr 8100] Finished\n",
      "[Itr 8200] Finished\n",
      "[Itr 8300] Finished\n",
      "[Itr 8400] Finished\n",
      "[Itr 8500] Finished\n",
      "[Itr 8600] Finished\n",
      "[Itr 8700] Finished\n",
      "[Itr 8800] Finished\n",
      "[Itr 8900] Finished\n",
      "[Itr 9000] Finished\n",
      "INFO:tensorflow:./generated_data/cml-KuaiRec/KuaiRec-9000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 9000] loss: 1205.968978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Itr 9100] Finished\n",
      "[Itr 9200] Finished\n",
      "[Itr 9300] Finished\n",
      "[Itr 9400] Finished\n",
      "[Itr 9500] Finished\n",
      "[Itr 9600] Finished\n",
      "[Itr 9700] Finished\n",
      "[Itr 9800] Finished\n",
      "[Itr 9900] Finished\n",
      "[Itr 10000] Finished\n",
      "INFO:tensorflow:./generated_data/cml-KuaiRec/KuaiRec-10000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 10000] loss: 1194.621136\n"
     ]
    }
   ],
   "source": [
    "model_trainer.train(num_itr=10001, display_itr=display_itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:./generated_data/cml-KuaiRec/ is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.save(OUTPUT_PATH,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DEFINING FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eq(infilename, infilename_neg, trainfilename, gamma=-1.0, K=1):\n",
    "    infile = open(infilename, 'rb')\n",
    "    infile_neg = open(infilename_neg, 'rb')\n",
    "    P = pickle.load(infile)\n",
    "    infile.close()\n",
    "    P_neg = pickle.load(infile_neg)\n",
    "    infile_neg.close()\n",
    "    NUM_NEGATIVES = P[\"num_negatives\"]\n",
    "    #\n",
    "    for theuser in P[\"users\"]:\n",
    "        neg_items = list(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:])\n",
    "        neg_scores = list(P_neg[\"results\"][theuser][NUM_NEGATIVES:])\n",
    "        P[\"user_items\"][theuser] = list(neg_items) + list(P[\"user_items\"][theuser][NUM_NEGATIVES:])\n",
    "        P[\"results\"][theuser] = list(neg_scores) + list(P[\"results\"][theuser][NUM_NEGATIVES:])\n",
    "    #\n",
    "    Zui = dict()\n",
    "    Ni = dict()\n",
    "    # fill in dictionary Ni\n",
    "    trainset = np.load(trainfilename)\n",
    "    for i in trainset['item_id']:\n",
    "        if i in Ni:\n",
    "            Ni[i] += 1\n",
    "        else:\n",
    "            Ni[i] = 1\n",
    "    del trainset\n",
    "\n",
    "    # count #users with non-zero item frequencies\n",
    "    nonzero_user_count = 0\n",
    "    for theuser in P[\"users\"]:\n",
    "        pos_items = P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]\n",
    "        for pos_item in pos_items:\n",
    "            if pos_item in Ni:\n",
    "                nonzero_user_count += 1\n",
    "                break\n",
    "    # fill in dictionary Zui\n",
    "    for theuser in P[\"users\"]:\n",
    "        all_scores = np.array(P[\"results\"][theuser])\n",
    "        pos_items = P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]\n",
    "        pos_scores = P[\"results\"][theuser][len(P_neg[\"results\"][theuser][NUM_NEGATIVES:]):]\n",
    "        for i, pos_item in enumerate(pos_items):\n",
    "            pos_score = pos_scores[i]\n",
    "            Zui[(theuser, pos_item)] = float(np.sum(all_scores > pos_score))\n",
    "    # calculate per-user scores\n",
    "    sum_user_auc = 0.0\n",
    "    sum_user_recall = 0.0\n",
    "\n",
    "    for theuser in P[\"users\"]:\n",
    "        numerator_auc = 0.0\n",
    "        numerator_recall = 0.0\n",
    "        denominator = 0.0\n",
    "        for theitem in P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]:\n",
    "            if theitem not in Ni:\n",
    "                continue\n",
    "            pui = np.power(Ni[theitem], (gamma + 1) / 2.0)\n",
    "\n",
    "            numerator_auc += (1 - Zui[(theuser, theitem)] / len(P[\"user_items\"][theuser])) / pui\n",
    "            # Calcolo il Recall a 1, vedi nota 6 paper\n",
    "            if Zui[(theuser, theitem)] < K:\n",
    "                numerator_recall += 1.0 / pui\n",
    "            denominator += 1 / pui\n",
    "                \n",
    "\n",
    "        if denominator > 0:\n",
    "            sum_user_auc += numerator_auc / denominator\n",
    "            sum_user_recall += numerator_recall / denominator \n",
    "\n",
    "    return {\n",
    "        \"auc\"       : sum_user_auc / nonzero_user_count,\n",
    "        \"recall\"    : sum_user_recall / nonzero_user_count\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aoa(infilename, infilename_neg, trainfilename, K=1):\n",
    "    infile = open(infilename, 'rb')\n",
    "    infile_neg = open(infilename_neg, 'rb')\n",
    "    P = pickle.load(infile)\n",
    "    infile.close()\n",
    "    P_neg = pickle.load(infile_neg)\n",
    "    infile_neg.close()\n",
    "    NUM_NEGATIVES = P[\"num_negatives\"]\n",
    "    #\n",
    "    for theuser in P[\"users\"]:\n",
    "        neg_items = list(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:])\n",
    "        neg_scores = list(P_neg[\"results\"][theuser][NUM_NEGATIVES:])\n",
    "        P[\"user_items\"][theuser] = list(neg_items) + list(P[\"user_items\"][theuser][NUM_NEGATIVES:])\n",
    "        P[\"results\"][theuser] = list(neg_scores) + list(P[\"results\"][theuser][NUM_NEGATIVES:])\n",
    "    #\n",
    "    Zui = dict()\n",
    "    Ni = dict()\n",
    "    # fill in dictionary Ni\n",
    "    trainset = np.load(trainfilename)\n",
    "    for i in trainset['item_id']:\n",
    "        if i in Ni:\n",
    "            Ni[i] += 1\n",
    "        else:\n",
    "            Ni[i] = 1\n",
    "    del trainset\n",
    "    # count #users with non-zero item frequencies\n",
    "    nonzero_user_count = 0\n",
    "    for theuser in P[\"users\"]:\n",
    "        pos_items = P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]\n",
    "        for pos_item in pos_items:\n",
    "            if pos_item in Ni:\n",
    "                nonzero_user_count += 1\n",
    "                break\n",
    "    # fill in dictionary Zui\n",
    "    for theuser in P[\"users\"]:\n",
    "        all_scores = np.array(P[\"results\"][theuser])\n",
    "        pos_items = P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]\n",
    "        pos_scores = P[\"results\"][theuser][len(P_neg[\"results\"][theuser][NUM_NEGATIVES:]):]\n",
    "        for i, pos_item in enumerate(pos_items):\n",
    "            pos_score = pos_scores[i]\n",
    "            Zui[(theuser, pos_item)] = float(np.sum(all_scores > pos_score))\n",
    "    # calculate per-user scores\n",
    "    sum_user_auc = 0.0\n",
    "    sum_user_recall = 0.0\n",
    "    for theuser in P[\"users\"]:\n",
    "        numerator_auc = 0.0\n",
    "        numerator_recall = 0.0\n",
    "        denominator = 0.0\n",
    "\n",
    "        for theitem in P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]:\n",
    "            if theitem not in Ni:\n",
    "                continue\n",
    "            numerator_auc += (1 - Zui[(theuser, theitem)] / len(P[\"user_items\"][theuser]))\n",
    "            # Calcolo il Recall a 30, vedi nota 6 paper\n",
    "            if Zui[(theuser, theitem)] < K:\n",
    "                numerator_recall += 1.0\n",
    "            denominator += 1 \n",
    "\n",
    "        if denominator > 0:\n",
    "            sum_user_auc += numerator_auc / denominator\n",
    "            sum_user_recall += numerator_recall / denominator\n",
    "\n",
    "    return {\n",
    "        \"auc\"       : sum_user_auc / nonzero_user_count,\n",
    "        \"recall\"    : sum_user_recall / nonzero_user_count\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified(infilename, infilename_neg, trainfilename, gamma=1.0, K=30, partition=10):\n",
    "\n",
    "    # Read pickles\n",
    "    infile = open(infilename, 'rb')\n",
    "    infile_neg = open(infilename_neg, 'rb')\n",
    "    P = pickle.load(infile)\n",
    "    infile.close()\n",
    "    P_neg = pickle.load(infile_neg)\n",
    "    infile_neg.close()\n",
    "    NUM_NEGATIVES = P[\"num_negatives\"]\n",
    "\n",
    "    # Merge P and P_neg\n",
    "    for theuser in P[\"users\"]:\n",
    "        neg_items = list(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:])\n",
    "        neg_scores = list(P_neg[\"results\"][theuser][NUM_NEGATIVES:])\n",
    "        P[\"user_items\"][theuser] = list(neg_items) + list(P[\"user_items\"][theuser][NUM_NEGATIVES:])\n",
    "        P[\"results\"][theuser] = list(neg_scores) + list(P[\"results\"][theuser][NUM_NEGATIVES:])\n",
    "\n",
    "    Zui = dict()\n",
    "    Ni = dict()\n",
    "\n",
    "    # Compute frequencies of items in the training set\n",
    "    trainset = np.load(trainfilename)\n",
    "    for i in trainset['item_id']:\n",
    "        if i in Ni:\n",
    "            Ni[i] += 1\n",
    "        else:\n",
    "            Ni[i] = 1\n",
    "    del trainset\n",
    "\n",
    "    # Compute recommendations for each user\n",
    "    for theuser in P[\"users\"]:\n",
    "        all_scores = np.array(P[\"results\"][theuser])\n",
    "        pos_items = P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]\n",
    "        pos_scores = P[\"results\"][theuser][len(P_neg[\"results\"][theuser][NUM_NEGATIVES:]):]\n",
    "        for i, pos_item in enumerate(pos_items):\n",
    "            pos_score = pos_scores[i]\n",
    "            Zui[(theuser, pos_item)] = float(np.sum(all_scores > pos_score))\n",
    "\n",
    "    pui = dict()\n",
    "    w = dict()\n",
    "\n",
    "    # Compute dictionary of propensity scores\n",
    "    for theuser in P[\"users\"]:\n",
    "        for theitem in P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]:\n",
    "            if theitem not in Ni:\n",
    "                continue\n",
    "            if theitem in pui:\n",
    "                continue\n",
    "            pui[theitem] = np.power(Ni[theitem], (gamma + 1) / 2.0)\n",
    "\n",
    "    # Take the list of items (not tuples) in pui sorted by value\n",
    "    items_sorted_by_value = sorted(pui, key=pui.get, reverse=True)\n",
    "\n",
    "    # Compute linspace between the pui[0] and pui[-1] \n",
    "\n",
    "    # Maybe try to split the logspace instead of the linspace?\n",
    "    # logspace = np.logspace(pui[items_sorted_by_value[0]], pui[items_sorted_by_value[-1]], partition+1)\n",
    "\n",
    "    linspace = np.linspace(pui[items_sorted_by_value[0]], pui[items_sorted_by_value[-1]], partition+1)\n",
    "   \n",
    "    # Compute dictionary w, that is, for each item, assigns the average of the puis in the partition it belongs to\n",
    "    i=0\n",
    "    j = 0\n",
    "    while i < len(items_sorted_by_value):\n",
    "                            \n",
    "        avg = 0\n",
    "        start = i\n",
    "        end = i\n",
    "    \n",
    "        while i < len(items_sorted_by_value) and pui[items_sorted_by_value[i]] >= linspace[j+1]:\n",
    "            avg += 1.0 / pui[items_sorted_by_value[i]]\n",
    "            end = i\n",
    "            i += 1\n",
    "        \n",
    "        # Is the average the only good choice? even with the log space split?\n",
    "        avg = avg / (end - start + 1)\n",
    "\n",
    "        for k in range(start, end+1):\n",
    "            w[items_sorted_by_value[k]] = avg\n",
    "\n",
    "\n",
    "        j += 1\n",
    "\n",
    "    nonzero_user_count = 0\n",
    "    sum_user_auc = 0.0\n",
    "    sum_user_recall = 0.0\n",
    "\n",
    "    # Compute score with AUC and compute Recall\n",
    "    for theuser in P[\"users\"]:\n",
    "        numerator_auc = 0.0\n",
    "        numerator_recall = 0.0\n",
    "        denominator = 0.0\n",
    "        for theitem in P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]:\n",
    "            # Skip items with null frequency\n",
    "            if  theitem not in Ni:\n",
    "                continue\n",
    "            # Add things to be summed for each item\n",
    "            numerator_auc += (1 - Zui[(theuser, theitem)] / len(P[\"user_items\"][theuser])) * w[theitem]\n",
    "            # Add things for recall\n",
    "            if Zui[(theuser, theitem)] < K:\n",
    "                numerator_recall += 1.0 * w[theitem] #spetta\n",
    "            # Increment denominator that the sum must be divided by \n",
    "            denominator += 1 / pui[theitem]\n",
    "\n",
    "\n",
    "        # If there was at least one item for the user, count the user and sum the results\n",
    "        if denominator > 0:\n",
    "            nonzero_user_count += 1\n",
    "            sum_user_auc += numerator_auc / denominator\n",
    "            sum_user_recall += numerator_recall / denominator \n",
    "\n",
    "    return {\n",
    "        \"auc\"       : sum_user_auc / nonzero_user_count, \n",
    "        \"recall\"    : sum_user_recall / nonzero_user_count\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_logspace(infilename, infilename_neg, trainfilename, gamma=1.0, K=30, partition=10):\n",
    "\n",
    "    # Read pickles\n",
    "    infile = open(infilename, 'rb')\n",
    "    infile_neg = open(infilename_neg, 'rb')\n",
    "    P = pickle.load(infile)\n",
    "    infile.close()\n",
    "    P_neg = pickle.load(infile_neg)\n",
    "    infile_neg.close()\n",
    "    NUM_NEGATIVES = P[\"num_negatives\"]\n",
    "\n",
    "    # Merge P and P_neg\n",
    "    for theuser in P[\"users\"]:\n",
    "        neg_items = list(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:])\n",
    "        neg_scores = list(P_neg[\"results\"][theuser][NUM_NEGATIVES:])\n",
    "        P[\"user_items\"][theuser] = list(neg_items) + list(P[\"user_items\"][theuser][NUM_NEGATIVES:])\n",
    "        P[\"results\"][theuser] = list(neg_scores) + list(P[\"results\"][theuser][NUM_NEGATIVES:])\n",
    "\n",
    "    Zui = dict()\n",
    "    Ni = dict()\n",
    "\n",
    "    # Compute frequencies of items in the training set\n",
    "    trainset = np.load(trainfilename)\n",
    "    for i in trainset['item_id']:\n",
    "        if i in Ni:\n",
    "            Ni[i] += 1\n",
    "        else:\n",
    "            Ni[i] = 1\n",
    "    del trainset\n",
    "\n",
    "    # Compute recommendations for each user\n",
    "    for theuser in P[\"users\"]:\n",
    "        all_scores = np.array(P[\"results\"][theuser])\n",
    "        pos_items = P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]\n",
    "        pos_scores = P[\"results\"][theuser][len(P_neg[\"results\"][theuser][NUM_NEGATIVES:]):]\n",
    "        for i, pos_item in enumerate(pos_items):\n",
    "            pos_score = pos_scores[i]\n",
    "            Zui[(theuser, pos_item)] = float(np.sum(all_scores > pos_score))\n",
    "\n",
    "    pui = dict()\n",
    "    w = dict()\n",
    "\n",
    "    # Compute dictionary of propensity scores\n",
    "    for theuser in P[\"users\"]:\n",
    "        for theitem in P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]:\n",
    "            if theitem not in Ni:\n",
    "                continue\n",
    "            if theitem in pui:\n",
    "                continue\n",
    "            pui[theitem] = np.power(Ni[theitem], (gamma + 1) / 2.0)\n",
    "\n",
    "    # Take the list of items (not tuples) in pui sorted by value\n",
    "    items_sorted_by_value = sorted(pui, key=pui.get, reverse=True)\n",
    "\n",
    "    # Compute linspace between the pui[0] and pui[-1] \n",
    "\n",
    "    # Maybe try to split the logspace instead of the linspace?\n",
    "    logspace = np.logspace(pui[items_sorted_by_value[0]], pui[items_sorted_by_value[-1]], partition+1)\n",
    "   \n",
    "    # Compute dictionary w, that is, for each item, assigns the average of the puis in the partition it belongs to\n",
    "    i=0\n",
    "    j = 0\n",
    "    while i < len(items_sorted_by_value):\n",
    "                            \n",
    "        avg = 0\n",
    "        start = i\n",
    "        end = i\n",
    "    \n",
    "        while i < len(items_sorted_by_value) and pui[items_sorted_by_value[i]] >= logspace[j+1]:\n",
    "            avg += 1.0 / pui[items_sorted_by_value[i]]\n",
    "            end = i\n",
    "            i += 1\n",
    "        \n",
    "        # Is the average the only good choice? even with the log space split?\n",
    "        avg = avg / (end - start + 1)\n",
    "\n",
    "        for k in range(start, end+1):\n",
    "            w[items_sorted_by_value[k]] = avg\n",
    "\n",
    "\n",
    "        j += 1\n",
    "\n",
    "    nonzero_user_count = 0\n",
    "    sum_user_auc = 0.0\n",
    "    sum_user_recall = 0.0\n",
    "\n",
    "    # Compute score with AUC and compute Recall\n",
    "    for theuser in P[\"users\"]:\n",
    "        numerator_auc = 0.0\n",
    "        numerator_recall = 0.0\n",
    "        denominator = 0.0\n",
    "        for theitem in P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]:\n",
    "            # Skip items with null frequency\n",
    "            if  theitem not in Ni:\n",
    "                continue\n",
    "            # Add things to be summed for each item\n",
    "            numerator_auc += (1 - Zui[(theuser, theitem)] / len(P[\"user_items\"][theuser])) * w[theitem]\n",
    "            # Add things for recall\n",
    "            if Zui[(theuser, theitem)] < K:\n",
    "                numerator_recall += 1.0 * w[theitem] #spetta\n",
    "            # Increment denominator that the sum must be divided by \n",
    "            denominator += 1 / pui[theitem]\n",
    "\n",
    "\n",
    "        # If there was at least one item for the user, count the user and sum the results\n",
    "        if denominator > 0:\n",
    "            nonzero_user_count += 1\n",
    "            sum_user_auc += numerator_auc / denominator\n",
    "            sum_user_recall += numerator_recall / denominator \n",
    "\n",
    "    return {\n",
    "        \"auc\"       : sum_user_auc / nonzero_user_count, \n",
    "        \"recall\"    : sum_user_recall / nonzero_user_count\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This version uses the linspace of the number of number of items used for evaluation, not of the propensities\n",
    "\n",
    "def stratified_2(infilename, infilename_neg, trainfilename, gamma=1.0, K=30, partition=10):\n",
    "\n",
    "    # Read pickles\n",
    "    infile = open(infilename, 'rb')\n",
    "    infile_neg = open(infilename_neg, 'rb')\n",
    "    P = pickle.load(infile)\n",
    "    infile.close()\n",
    "    P_neg = pickle.load(infile_neg)\n",
    "    infile_neg.close()\n",
    "    NUM_NEGATIVES = P[\"num_negatives\"]\n",
    "\n",
    "    # Merge P and P_neg\n",
    "    for theuser in P[\"users\"]:\n",
    "        neg_items = list(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:])\n",
    "        neg_scores = list(P_neg[\"results\"][theuser][NUM_NEGATIVES:])\n",
    "        P[\"user_items\"][theuser] = list(neg_items) + list(P[\"user_items\"][theuser][NUM_NEGATIVES:])\n",
    "        P[\"results\"][theuser] = list(neg_scores) + list(P[\"results\"][theuser][NUM_NEGATIVES:])\n",
    "\n",
    "    Zui = dict()\n",
    "    Ni = dict()\n",
    "\n",
    "    # Compute frequencies of items in the training set\n",
    "    trainset = np.load(trainfilename)\n",
    "    for i in trainset['item_id']:\n",
    "        if i in Ni:\n",
    "            Ni[i] += 1\n",
    "        else:\n",
    "            Ni[i] = 1\n",
    "    del trainset\n",
    "\n",
    "    # Compute recommendations for each user\n",
    "    for theuser in P[\"users\"]:\n",
    "        all_scores = np.array(P[\"results\"][theuser])\n",
    "        pos_items = P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]\n",
    "        pos_scores = P[\"results\"][theuser][len(P_neg[\"results\"][theuser][NUM_NEGATIVES:]):]\n",
    "        for i, pos_item in enumerate(pos_items):\n",
    "            pos_score = pos_scores[i]\n",
    "            Zui[(theuser, pos_item)] = float(np.sum(all_scores > pos_score))\n",
    "\n",
    "    pui = dict()\n",
    "    w = dict()\n",
    "\n",
    "    # Compute dictionary of propensity scores\n",
    "    for theuser in P[\"users\"]:\n",
    "        for theitem in P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]:\n",
    "            if theitem not in Ni:\n",
    "                continue\n",
    "            if theitem in pui:\n",
    "                continue\n",
    "            pui[theitem] = np.power(Ni[theitem], (gamma + 1) / 2.0)\n",
    "\n",
    "    # Take the list of items (not tuples) in pui sorted by value\n",
    "    items_sorted_by_value = sorted(pui, key=pui.get, reverse=True)\n",
    "\n",
    "    # Compute linspace between the 0 to len(item_sorted...)\n",
    "    linspace = np.linspace(0, len(items_sorted_by_value), partition+1)\n",
    "   \n",
    "    # Compute dictionary w, that is, for each item, assigns the average of the puis in the partition it belongs to\n",
    "    i=0\n",
    "    j = 0\n",
    "    while i < len(items_sorted_by_value):\n",
    "                            \n",
    "        avg = 0\n",
    "        start = i\n",
    "        end = i\n",
    "    \n",
    "        while i < len(items_sorted_by_value) and i < linspace[j+1]:\n",
    "            avg += 1.0 / pui[items_sorted_by_value[i]]\n",
    "            end = i\n",
    "            i += 1\n",
    "        \n",
    "        avg = avg / (end - start + 1)\n",
    "\n",
    "        for k in range(start, end+1):\n",
    "            w[items_sorted_by_value[k]] = avg\n",
    "\n",
    "\n",
    "        j += 1\n",
    "\n",
    "    nonzero_user_count = 0\n",
    "    sum_user_auc = 0.0\n",
    "    sum_user_recall = 0.0\n",
    "\n",
    "    # Compute score with AUC and compute Recall\n",
    "    for theuser in P[\"users\"]:\n",
    "        numerator_auc = 0.0\n",
    "        numerator_recall = 0.0\n",
    "        denominator = 0.0\n",
    "        for theitem in P[\"user_items\"][theuser][len(P_neg[\"user_items\"][theuser][NUM_NEGATIVES:]):]:\n",
    "            # Skip items with null frequency\n",
    "            if  theitem not in Ni:\n",
    "                continue\n",
    "            # Add things to be summed for each item\n",
    "            numerator_auc += (1 - Zui[(theuser, theitem)] / len(P[\"user_items\"][theuser])) * w[theitem]\n",
    "            # Add things for recall\n",
    "            if Zui[(theuser, theitem)] < K:\n",
    "                numerator_recall += 1.0 * w[theitem] #spetta\n",
    "            # Increment denominator that the sum must be divided by \n",
    "            denominator += 1 / pui[theitem]\n",
    "\n",
    "\n",
    "        # If there was at least one item for the user, count the user and sum the results\n",
    "        if denominator > 0:\n",
    "            nonzero_user_count += 1\n",
    "            sum_user_auc += numerator_auc / denominator\n",
    "            sum_user_recall += numerator_recall / denominator \n",
    "\n",
    "    return {\n",
    "        \"auc\"       : sum_user_auc / nonzero_user_count, \n",
    "        \"recall\"    : sum_user_recall / nonzero_user_count\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **EVALUATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_results = []\n",
    "recall_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = dict()\n",
    "raw_data['train_data'] = np.load(output_name + \"training_arr.npy\")\n",
    "raw_data['test_data_pos_biased'] = np.load(output_name + \"biased-test_arr_pos.npy\")\n",
    "raw_data['test_data_neg_biased'] = np.load(output_name + \"biased-test_arr_neg.npy\")\n",
    "raw_data['test_data_pos_unbiased'] = np.load(output_name + \"unbiased-test_arr_pos.npy\")\n",
    "raw_data['test_data_neg_unbiased'] = np.load(output_name + \"unbiased-test_arr_neg.npy\")\n",
    "raw_data['max_user'] = 7177\n",
    "raw_data['max_item'] = 10729\n",
    "batch_size = 8000\n",
    "test_batch_size = 1000\n",
    "display_itr = 1000\n",
    "\n",
    "train_dataset = ImplicitDataset(raw_data['train_data'], raw_data['max_user'], raw_data['max_item'], name='Train')\n",
    "test_dataset_pos_biased = ImplicitDataset(raw_data['test_data_pos_biased'], raw_data['max_user'], raw_data['max_item'])\n",
    "test_dataset_neg_biased = ImplicitDataset(raw_data['test_data_neg_biased'], raw_data['max_user'], raw_data['max_item'])\n",
    "test_dataset_pos_unbiased = ImplicitDataset(raw_data['test_data_pos_unbiased'], raw_data['max_user'], raw_data['max_item'])\n",
    "test_dataset_neg_unbiased = ImplicitDataset(raw_data['test_data_neg_unbiased'], raw_data['max_user'], raw_data['max_item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./generated_data/cml-KuaiRec/\n"
     ]
    }
   ],
   "source": [
    "#Code to avoid tf using cached embeddings\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "model = MODEL_CLASS(batch_size=batch_size, max_user=train_dataset.max_user(), max_item=train_dataset.max_item(),\n",
    "    dim_embed=50, l2_reg=0.001, opt='Adam', sess_config=None)\n",
    "sampler = PairwiseSampler(batch_size=batch_size, dataset=train_dataset, num_process=4)\n",
    "model_trainer = ImplicitModelTrainer(batch_size=batch_size, test_batch_size=test_batch_size,\n",
    "                                     train_dataset=train_dataset, model=model, sampler=sampler,\n",
    "                                     eval_save_prefix=OUTPUT_PATH + DATASET_NAME,\n",
    "                                     item_serving_size=500)\n",
    "auc_evaluator = AUC()\n",
    "\n",
    "model.load(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Subsampling negative items]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    }
   ],
   "source": [
    "model_trainer._eval_manager = ImplicitEvalManager(evaluators=[auc_evaluator])\n",
    "model_trainer._num_negatives = 200 # Had to increment it, original 200 now?\n",
    "model_trainer._exclude_positives([train_dataset, test_dataset_pos_biased, test_dataset_neg_biased])\n",
    "model_trainer._sample_negatives(seed=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biased Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7157/7157 [00:07<00:00, 929.44it/s]\n",
      "100%|| 7176/7176 [14:44<00:00,  8.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AUC': [0.48961394948335246,\n",
       "  0.49236624928856004,\n",
       "  0.5162584175084175,\n",
       "  0.5027956225127914,\n",
       "  0.5271145745577085,\n",
       "  0.5065462753950338,\n",
       "  0.5100141322781232,\n",
       "  0.48219830028328614,\n",
       "  0.49902894884766724,\n",
       "  0.5124756167527252,\n",
       "  0.5154997184684684,\n",
       "  0.5084057353776263,\n",
       "  0.4995945945945946,\n",
       "  0.5004532415375789,\n",
       "  0.5026338659938323,\n",
       "  0.4845082433200682,\n",
       "  0.4958070866141733,\n",
       "  0.4937532693984307,\n",
       "  0.4850842459983151,\n",
       "  0.4725997191011236,\n",
       "  0.5373773957158963,\n",
       "  0.49247406784412673,\n",
       "  0.5022363584959004,\n",
       "  0.5051277372262774,\n",
       "  0.505828659562535,\n",
       "  0.500458767238953,\n",
       "  0.48639194139194136,\n",
       "  0.4926590653153154,\n",
       "  0.4960225007120478,\n",
       "  0.48711277761753674,\n",
       "  0.4866112207499295,\n",
       "  0.4641259931895573,\n",
       "  0.5184520034592102,\n",
       "  0.4925372504919876,\n",
       "  0.4936882453151618,\n",
       "  0.5018566591422121,\n",
       "  0.49874964956546125,\n",
       "  0.4889414729767572,\n",
       "  0.5016084611016468,\n",
       "  0.47496624472573845,\n",
       "  0.506484440706476,\n",
       "  0.4875196850393701,\n",
       "  0.4955734206033011,\n",
       "  0.510803264604811,\n",
       "  0.5117566807313643,\n",
       "  0.4916521617069063,\n",
       "  0.49619668911335574,\n",
       "  0.5325325410299943,\n",
       "  0.5354756346658884,\n",
       "  0.486487825594564,\n",
       "  0.4865696166042087,\n",
       "  0.48512748669094985,\n",
       "  0.5565546338672769,\n",
       "  0.508844047275872,\n",
       "  0.5023618940248027,\n",
       "  0.518328190743338,\n",
       "  0.5215558997465503,\n",
       "  0.49621705865684335,\n",
       "  0.5248139797068772,\n",
       "  0.5164630044843049,\n",
       "  0.49515749148694665,\n",
       "  0.5103180914512923,\n",
       "  0.5361590334363585,\n",
       "  0.5041576704545454,\n",
       "  0.4917868162692847,\n",
       "  0.4692518455423055,\n",
       "  0.48795307670694016,\n",
       "  0.4972050482132728,\n",
       "  0.4829332206255283,\n",
       "  0.4763125,\n",
       "  0.5172427403439527,\n",
       "  0.5110858514543914,\n",
       "  0.5073608745031233,\n",
       "  0.49457082748948106,\n",
       "  0.4876395216400911,\n",
       "  0.48386993006993007,\n",
       "  0.5138712871287129,\n",
       "  0.5281587122281841,\n",
       "  0.4932229865290914,\n",
       "  0.5075509626274066,\n",
       "  0.45465531795160374,\n",
       "  0.48908694428812605,\n",
       "  0.48002705011389524,\n",
       "  0.4826453243470935,\n",
       "  0.5273554994388328,\n",
       "  0.46025271273557966,\n",
       "  0.4881334650112867,\n",
       "  0.5217824008996346,\n",
       "  0.5143557936284184,\n",
       "  0.4900758226037196,\n",
       "  0.46761542792792793,\n",
       "  0.4559605982168536,\n",
       "  0.5021685043822448,\n",
       "  0.5238839541547278,\n",
       "  0.5434951868629672,\n",
       "  0.5346847610969748,\n",
       "  0.5114301738642738,\n",
       "  0.5317826086956521,\n",
       "  0.5048284589426322,\n",
       "  0.508245337159254,\n",
       "  0.47289867344058706,\n",
       "  0.5285708154506438,\n",
       "  0.4560036394176932,\n",
       "  0.5089884474499858,\n",
       "  0.48897291196388265,\n",
       "  0.5015300932466799,\n",
       "  0.4990014044943821,\n",
       "  0.5198439273552781,\n",
       "  0.4923370025402201,\n",
       "  0.5271402214022141,\n",
       "  0.4713704436281435,\n",
       "  0.5149898960739031,\n",
       "  0.49122649452708395,\n",
       "  0.49769491525423726,\n",
       "  0.5265324416619237,\n",
       "  0.5043652592802494,\n",
       "  0.4736782902137233,\n",
       "  0.4717761836441894,\n",
       "  0.52554850535815,\n",
       "  0.499622695035461,\n",
       "  0.5045779584969152,\n",
       "  0.5232113239919931,\n",
       "  0.5001188791395415,\n",
       "  0.5025248791583736,\n",
       "  0.523368897983046,\n",
       "  0.4843016997167139,\n",
       "  0.5232676495605331,\n",
       "  0.5169660874439461,\n",
       "  0.4891520880361173,\n",
       "  0.4974241146711636,\n",
       "  0.5143010449025699,\n",
       "  0.48189249720044797,\n",
       "  0.5038970588235294,\n",
       "  0.46808990357345437,\n",
       "  0.5379420903954802,\n",
       "  0.478574831838565,\n",
       "  0.5116199158485273,\n",
       "  0.43496922216004474,\n",
       "  0.5303605499438833,\n",
       "  0.47207748455923637,\n",
       "  0.5410887889856701,\n",
       "  0.5174002248454187,\n",
       "  0.47818641212801805,\n",
       "  0.49410688970796707,\n",
       "  0.4607383492419989,\n",
       "  0.5025822461712989,\n",
       "  0.4841163120567376,\n",
       "  0.48111717403790927,\n",
       "  0.45734,\n",
       "  0.47337715578173595,\n",
       "  0.4433720930232558,\n",
       "  0.5079575484959236,\n",
       "  0.5093426966292135,\n",
       "  0.5194399213924761,\n",
       "  0.4966613924050633,\n",
       "  0.4848934081346424,\n",
       "  0.5016423357664234,\n",
       "  0.518304347826087,\n",
       "  0.47879566210045665,\n",
       "  0.48551336146272855,\n",
       "  0.5268228858663513,\n",
       "  0.46660832137733144,\n",
       "  0.5142020975056689,\n",
       "  0.4807565882686314,\n",
       "  0.5035191082802548,\n",
       "  0.48734593837535006,\n",
       "  0.4780953716690042,\n",
       "  0.4762521055586749,\n",
       "  0.49817840646651274,\n",
       "  0.5044058295964124,\n",
       "  0.5220201590005679,\n",
       "  0.5180706051873198,\n",
       "  0.5003828892005611,\n",
       "  0.5163244469653999,\n",
       "  0.5274131165919282,\n",
       "  0.515,\n",
       "  0.4816605890603085,\n",
       "  0.5390380082498526,\n",
       "  0.4690727732509131,\n",
       "  0.47140999711066167,\n",
       "  0.5179486815990927,\n",
       "  0.482456338028169,\n",
       "  0.5215740479548661,\n",
       "  0.5145172607353353,\n",
       "  0.5065879339783722,\n",
       "  0.5087188462615514,\n",
       "  0.47798412248369715,\n",
       "  0.49985943210570705,\n",
       "  0.5184391988555078,\n",
       "  0.45929232062780273,\n",
       "  0.5477794161014451,\n",
       "  0.5106623631770979,\n",
       "  0.4913661892726762,\n",
       "  0.5329364633117796,\n",
       "  0.5077609379468115,\n",
       "  0.4586582278481013,\n",
       "  0.49564874753729243,\n",
       "  0.5317599660729432,\n",
       "  0.5159582030139324,\n",
       "  0.49521548057839526,\n",
       "  0.5466929472477065,\n",
       "  0.4824517593643587,\n",
       "  0.5056441454337246,\n",
       "  0.529642051860203,\n",
       "  0.5175470109458321,\n",
       "  0.4967055680539933,\n",
       "  0.4817055680539932,\n",
       "  0.49877070245573957,\n",
       "  0.5033087400681043,\n",
       "  0.4560345311622684,\n",
       "  0.5256629438717068,\n",
       "  0.5258521267485012,\n",
       "  0.5082431662870159,\n",
       "  0.510095305832148,\n",
       "  0.48646092865232166,\n",
       "  0.47777793574068805,\n",
       "  0.4874215630347975,\n",
       "  0.501101478112564,\n",
       "  0.5125021361435489,\n",
       "  0.5228551375631668,\n",
       "  0.4601681390709604,\n",
       "  0.5185537770289245,\n",
       "  0.4950294447560291,\n",
       "  0.5022047685834502,\n",
       "  0.5211037868162692,\n",
       "  0.4528771676300578,\n",
       "  0.5037282913165266,\n",
       "  0.5033239752947782,\n",
       "  0.501372301654051,\n",
       "  0.5073649594178562,\n",
       "  0.49018492377188033,\n",
       "  0.5019417613636363,\n",
       "  0.5188207013574662,\n",
       "  0.47030191873589167,\n",
       "  0.5070770095559303,\n",
       "  0.5004328943681704,\n",
       "  0.5006622894661719,\n",
       "  0.5064700084483243,\n",
       "  0.5343622737556561,\n",
       "  0.4792139429861699,\n",
       "  0.49563447501403707,\n",
       "  0.5211198428290766,\n",
       "  0.5048692718583074,\n",
       "  0.4729376058723885,\n",
       "  0.5298131241084165,\n",
       "  0.518314606741573,\n",
       "  0.4832644394110985,\n",
       "  0.5347759932375317,\n",
       "  0.4818571831780976,\n",
       "  0.4972676371780515,\n",
       "  0.5053212567223323,\n",
       "  0.5215291750503018,\n",
       "  0.5459318438914028,\n",
       "  0.49218083593972134,\n",
       "  0.531535421958792,\n",
       "  0.523743345474923,\n",
       "  0.4921947004608295,\n",
       "  0.519745142213461,\n",
       "  0.47858056265984655,\n",
       "  0.5300701852891634,\n",
       "  0.5188517566409597,\n",
       "  0.5183020453908659,\n",
       "  0.5108769963575231,\n",
       "  0.5472270803949224,\n",
       "  0.5079336734693878,\n",
       "  0.5101456447963801,\n",
       "  0.5021727452643484,\n",
       "  0.44694936708860766,\n",
       "  0.5590490196078431,\n",
       "  0.47855658522886824,\n",
       "  0.500343220338983,\n",
       "  0.49564443188241947,\n",
       "  0.4754707700955593,\n",
       "  0.5077617176536626,\n",
       "  0.5162464306110793,\n",
       "  0.5195412064570943,\n",
       "  0.5174726046642315,\n",
       "  0.49375070661390613,\n",
       "  0.5094434931506849,\n",
       "  0.5053805260212647,\n",
       "  0.47472627737226275,\n",
       "  0.4926445005611672,\n",
       "  0.5134042853115309,\n",
       "  0.4966793142214727,\n",
       "  0.4999122807017544,\n",
       "  0.5094435075885329,\n",
       "  0.5213186191284663,\n",
       "  0.4854583453444796,\n",
       "  0.5024275466284075,\n",
       "  0.5059468626342566,\n",
       "  0.5038808918995202,\n",
       "  0.49400875458909915,\n",
       "  0.510336524922557,\n",
       "  0.5009010152284263,\n",
       "  0.4725070067264574,\n",
       "  0.5366817667044167,\n",
       "  0.4822349570200573,\n",
       "  0.49390349650349646,\n",
       "  0.5162279473536825,\n",
       "  0.5016527977044477,\n",
       "  0.5132118155619596,\n",
       "  0.5096516853932584,\n",
       "  0.4991256122154999,\n",
       "  0.5348172135866436,\n",
       "  0.542550636574074,\n",
       "  0.546762610430322,\n",
       "  0.5183182461103254,\n",
       "  0.5152430457993818,\n",
       "  0.5109247251198196,\n",
       "  0.49244252057905197,\n",
       "  0.5018590470788429,\n",
       "  0.50459444129325,\n",
       "  0.47344475524475527,\n",
       "  0.49703986429177266,\n",
       "  0.5039312869614193,\n",
       "  0.49106872370266474,\n",
       "  0.4760047914317926,\n",
       "  0.49392897248736667,\n",
       "  0.4977009692132269,\n",
       "  0.5108330995792426,\n",
       "  0.5048135165451486,\n",
       "  0.4592822488584475,\n",
       "  0.47878082959641255,\n",
       "  0.49906591865357647,\n",
       "  0.4956271091113611,\n",
       "  0.5221017761488582,\n",
       "  0.495620757918552,\n",
       "  0.4970275203594496,\n",
       "  0.49941390914189565,\n",
       "  0.5035381593714927,\n",
       "  0.5174456368257555,\n",
       "  0.5169473531122746,\n",
       "  0.5046439585085506,\n",
       "  0.4540178824865172,\n",
       "  0.49521801905861973,\n",
       "  0.5264135317237507,\n",
       "  0.5076653420380357,\n",
       "  0.5025896414342629,\n",
       "  0.5164801965886094,\n",
       "  0.4627492099971273,\n",
       "  0.4979031354983203,\n",
       "  0.48561147966541673,\n",
       "  0.499905795032829,\n",
       "  0.5266985376827896,\n",
       "  0.4862282425603594,\n",
       "  0.5040410760775239,\n",
       "  0.529431213224993,\n",
       "  0.5038774920543195,\n",
       "  0.5317274256870442,\n",
       "  0.5012352279122116,\n",
       "  0.46990030890199386,\n",
       "  0.537871912693854,\n",
       "  0.47178731762065096,\n",
       "  0.5161157380815623,\n",
       "  0.5109706546275395,\n",
       "  0.4993499579714205,\n",
       "  0.5290712682379348,\n",
       "  0.5043950478334271,\n",
       "  0.47291232638888886,\n",
       "  0.5001112061591104,\n",
       "  0.5258848433530906,\n",
       "  0.5010635903207653,\n",
       "  0.49138975375035376,\n",
       "  0.5085550724637682,\n",
       "  0.5207892527287993,\n",
       "  0.48152352607709753,\n",
       "  0.4933748949285514,\n",
       "  0.49511280315848843,\n",
       "  0.5161782902137233,\n",
       "  0.49282271702367536,\n",
       "  0.5267191896454699,\n",
       "  0.5125395430579965,\n",
       "  0.4808499147242752,\n",
       "  0.5307596180848076,\n",
       "  0.5042883314543405,\n",
       "  0.5025213310580204,\n",
       "  0.5081734578381437,\n",
       "  0.5020916905444126,\n",
       "  0.5054899461908807,\n",
       "  0.465654862282181,\n",
       "  0.5210480659840728,\n",
       "  0.4803840742824986,\n",
       "  0.496155693698785,\n",
       "  0.4950944206008584,\n",
       "  0.4913323943661972,\n",
       "  0.478716577540107,\n",
       "  0.5232761047002533,\n",
       "  0.5165199662542181,\n",
       "  0.48003788982803847,\n",
       "  0.5039247613700168,\n",
       "  0.4747323430493274,\n",
       "  0.474817620650954,\n",
       "  0.5219708545557442,\n",
       "  0.4925098314606742,\n",
       "  0.4839167842031029,\n",
       "  0.4904583921015515,\n",
       "  0.49635495647290084,\n",
       "  0.4898401122019636,\n",
       "  0.4726629055007053,\n",
       "  0.5101578798985058,\n",
       "  0.5199758179231864,\n",
       "  0.48027076835837823,\n",
       "  0.5020861581920903,\n",
       "  0.49843952636030453,\n",
       "  0.4876757369614512,\n",
       "  0.5067202618099031,\n",
       "  0.496952479338843,\n",
       "  0.49377702892445946,\n",
       "  0.5092771939789832,\n",
       "  0.5336289183846371,\n",
       "  0.5556513026052105,\n",
       "  0.46797278140062376,\n",
       "  0.45372474747474745,\n",
       "  0.46090552284833197,\n",
       "  0.516730172170477,\n",
       "  0.507035247299602,\n",
       "  0.5357181844297616,\n",
       "  0.5093392756083758,\n",
       "  0.46486827033218786,\n",
       "  0.4615882187147689,\n",
       "  0.5382057484348322,\n",
       "  0.5117313137032843,\n",
       "  0.5090711237553343,\n",
       "  0.4853451202263083,\n",
       "  0.48755334081976415,\n",
       "  0.4904971671388102,\n",
       "  0.4820998037566583,\n",
       "  0.48842853083262283,\n",
       "  0.49791267605633804,\n",
       "  0.5303438556933483,\n",
       "  0.4891589441168211,\n",
       "  0.5252757142857143,\n",
       "  0.4922388272132081,\n",
       "  0.487640101379893,\n",
       "  0.5199057134815649,\n",
       "  0.47746018202502843,\n",
       "  0.484072092368347,\n",
       "  0.5071844250773123,\n",
       "  0.5087359708193041,\n",
       "  0.5306786820613911,\n",
       "  0.4962917847025496,\n",
       "  0.48839437819420783,\n",
       "  0.4960159977547011,\n",
       "  0.4937628132118451,\n",
       "  0.5119243744728704,\n",
       "  0.5240436384244829,\n",
       "  0.5151710261569417,\n",
       "  0.5444105233539673,\n",
       "  0.5081641833005341,\n",
       "  0.5187056988942444,\n",
       "  0.4892824536376605,\n",
       "  0.4776827896512936,\n",
       "  0.497058658433904,\n",
       "  0.47134744812114415,\n",
       "  0.48359071729957803,\n",
       "  0.523174133558749,\n",
       "  0.5085902836281944,\n",
       "  0.4682546374367622,\n",
       "  0.4913328651685393,\n",
       "  0.5358131682611142,\n",
       "  0.5165934684684684,\n",
       "  0.5025436619718311,\n",
       "  0.5165811724915446,\n",
       "  0.5077912552891396,\n",
       "  0.5105433866891322,\n",
       "  0.5127338847689675,\n",
       "  0.5205713481564875,\n",
       "  0.5059591373439274,\n",
       "  0.5075521714608009,\n",
       "  0.4950579423403052,\n",
       "  0.48872425629290617,\n",
       "  0.4833432793407218,\n",
       "  0.48596498599439775,\n",
       "  0.4473301381449111,\n",
       "  0.46989340813464237,\n",
       "  0.49858522250209913,\n",
       "  0.4942097136440202,\n",
       "  0.4724593609865471,\n",
       "  0.4880553191489362,\n",
       "  0.5051731970471324,\n",
       "  0.5268573046432615,\n",
       "  0.5048481866741635,\n",
       "  0.5172535211267606,\n",
       "  0.4603633022335313,\n",
       "  0.4907730078563412,\n",
       "  0.5149812518027113,\n",
       "  0.5006605374823196,\n",
       "  0.49702913181424857,\n",
       "  0.5084015130288596,\n",
       "  0.4602525832376579,\n",
       "  0.5067881260551491,\n",
       "  0.5213968521641372,\n",
       "  0.5111762225969646,\n",
       "  0.49407754759238515,\n",
       "  0.4789557497181511,\n",
       "  0.4986000560538117,\n",
       "  0.4817587085811385,\n",
       "  0.512460407239819,\n",
       "  0.5304656381486675,\n",
       "  0.4774557708508846,\n",
       "  0.4957109144542773,\n",
       "  0.4505033840947547,\n",
       "  0.48956613310867736,\n",
       "  0.4823709122203098,\n",
       "  0.500119920993228,\n",
       "  0.48443117977528083,\n",
       "  0.5152976691940466,\n",
       "  0.492818362706083,\n",
       "  0.506137960101152,\n",
       "  0.5082366134006168,\n",
       "  0.4879651489600899,\n",
       "  0.5546517832069643,\n",
       "  0.5058629943502825,\n",
       "  0.5179609175870858,\n",
       "  0.468724690663667,\n",
       "  0.4887235841081995,\n",
       "  0.48008588064046576,\n",
       "  0.4824205899035734,\n",
       "  0.5246154937570942,\n",
       "  0.4833333333333333,\n",
       "  0.4779528883903534,\n",
       "  0.49437939769209116,\n",
       "  0.46502101428971704,\n",
       "  0.48479002254791426,\n",
       "  0.5082734418865806,\n",
       "  0.4752760387023335,\n",
       "  0.5417645390070922,\n",
       "  0.5161876584953509,\n",
       "  0.5321051889452906,\n",
       "  0.4990284222737819,\n",
       "  0.48709085778781036,\n",
       "  0.49479353932584275,\n",
       "  0.5188935810810811,\n",
       "  0.5173697549985921,\n",
       "  0.5137167273746147,\n",
       "  0.49727895914941245,\n",
       "  0.5115659955257271,\n",
       "  0.5059325119014282,\n",
       "  0.4879963544587773,\n",
       "  0.4710563781321184,\n",
       "  0.5113153456998314,\n",
       "  0.5007603815937149,\n",
       "  0.5490626764539809,\n",
       "  0.5116101457399104,\n",
       "  0.518800227985181,\n",
       "  0.4986072931276297,\n",
       "  0.5052763385146805,\n",
       "  0.4721302521008403,\n",
       "  0.49861322081575243,\n",
       "  0.5254772599663111,\n",
       "  0.4846998308906426,\n",
       "  0.48438245315161843,\n",
       "  0.5227327537857543,\n",
       "  0.48824944071588366,\n",
       "  0.4821268444948921,\n",
       "  0.5159836987071389,\n",
       "  0.48150301464254947,\n",
       "  0.5143242483843776,\n",
       "  0.48765463196193676,\n",
       "  0.49071043675553033,\n",
       "  0.4939649321266968,\n",
       "  0.48722362160649313,\n",
       "  0.46571088053841836,\n",
       "  0.5018524222906748,\n",
       "  0.4799178470254957,\n",
       "  0.5001123595505618,\n",
       "  0.49737721021611003,\n",
       "  0.5108095238095238,\n",
       "  0.5176017524024873,\n",
       "  0.5195699541284403,\n",
       "  0.49177138849929874,\n",
       "  0.48674248806515025,\n",
       "  0.5247098402018504,\n",
       "  0.4896817797803436,\n",
       "  0.49445513727710155,\n",
       "  0.5205680539932509,\n",
       "  0.4952658371040724,\n",
       "  0.4940592383638928,\n",
       "  0.49877805836139166,\n",
       "  0.5340463483146067,\n",
       "  0.4970608965322808,\n",
       "  0.5131831146605818,\n",
       "  0.507109396914446,\n",
       "  0.45716150315547904,\n",
       "  0.4993060247747748,\n",
       "  0.5086490683229814,\n",
       "  0.5112173295454546,\n",
       "  0.49207713884992993,\n",
       "  0.5189517045454546,\n",
       "  0.5001696578799775,\n",
       "  0.5451501416430595,\n",
       "  0.5227678070667414,\n",
       "  0.5205497603608684,\n",
       "  0.47475852272727276,\n",
       "  0.504937464468448,\n",
       "  0.5084536958368734,\n",
       "  0.5120694522868436,\n",
       "  0.5205020979020979,\n",
       "  0.49599720279720283,\n",
       "  0.4943475767135073,\n",
       "  0.48650086009174315,\n",
       "  0.476781462585034,\n",
       "  0.5200028019052956,\n",
       "  0.4810906515580737,\n",
       "  0.48760863391082077,\n",
       "  0.5073555804823332,\n",
       "  0.5068879608294931,\n",
       "  0.5060641605426794,\n",
       "  0.4937054198258916,\n",
       "  0.5260261456283384,\n",
       "  0.48594759206798865,\n",
       "  0.4985213457732542,\n",
       "  0.5270994397759103,\n",
       "  0.4903983050847458,\n",
       "  0.5232602585722316,\n",
       "  0.48218344389962503,\n",
       "  0.4917976424361493,\n",
       "  0.4754352085082564,\n",
       "  0.5000028280542986,\n",
       "  0.4831135057471264,\n",
       "  0.49114493996569464,\n",
       "  0.4712439988703756,\n",
       "  0.4965737051792829,\n",
       "  0.495375,\n",
       "  0.5132570621468926,\n",
       "  0.5063758581235698,\n",
       "  0.5076642335766424,\n",
       "  0.49880750776178384,\n",
       "  0.5190745428973277,\n",
       "  0.5086490289895863,\n",
       "  0.4643944491169049,\n",
       "  0.4701839796207189,\n",
       "  0.482928231006448,\n",
       "  0.5109158771174275,\n",
       "  0.5073178251121077,\n",
       "  0.5236876936074345,\n",
       "  0.5457142857142857,\n",
       "  0.5493099415204677,\n",
       "  0.5117037454238242,\n",
       "  0.4778279147982063,\n",
       "  0.4872687535250987,\n",
       "  0.49606770098730607,\n",
       "  0.46901434195725533,\n",
       "  0.49347112117780295,\n",
       "  0.5158668730650154,\n",
       "  0.48782737257110675,\n",
       "  0.4849225570261898,\n",
       "  0.5191200335758254,\n",
       "  0.5187932489451477,\n",
       "  0.4969892167990919,\n",
       "  0.48023993144815763,\n",
       "  0.4789475945017182,\n",
       "  0.5021754183496826,\n",
       "  0.5218993231810491,\n",
       "  0.5004690647482015,\n",
       "  0.518569028283394,\n",
       "  0.5128894825646795,\n",
       "  0.47652969321699973,\n",
       "  0.4558070978820836,\n",
       "  0.49253928170594835,\n",
       "  0.5376434782608696,\n",
       "  0.5065510378163207,\n",
       "  0.519441117764471,\n",
       "  0.4942190128996074,\n",
       "  0.4955210674157304,\n",
       "  0.5113214185195609,\n",
       "  0.4847869037538809,\n",
       "  0.49500143020594967,\n",
       "  0.4941115470852018,\n",
       "  0.502728297632469,\n",
       "  0.5115372670807453,\n",
       "  0.5178330935251798,\n",
       "  0.47872686483454846,\n",
       "  0.5073465346534654,\n",
       "  0.5155509915014165,\n",
       "  0.4879540358744395,\n",
       "  0.48915942028985504,\n",
       "  0.5144627285513361,\n",
       "  0.5274321622393602,\n",
       "  0.5007841459937268,\n",
       "  0.4991253189679614,\n",
       "  0.5135311447811448,\n",
       "  0.4884848908785674,\n",
       "  0.48394508265620617,\n",
       "  0.5257721952612047,\n",
       "  0.5265676892766676,\n",
       "  0.5164548829240434,\n",
       "  0.4528920056100982,\n",
       "  0.5012394603709949,\n",
       "  0.45718934081346424,\n",
       "  0.48177659275891105,\n",
       "  0.4995820389720418,\n",
       "  0.496620253164557,\n",
       "  0.5264652014652015,\n",
       "  0.4875192362496438,\n",
       "  0.5299341367713004,\n",
       "  0.4960989627137651,\n",
       "  0.46749929278642155,\n",
       "  0.49526581912741985,\n",
       "  0.518563202247191,\n",
       "  0.5187108161536289,\n",
       "  0.501835604770017,\n",
       "  0.5257763713080169,\n",
       "  0.4764386261261262,\n",
       "  0.48021629213483136,\n",
       "  0.5038348289399889,\n",
       "  0.5077715250422059,\n",
       "  0.48815369261477043,\n",
       "  0.4924546998867498,\n",
       "  0.48813592780597853,\n",
       "  0.552789029535865,\n",
       "  0.46609379387812405,\n",
       "  0.501521989077321,\n",
       "  0.504566261655835,\n",
       "  0.4989107648725213,\n",
       "  0.49062464346833995,\n",
       "  0.46606599713055963,\n",
       "  0.4906711505437894,\n",
       "  0.5035100084578517,\n",
       "  0.5038561354019746,\n",
       "  0.4799662826636696,\n",
       "  0.5308597733711048,\n",
       "  0.5081690945444158,\n",
       "  0.46234072410889704,\n",
       "  0.5096514896008995,\n",
       "  0.5144461712348121,\n",
       "  0.5022596019063639,\n",
       "  0.5252137599093998,\n",
       "  0.5312769532343882,\n",
       "  0.4983901408450704,\n",
       "  0.47991612169462616,\n",
       "  0.49748308906426153,\n",
       "  0.5639926945771284,\n",
       "  0.4698219373219373,\n",
       "  0.49062698642010977,\n",
       "  0.5246629370629371,\n",
       "  0.4863320246775098,\n",
       "  0.5419960193346602,\n",
       "  0.503076266363119,\n",
       "  0.5373915508931103,\n",
       "  0.48520868347338936,\n",
       "  0.48285551439156454,\n",
       "  0.5134709567198178,\n",
       "  0.5246113175192911,\n",
       "  0.4897108843537415,\n",
       "  0.5084334461364918,\n",
       "  0.5233608935306063,\n",
       "  0.4985989319842608,\n",
       "  0.4767317415730337,\n",
       "  0.4533048233314639,\n",
       "  0.497209367945824,\n",
       "  0.4997061304836895,\n",
       "  0.4815697837686043,\n",
       "  0.4931234186111892,\n",
       "  0.4780684389140271,\n",
       "  0.5086166007905139,\n",
       "  0.5035098206660973,\n",
       "  0.5018236613400617,\n",
       "  0.4655411863930278,\n",
       "  0.5259097400742645,\n",
       "  0.5150557780320367,\n",
       "  0.4774922774501545,\n",
       "  0.49433333333333335,\n",
       "  0.48776422764227645,\n",
       "  0.5082598314606741,\n",
       "  0.510324347093513,\n",
       "  0.4918649563010995,\n",
       "  0.4981951834220106,\n",
       "  0.5194527293190772,\n",
       "  0.5037545942889454,\n",
       "  0.4562225352112676,\n",
       "  0.5097902097902098,\n",
       "  0.5427700397953382,\n",
       "  0.5000593555681175,\n",
       "  0.5166358284272498,\n",
       "  0.47253535067873303,\n",
       "  0.4743943298969072,\n",
       "  0.48589609286523217,\n",
       "  0.5331632080762759,\n",
       "  0.4321373829122907,\n",
       "  0.4696253602305475,\n",
       "  0.5210070126227209,\n",
       "  0.49022413307020013,\n",
       "  0.4681789861229113,\n",
       "  0.5296531134489622,\n",
       "  0.5118476430976431,\n",
       "  0.46724014848657913,\n",
       "  0.47777840112201964,\n",
       "  0.5333724879705632,\n",
       "  0.5071275696986765,\n",
       "  0.5119244035642426,\n",
       "  0.49405295601008686,\n",
       "  0.47133126059920866,\n",
       "  0.5238646595385481,\n",
       "  0.5243690409422322,\n",
       "  0.516895342312009,\n",
       "  0.48418222976796826,\n",
       "  0.5023197183098592,\n",
       "  0.5033084507042254,\n",
       "  0.511624633431085,\n",
       "  0.4965150238696996,\n",
       "  0.4817157563625965,\n",
       "  0.48374964397607517,\n",
       "  0.5017314189189189,\n",
       "  0.5218255090497738,\n",
       "  0.5174216765453006,\n",
       "  0.50300170794193,\n",
       "  0.4801106696935301,\n",
       "  0.5002621985417834,\n",
       "  0.5334230552423901,\n",
       "  0.49619168071950537,\n",
       "  0.4937721021611002,\n",
       "  0.5189366906474819,\n",
       "  0.5289684120660216,\n",
       "  0.4768557422969188,\n",
       "  0.49991840180078784,\n",
       "  0.5128429172510518,\n",
       "  0.47577690362461367,\n",
       "  0.5203396546844042,\n",
       "  0.5355530410183875,\n",
       "  0.4741864742501415,\n",
       "  0.5028380681818182,\n",
       "  0.49551869552994093,\n",
       "  0.4597424711511399,\n",
       "  0.5025476724621425,\n",
       "  0.49254827875734675,\n",
       "  0.49733988044406496,\n",
       "  0.48531908912004496,\n",
       "  0.5033361581920904,\n",
       "  0.46570031187978456,\n",
       "  0.48529682997118156,\n",
       "  0.5533699372504278,\n",
       "  0.5068361261005396,\n",
       "  0.507275273032764,\n",
       "  0.48231235891647856,\n",
       "  0.5090106651698008,\n",
       "  0.5297998848257991,\n",
       "  0.4897503692762186,\n",
       "  0.4963659359190556,\n",
       "  0.5315326421966937,\n",
       "  0.5202005610098176,\n",
       "  0.510966928251121,\n",
       "  0.4837877079221877,\n",
       "  0.5208097506304287,\n",
       "  0.5195695457094783,\n",
       "  0.4939416058394161,\n",
       "  0.519412260967379,\n",
       "  0.5258095238095237,\n",
       "  0.49500145602795576,\n",
       "  0.48227438340807177,\n",
       "  0.5155311355311355,\n",
       "  0.4975763143018655,\n",
       "  0.4674780887757987,\n",
       "  0.5114678641594161,\n",
       "  0.5104200618151166,\n",
       "  0.5183848992336078,\n",
       "  0.5268039932508437,\n",
       "  0.514251269035533,\n",
       "  0.4832351290684624,\n",
       "  0.5045151770657673,\n",
       "  0.5091147586980921,\n",
       "  0.5013511988716502,\n",
       "  0.5058972524327419,\n",
       "  0.4845448139797069,\n",
       "  0.511566299942096,\n",
       "  0.5116788526434196,\n",
       "  0.5103607523862997,\n",
       "  0.49745641169853766,\n",
       "  0.5427440225035162,\n",
       "  0.5057926487093154,\n",
       "  0.5341666666666667,\n",
       "  0.48067055808656034,\n",
       "  0.5098305322128852,\n",
       "  0.5041379310344828,\n",
       "  0.49061332950301634,\n",
       "  0.5446647887323943,\n",
       "  0.5444636727688787,\n",
       "  0.5181396976483763,\n",
       "  0.48375210792580103,\n",
       "  0.535604065273404,\n",
       "  0.5100608547976224,\n",
       "  0.5188025751072962,\n",
       "  0.5212752808988764,\n",
       "  0.5028180535966149,\n",
       "  0.48738250283125706,\n",
       "  0.5060355443604814,\n",
       "  0.5066685393258427,\n",
       "  0.4732794784580499,\n",
       "  0.4855685048322911,\n",
       "  0.5095751911639762,\n",
       "  0.4842274256870443,\n",
       "  0.4930011213905242,\n",
       "  0.47281470008448323,\n",
       "  0.49311659192825114,\n",
       "  0.5235152960987932,\n",
       "  0.48408254242162785,\n",
       "  0.5065189340813464,\n",
       "  0.4938885738588036,\n",
       "  0.5453221649484535,\n",
       "  0.49838371744986526,\n",
       "  0.503030855539972,\n",
       "  0.5098680886893068,\n",
       "  0.5234086272223841,\n",
       "  0.5114265375854214,\n",
       "  0.5295609065155807,\n",
       "  0.5175883017801639,\n",
       "  0.4963244382022472,\n",
       "  0.47444662921348313,\n",
       "  0.4800719322990127,\n",
       "  0.5272530864197531,\n",
       "  0.5118021450747954,\n",
       "  0.49335780852866423,\n",
       "  0.47653791334093504,\n",
       "  0.4996824712643678,\n",
       "  0.5280964395850855,\n",
       "  0.49939921392476133,\n",
       "  0.5381315714691673,\n",
       "  0.5004315518719635,\n",
       "  0.4838723284589427,\n",
       "  0.46046888200506897,\n",
       "  0.5082254901960784,\n",
       "  0.5238517359134889,\n",
       "  0.49999430686023344,\n",
       "  0.5388398182334564,\n",
       "  0.4965989702517163,\n",
       "  0.5207217220033765,\n",
       "  0.47993174061433447,\n",
       "  0.47757464788732396,\n",
       "  0.5119672360683282,\n",
       "  0.48225211267605633,\n",
       "  0.5157285714285714,\n",
       "  0.4918501270110076,\n",
       "  0.4909041211101767,\n",
       "  0.4957002383790226,\n",
       "  0.5268179231863442,\n",
       "  0.5048943661971831,\n",
       "  0.51002960248097,\n",
       "  0.505895061728395,\n",
       "  0.5085341650127587,\n",
       "  0.4926351351351352,\n",
       "  0.488405960078718,\n",
       "  0.5134799774393684,\n",
       "  0.5015492562447376,\n",
       "  0.47896707008162115,\n",
       "  0.507765778401122,\n",
       "  0.5104603040540541,\n",
       "  0.4924047619047619,\n",
       "  0.513580748042911,\n",
       "  0.5178942905596382,\n",
       "  0.5149858836815359,\n",
       "  0.5110582606248241,\n",
       "  0.5151780207457246,\n",
       "  0.49286731207289286,\n",
       "  0.48837091319052983,\n",
       "  0.4779481397970687,\n",
       "  0.4976015081206497,\n",
       "  0.47643364928909954,\n",
       "  0.4922872800692241,\n",
       "  0.515117830777967,\n",
       "  0.47097609001406476,\n",
       "  0.5307236095346197,\n",
       "  0.5211336146272855,\n",
       "  0.5000126227208976,\n",
       "  0.5014761904761905,\n",
       "  0.5271307956496852,\n",
       "  0.5408034453544196,\n",
       "  0.4628293918918918,\n",
       "  0.499810433295325,\n",
       "  0.5149191947831018,\n",
       "  0.5055541419281877,\n",
       "  0.4962584175084175,\n",
       "  0.5152145260796411,\n",
       "  0.4730793025871766,\n",
       "  0.5122459893048128,\n",
       "  0.5186079706048615,\n",
       "  0.521166087962963,\n",
       "  0.5317088963963964,\n",
       "  0.5070157215047726,\n",
       "  0.5150450450450451,\n",
       "  0.5365802019068985,\n",
       "  0.4575843339050887,\n",
       "  0.5050098286998035,\n",
       "  0.5137439406900485,\n",
       "  0.5322629187961385,\n",
       "  0.4793177989893318,\n",
       "  0.46638755980861246,\n",
       "  0.47560291643297814,\n",
       "  0.48731825987406985,\n",
       "  0.5147326203208556,\n",
       "  0.48485352673492604,\n",
       "  0.5081398305084746,\n",
       "  0.4880835450183461,\n",
       "  0.49958977240797975,\n",
       "  0.5375000000000001,\n",
       "  0.5292579006772009,\n",
       "  0.467071791972866,\n",
       "  0.5140513264129181,\n",
       "  0.48148618161308515,\n",
       "  0.5117469188879336,\n",
       "  0.5159457917261056,\n",
       "  ...]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trainer._eval_save_prefix = OUTPUT_PREFIX + \"-test-pos-biased\"\n",
    "model_trainer._evaluate_partial(test_dataset_pos_biased)\n",
    "\n",
    "model_trainer._eval_save_prefix = OUTPUT_PREFIX +  \"-test-neg-biased\"\n",
    "model_trainer._evaluate_partial(test_dataset_neg_biased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unbiased Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1411/1411 [00:06<00:00, 230.99it/s]\n",
      "100%|| 1411/1411 [02:19<00:00, 10.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AUC': [0.5990070019096116,\n",
       "  0.5000336083104185,\n",
       "  0.5228904538341157,\n",
       "  0.6319064124783362,\n",
       "  0.626116878767582,\n",
       "  0.5999292960344297,\n",
       "  0.5904657351962741,\n",
       "  0.5557896350812636,\n",
       "  0.5858969276511398,\n",
       "  0.6148610651670525,\n",
       "  0.5255388813096863,\n",
       "  0.5976587990281153,\n",
       "  0.5290530303030303,\n",
       "  0.5769832141746969,\n",
       "  0.5810282503037667,\n",
       "  0.5539259373079287,\n",
       "  0.5715790273556232,\n",
       "  0.6049727272727273,\n",
       "  0.5735583563535912,\n",
       "  0.5703200502039536,\n",
       "  0.558796889295517,\n",
       "  0.5672933743169398,\n",
       "  0.602921195652174,\n",
       "  0.5842520522955306,\n",
       "  0.538129418997848,\n",
       "  0.622120101943294,\n",
       "  0.5883373712901272,\n",
       "  0.5652935779816514,\n",
       "  0.5935637480798771,\n",
       "  0.611801330798479,\n",
       "  0.5745145330859617,\n",
       "  0.6437943989071038,\n",
       "  0.6064132434089516,\n",
       "  0.5942280923758304,\n",
       "  0.6318401015228426,\n",
       "  0.5869348894348895,\n",
       "  0.5877775819527671,\n",
       "  0.6534220997857363,\n",
       "  0.5708310376492194,\n",
       "  0.6923435137586936,\n",
       "  0.5949918327344005,\n",
       "  0.5824754601226994,\n",
       "  0.5764557356608478,\n",
       "  0.6341209563994374,\n",
       "  0.5509882280049567,\n",
       "  0.5755622916035162,\n",
       "  0.599801637279597,\n",
       "  0.6078447722899294,\n",
       "  0.6696743295019157,\n",
       "  0.6363731296758104,\n",
       "  0.6033974960876369,\n",
       "  0.5373464111922142,\n",
       "  0.6427898089171975,\n",
       "  0.6225543311906949,\n",
       "  0.5717578849721707,\n",
       "  0.5677194086190627,\n",
       "  0.5932353855721393,\n",
       "  0.6454051694027244,\n",
       "  0.6785380209990455,\n",
       "  0.6503682048040457,\n",
       "  0.5733265497808391,\n",
       "  0.5716989703210176,\n",
       "  0.5831115879828327,\n",
       "  0.6280812883435583,\n",
       "  0.5775443786982248,\n",
       "  0.5830982061416844,\n",
       "  0.5985363972856261,\n",
       "  0.5428502340093604,\n",
       "  0.5685593220338983,\n",
       "  0.5622907625542467,\n",
       "  0.5982014519056261,\n",
       "  0.524109359275411,\n",
       "  0.621194495412844,\n",
       "  0.6068162195497996,\n",
       "  0.5681245710363761,\n",
       "  0.5011772768809016,\n",
       "  0.5347772966285184,\n",
       "  0.5404523152407237,\n",
       "  0.5868009259259259,\n",
       "  0.5704806814724673,\n",
       "  0.5243658536585366,\n",
       "  0.727670609645132,\n",
       "  0.566561296534018,\n",
       "  0.5707898282249917,\n",
       "  0.5456225084329961,\n",
       "  0.5699647887323944,\n",
       "  0.6348878107944209,\n",
       "  0.5657045247494685,\n",
       "  0.5847050733496333,\n",
       "  0.5582335877862595,\n",
       "  0.5792101226993865,\n",
       "  0.5779617275280899,\n",
       "  0.5557333948339483,\n",
       "  0.5639113451086957,\n",
       "  0.5963537851037851,\n",
       "  0.5511635220125787,\n",
       "  0.5989935464044254,\n",
       "  0.5766558641975309,\n",
       "  0.572404868015084,\n",
       "  0.6467401960784314,\n",
       "  0.6595880480905233,\n",
       "  0.5855083207261724,\n",
       "  0.6464541590771099,\n",
       "  0.5863928340865074,\n",
       "  0.6064509990485252,\n",
       "  0.5790864932623002,\n",
       "  0.5752315580549123,\n",
       "  0.5398202863234847,\n",
       "  0.5006561436087898,\n",
       "  0.5478556295399515,\n",
       "  0.5716429014259145,\n",
       "  0.5086665655339806,\n",
       "  0.5304249605055292,\n",
       "  0.6302925857843138,\n",
       "  0.5352501749475157,\n",
       "  0.6019802286067346,\n",
       "  0.6243177683444512,\n",
       "  0.5536376537369915,\n",
       "  0.5749477295001634,\n",
       "  0.5243699565487275,\n",
       "  0.5656079214000614,\n",
       "  0.5693849080532657,\n",
       "  0.5642490898058252,\n",
       "  0.6166837881219904,\n",
       "  0.8027101096224116,\n",
       "  0.5529139382600562,\n",
       "  0.5654819461444308,\n",
       "  0.6548978201634879,\n",
       "  0.6341220382992535,\n",
       "  0.6443674230649674,\n",
       "  0.6107946918852959,\n",
       "  0.5896894124847001,\n",
       "  0.5967225265871737,\n",
       "  0.5793889739663093,\n",
       "  0.5298769987699877,\n",
       "  0.6279912490055688,\n",
       "  0.5857166666666667,\n",
       "  0.5992227979274612,\n",
       "  0.5488042803970222,\n",
       "  0.5916412639405204,\n",
       "  0.592853835978836,\n",
       "  0.6598673658235656,\n",
       "  0.5881685776262783,\n",
       "  0.6377893555626803,\n",
       "  0.6201591873862947,\n",
       "  0.635662832929782,\n",
       "  0.5935255227552275,\n",
       "  0.6338059210526316,\n",
       "  0.6168139040680024,\n",
       "  0.566013698630137,\n",
       "  0.55292663476874,\n",
       "  0.5784266911539638,\n",
       "  0.6078200312989045,\n",
       "  0.5312724458204334,\n",
       "  0.5896571879936808,\n",
       "  0.6024699907663896,\n",
       "  0.5841279975085643,\n",
       "  0.5916995148574894,\n",
       "  0.6447654093836246,\n",
       "  0.6032358490566038,\n",
       "  0.5963314797652147,\n",
       "  0.6360871545703007,\n",
       "  0.6503160232319781,\n",
       "  0.6229916382781047,\n",
       "  0.5453429101019462,\n",
       "  0.5589366858527719,\n",
       "  0.6211634506242907,\n",
       "  0.6182550659376004,\n",
       "  0.5807715674362091,\n",
       "  0.5892908530318601,\n",
       "  0.663476407914764,\n",
       "  0.6180166981726528,\n",
       "  0.5368442494515826,\n",
       "  0.5970686993438827,\n",
       "  0.5279893119572479,\n",
       "  0.6029948979591837,\n",
       "  0.566745182012848,\n",
       "  0.5617075857727416,\n",
       "  0.5893603744149766,\n",
       "  0.5129141965678626,\n",
       "  0.5588712461166725,\n",
       "  0.5560113484646195,\n",
       "  0.5901973001038421,\n",
       "  0.6149862595419847,\n",
       "  0.6530869829683698,\n",
       "  0.6321490015360984,\n",
       "  0.5783454655747648,\n",
       "  0.5662194337194337,\n",
       "  0.6357801184990125,\n",
       "  0.6146277239709443,\n",
       "  0.5571444658944659,\n",
       "  0.6298873325213156,\n",
       "  0.5417125729099157,\n",
       "  0.5770420560747663,\n",
       "  0.6302949224688355,\n",
       "  0.6195616733312828,\n",
       "  0.5937557251908397,\n",
       "  0.6015407617248977,\n",
       "  0.5177624484617824,\n",
       "  0.549060680355501,\n",
       "  0.6638524087143295,\n",
       "  0.6311534685863874,\n",
       "  0.5856090342679128,\n",
       "  0.6025634028892456,\n",
       "  0.6041852459016395,\n",
       "  0.6267513280212483,\n",
       "  0.5901937747940189,\n",
       "  0.5767668488160291,\n",
       "  0.5933957055214724,\n",
       "  0.6078647859922179,\n",
       "  0.63293402249924,\n",
       "  0.6140992582126457,\n",
       "  0.5353088923556942,\n",
       "  0.5705388272583201,\n",
       "  0.5916786271450859,\n",
       "  0.5772273534635879,\n",
       "  0.6438508597883599,\n",
       "  0.571167941363926,\n",
       "  0.5949566563467492,\n",
       "  0.5784952412208729,\n",
       "  0.5361575875486382,\n",
       "  0.5924719626168224,\n",
       "  0.5815078630897317,\n",
       "  0.5216646058732612,\n",
       "  0.5915444546287809,\n",
       "  0.5270536258379037,\n",
       "  0.5135136031851361,\n",
       "  0.6082747704969927,\n",
       "  0.6385301246537396,\n",
       "  0.6468533292420989,\n",
       "  0.6204817073170731,\n",
       "  0.6321702059202059,\n",
       "  0.5529969650986343,\n",
       "  0.561689364461738,\n",
       "  0.5507952035342379,\n",
       "  0.6135831234256927,\n",
       "  0.5623651960784314,\n",
       "  0.6028972989949749,\n",
       "  0.5368638776147361,\n",
       "  0.5678921220723918,\n",
       "  0.49594460006224705,\n",
       "  0.6578799873337555,\n",
       "  0.7187564687975646,\n",
       "  0.5416928251121076,\n",
       "  0.5497074038150662,\n",
       "  0.5694824498567335,\n",
       "  0.6105732583567636,\n",
       "  0.6166274193548388,\n",
       "  0.579628137589092,\n",
       "  0.6146474045053869,\n",
       "  0.5829182411542425,\n",
       "  0.5889720812182742,\n",
       "  0.6433722000613685,\n",
       "  0.535306976744186,\n",
       "  0.6342753846153846,\n",
       "  0.5351732522796353,\n",
       "  0.5726084779706274,\n",
       "  0.5643436960276339,\n",
       "  0.6332660800970873,\n",
       "  0.5396673787000306,\n",
       "  0.6053820885200553,\n",
       "  0.5713139386189258,\n",
       "  0.5098916692096429,\n",
       "  0.6107604388905821,\n",
       "  0.5405991864831039,\n",
       "  0.6035981781376518,\n",
       "  0.5138056741915803,\n",
       "  0.6072421763869132,\n",
       "  0.5727007850241547,\n",
       "  0.5791848164281269,\n",
       "  0.6231271749446378,\n",
       "  0.595930764206401,\n",
       "  0.5060393603936039,\n",
       "  0.5992986217457886,\n",
       "  0.5451027922675667,\n",
       "  0.6116360601001669,\n",
       "  0.7138506633755014,\n",
       "  0.6741159196290571,\n",
       "  0.6347828096118299,\n",
       "  0.6117913866829566,\n",
       "  0.5919042420461634,\n",
       "  0.6017971856836953,\n",
       "  0.6389283276450511,\n",
       "  0.5185385323917716,\n",
       "  0.5356989905169776,\n",
       "  0.6016823491239455,\n",
       "  0.7047419571045576,\n",
       "  0.5517709923664122,\n",
       "  0.5552604166666666,\n",
       "  0.5939864652187599,\n",
       "  0.6468395061728396,\n",
       "  0.5786259426847662,\n",
       "  0.618588466183575,\n",
       "  0.5259138301134622,\n",
       "  0.6045712982669504,\n",
       "  0.6141324200913242,\n",
       "  0.593755980861244,\n",
       "  0.544003076923077,\n",
       "  0.6092587752053771,\n",
       "  0.5703102300242131,\n",
       "  0.6027217944425846,\n",
       "  0.6219942196531792,\n",
       "  0.6286203759854457,\n",
       "  0.5473921568627451,\n",
       "  0.5866774791473587,\n",
       "  0.5756096804219671,\n",
       "  0.5601875,\n",
       "  0.5686402309328471,\n",
       "  0.6435032724767482,\n",
       "  0.5709944064636421,\n",
       "  0.6047859477124183,\n",
       "  0.6026246921182267,\n",
       "  0.5148163884673748,\n",
       "  0.5893833535844472,\n",
       "  0.5643101879927229,\n",
       "  0.6199243490499647,\n",
       "  0.6250376678676711,\n",
       "  0.6096203528670447,\n",
       "  0.6160943643512451,\n",
       "  0.55449637919684,\n",
       "  0.5391384522370012,\n",
       "  0.5996643163703249,\n",
       "  0.5957371306731648,\n",
       "  0.5272207792207791,\n",
       "  0.6396985924112607,\n",
       "  0.6224395099540583,\n",
       "  0.6132824838478105,\n",
       "  0.5779381608458827,\n",
       "  0.627094892812106,\n",
       "  0.6402515822784811,\n",
       "  0.6083895705521472,\n",
       "  0.6051498929336188,\n",
       "  0.5352262966633631,\n",
       "  0.5467553526448362,\n",
       "  0.6244488636363636,\n",
       "  0.6275603785900783,\n",
       "  0.6593776824034334,\n",
       "  0.6486139666784828,\n",
       "  0.5465712545676005,\n",
       "  0.48535252463054185,\n",
       "  0.6204930662557782,\n",
       "  0.6209136668700427,\n",
       "  0.6163500761035008,\n",
       "  0.5681681918586305,\n",
       "  0.5587085889570552,\n",
       "  0.5738334858188472,\n",
       "  0.6177475698663426,\n",
       "  0.5616941713483146,\n",
       "  0.5747176181706569,\n",
       "  0.5890799492385786,\n",
       "  0.6215717860494213,\n",
       "  0.6071465648854961,\n",
       "  0.5509667872410392,\n",
       "  0.5676152874289324,\n",
       "  0.6269282238442823,\n",
       "  0.5799075025693731,\n",
       "  0.5180873634945398,\n",
       "  0.5945952233250621,\n",
       "  0.5984333843797855,\n",
       "  0.5701165354330708,\n",
       "  0.5959232429099877,\n",
       "  0.5458417508417509,\n",
       "  0.6044925124792013,\n",
       "  0.651629392971246,\n",
       "  0.6119833585476551,\n",
       "  0.5601966768396066,\n",
       "  0.5517147787888297,\n",
       "  0.586899162371134,\n",
       "  0.5887214611872147,\n",
       "  0.5709929835265406,\n",
       "  0.5911072988147225,\n",
       "  0.5448593943139679,\n",
       "  0.5447548862544056,\n",
       "  0.5970368558382256,\n",
       "  0.4875761997405966,\n",
       "  0.5729457125231339,\n",
       "  0.624040012406948,\n",
       "  0.6014980128401101,\n",
       "  0.5427013689907673,\n",
       "  0.6425322225715184,\n",
       "  0.5497861216730038,\n",
       "  0.6171557527539779,\n",
       "  0.5789996382054993,\n",
       "  0.5418006674757282,\n",
       "  0.5752689075630252,\n",
       "  0.636510172143975,\n",
       "  0.5971388190954774,\n",
       "  0.580274223034735,\n",
       "  0.5478634639696587,\n",
       "  0.6860660980810235,\n",
       "  0.6594182825484765,\n",
       "  0.602550925925926,\n",
       "  0.59377032857617,\n",
       "  0.6057698489231759,\n",
       "  0.5497079950031231,\n",
       "  0.5338024152968802,\n",
       "  0.5746435128518972,\n",
       "  0.526000633312223,\n",
       "  0.6350496195831955,\n",
       "  0.6167169517884914,\n",
       "  0.5979375576745617,\n",
       "  0.5986360884044808,\n",
       "  0.5897146401985112,\n",
       "  0.6194812899300274,\n",
       "  0.591246125232486,\n",
       "  0.5218257829127394,\n",
       "  0.5411995141208624,\n",
       "  0.511586963642319,\n",
       "  0.611208538083538,\n",
       "  0.5943515719467957,\n",
       "  0.639536231884058,\n",
       "  0.5646583282489323,\n",
       "  0.6278003095975232,\n",
       "  0.5865832270408163,\n",
       "  0.571066545123063,\n",
       "  0.5484031657355679,\n",
       "  0.6209637995049505,\n",
       "  0.59646687211094,\n",
       "  0.542842717258262,\n",
       "  0.6468070953436807,\n",
       "  0.6436920190995906,\n",
       "  0.6047577367927477,\n",
       "  0.5867154620311071,\n",
       "  0.6116068965517242,\n",
       "  0.5688697376449054,\n",
       "  0.5588435268550139,\n",
       "  0.51243125,\n",
       "  0.6273631214600378,\n",
       "  0.5024248927038627,\n",
       "  0.5969651589242053,\n",
       "  0.5578589070700833,\n",
       "  0.5597132955261499,\n",
       "  0.618177527405603,\n",
       "  0.6495492180312789,\n",
       "  0.6168930416286843,\n",
       "  0.5389369479134938,\n",
       "  0.5524953125,\n",
       "  0.552803738317757,\n",
       "  0.604422447643979,\n",
       "  0.5732166768107121,\n",
       "  0.6063512241054614,\n",
       "  0.5933297775068577,\n",
       "  0.5692751842751843,\n",
       "  0.6498355364279127,\n",
       "  0.5571577017114915,\n",
       "  0.6217241901301848,\n",
       "  0.5814400246685169,\n",
       "  0.5827304533008822,\n",
       "  0.6079707252162342,\n",
       "  0.5620437291223808,\n",
       "  0.6017659067710106,\n",
       "  0.6002218170768764,\n",
       "  0.5543615310389193,\n",
       "  0.5682797181372549,\n",
       "  0.5608090101522842,\n",
       "  0.5010521443998766,\n",
       "  0.6419280442804428,\n",
       "  0.5586668748048704,\n",
       "  0.6520779220779221,\n",
       "  0.5411797752808989,\n",
       "  0.6258537090758391,\n",
       "  0.5114186117005153,\n",
       "  0.5290459249676585,\n",
       "  0.601751145038168,\n",
       "  0.6487487420328749,\n",
       "  0.6323461655046985,\n",
       "  0.5428955273698265,\n",
       "  0.5750936914428482,\n",
       "  0.5761080105055811,\n",
       "  0.5395143385753931,\n",
       "  0.6463990610328638,\n",
       "  0.6224182706996639,\n",
       "  0.45370508255098735,\n",
       "  0.6528276658963355,\n",
       "  0.6063475629181267,\n",
       "  0.6120103092783505,\n",
       "  0.5652407802499239,\n",
       "  0.5748268398268398,\n",
       "  0.6045134383688601,\n",
       "  0.5980413625304136,\n",
       "  0.6211099269183922,\n",
       "  0.5217733457019171,\n",
       "  0.625623460591133,\n",
       "  0.6846596434359806,\n",
       "  0.565603695444409,\n",
       "  0.6348160535117057,\n",
       "  0.5914974156278504,\n",
       "  0.5567820121951219,\n",
       "  0.6214242424242424,\n",
       "  0.5574809276777541,\n",
       "  0.6589090631675313,\n",
       "  0.6824755288916955,\n",
       "  0.5689037515375153,\n",
       "  0.5482866707242848,\n",
       "  0.6003969250078444,\n",
       "  0.6545367762128326,\n",
       "  0.5699542124542124,\n",
       "  0.5480636020151133,\n",
       "  0.6133328206705629,\n",
       "  0.6060249554367202,\n",
       "  0.6592112632233976,\n",
       "  0.6117322066948326,\n",
       "  0.6155628581058308,\n",
       "  0.5748582995951418,\n",
       "  0.6019797031202665,\n",
       "  0.6201578770574404,\n",
       "  0.6061938573315719,\n",
       "  0.5507975460122699,\n",
       "  0.5926268337408314,\n",
       "  0.6262374843554442,\n",
       "  0.5858664425427873,\n",
       "  0.6488172043010753,\n",
       "  0.5904135220125786,\n",
       "  0.5413772070626003,\n",
       "  0.5899002116722104,\n",
       "  0.5109193993257739,\n",
       "  0.5992464569650882,\n",
       "  0.5450563165905632,\n",
       "  0.5774852255054432,\n",
       "  0.6323425616063281,\n",
       "  0.5893026941362915,\n",
       "  0.5715430042398547,\n",
       "  0.571818477553676,\n",
       "  0.5729772382397572,\n",
       "  0.6369103343465047,\n",
       "  0.5680449612403101,\n",
       "  0.6111861379063952,\n",
       "  0.566872267332917,\n",
       "  0.6725540845979979,\n",
       "  0.563143337408313,\n",
       "  0.5760072969543147,\n",
       "  0.5685683025945608,\n",
       "  0.5294279141104294,\n",
       "  0.6061670724284846,\n",
       "  0.6021417589175891,\n",
       "  0.5849938968568813,\n",
       "  0.5803416536661467,\n",
       "  0.5679866085331673,\n",
       "  0.5858203720646539,\n",
       "  0.5500950628641521,\n",
       "  0.5834059439378588,\n",
       "  0.6940978223297615,\n",
       "  0.601631455399061,\n",
       "  0.6994365127582017,\n",
       "  0.6923407160194175,\n",
       "  0.5611276923076923,\n",
       "  0.6368983208955223,\n",
       "  0.5540243132301862,\n",
       "  0.5916230283911672,\n",
       "  0.48494283065512983,\n",
       "  0.6122577696526509,\n",
       "  0.5554486967997361,\n",
       "  0.6183879093198993,\n",
       "  0.5775224071702945,\n",
       "  0.5872848664688427,\n",
       "  0.5357053571428572,\n",
       "  0.5264511400651466,\n",
       "  0.5869894424282415,\n",
       "  0.6051143489487273,\n",
       "  0.5301660006148171,\n",
       "  0.5795417298937784,\n",
       "  0.5640781010719755,\n",
       "  0.5321043719211823,\n",
       "  0.5882698463508322,\n",
       "  0.5636607142857143,\n",
       "  0.5634674018812845,\n",
       "  0.601260249013058,\n",
       "  0.6224411672419202,\n",
       "  0.5904483464030004,\n",
       "  0.5663292307692307,\n",
       "  0.6479240710823909,\n",
       "  0.5743979623340537,\n",
       "  0.6277489659560929,\n",
       "  0.5895946435034383,\n",
       "  0.6433638304361086,\n",
       "  0.6977106227106227,\n",
       "  0.5855785123966942,\n",
       "  0.6137304267731041,\n",
       "  0.5144451871657754,\n",
       "  0.5855163378545006,\n",
       "  0.5360377069282648,\n",
       "  0.630548632218845,\n",
       "  0.6719462169553327,\n",
       "  0.5354816165299301,\n",
       "  0.5156004901960785,\n",
       "  0.5693730886850152,\n",
       "  0.5595160246034315,\n",
       "  0.5893343098958334,\n",
       "  0.6259162468513854,\n",
       "  0.60442,\n",
       "  0.5655427521710087,\n",
       "  0.6178062157221207,\n",
       "  0.7023531193216233,\n",
       "  0.5606078930617441,\n",
       "  0.5240003315649868,\n",
       "  0.5956894948868918,\n",
       "  0.5818549905838041,\n",
       "  0.5698625901751975,\n",
       "  0.5912099871959027,\n",
       "  0.5964620877252635,\n",
       "  0.5399756764974156,\n",
       "  0.6176271460965339,\n",
       "  0.5019805408970975,\n",
       "  0.6016311926605504,\n",
       "  0.5418073301950236,\n",
       "  0.5795303781773093,\n",
       "  0.5740589711417816,\n",
       "  0.6322116736990154,\n",
       "  0.5207088646023073,\n",
       "  0.5343755912961211,\n",
       "  0.6573095673369896,\n",
       "  0.5675089541547278,\n",
       "  0.59875,\n",
       "  0.6179230038022814,\n",
       "  0.5668069533394328,\n",
       "  0.6065050051777701,\n",
       "  0.5695101041028782,\n",
       "  0.584229397074563,\n",
       "  0.6514556347150259,\n",
       "  0.5509253400822525,\n",
       "  0.6127386692381871,\n",
       "  0.5720353443022547,\n",
       "  0.6121893218778767,\n",
       "  0.5446932707355243,\n",
       "  0.6376649665285304,\n",
       "  0.6367372621240024,\n",
       "  0.5688418079096045,\n",
       "  0.5557983450812136,\n",
       "  0.5965813060179257,\n",
       "  0.551999694002448,\n",
       "  0.6631628614916285,\n",
       "  0.6331901743264658,\n",
       "  0.6238799485033795,\n",
       "  0.5775802310654685,\n",
       "  0.539585732565579,\n",
       "  0.6070422535211267,\n",
       "  0.5361350844277674,\n",
       "  0.5767037037037037,\n",
       "  0.5367877857386557,\n",
       "  0.6074621733149931,\n",
       "  0.5217176317501626,\n",
       "  0.6243183984747378,\n",
       "  0.5777077223851417,\n",
       "  0.5728146417445483,\n",
       "  0.6389851334951457,\n",
       "  0.6218889294848374,\n",
       "  0.6100972940103375,\n",
       "  0.5762680824869191,\n",
       "  0.6464474885844749,\n",
       "  0.5797734976887519,\n",
       "  0.590657592653329,\n",
       "  0.5578697773711497,\n",
       "  0.560075237160615,\n",
       "  0.681163046899591,\n",
       "  0.6171667709637046,\n",
       "  0.5802557781201849,\n",
       "  0.57183952132556,\n",
       "  0.5965638561686298,\n",
       "  0.58226468730259,\n",
       "  0.6215251572327044,\n",
       "  0.6658039275851488,\n",
       "  0.5727058823529412,\n",
       "  0.5295472682627378,\n",
       "  0.6003796095444686,\n",
       "  0.5514683505782106,\n",
       "  0.6094588810761234,\n",
       "  0.6056663223140495,\n",
       "  0.5761917892156863,\n",
       "  0.6218060646451182,\n",
       "  0.6167264653641207,\n",
       "  0.5989743197798839,\n",
       "  0.5576023757424196,\n",
       "  0.613755057578587,\n",
       "  0.656359649122807,\n",
       "  0.5739844236760124,\n",
       "  0.6392729083665338,\n",
       "  0.569890560875513,\n",
       "  0.6013110620863537,\n",
       "  0.6751899696048632,\n",
       "  0.5577494456762749,\n",
       "  0.5084281716417911,\n",
       "  0.6343203883495145,\n",
       "  0.567579656862745,\n",
       "  0.5342328208346407,\n",
       "  0.5573049754299755,\n",
       "  0.5620312026658588,\n",
       "  0.6319531722054381,\n",
       "  0.6899400564174895,\n",
       "  0.6727337201805286,\n",
       "  0.5540980868508958,\n",
       "  0.5969356796116505,\n",
       "  0.5943012085528354,\n",
       "  0.5651817558299039,\n",
       "  0.5967901990811638,\n",
       "  0.5368433039781354,\n",
       "  0.5666028552887735,\n",
       "  0.5755105150868638,\n",
       "  0.553857947434293,\n",
       "  0.6058116783858147,\n",
       "  0.6026693227091633,\n",
       "  0.6461644284310514,\n",
       "  0.6637971985383678,\n",
       "  0.5707489619929734,\n",
       "  0.6414647467725919,\n",
       "  0.6450547445255475,\n",
       "  0.5597985347985348,\n",
       "  0.5466772453189463,\n",
       "  0.5956254572055596,\n",
       "  0.544395922093731,\n",
       "  0.6566262657256826,\n",
       "  0.5064948932219128,\n",
       "  0.5999399445642131,\n",
       "  0.593881107998755,\n",
       "  0.6009513742071881,\n",
       "  0.5999253048780488,\n",
       "  0.5838866584311303,\n",
       "  0.6008048780487805,\n",
       "  0.5902044552944766,\n",
       "  0.627526717557252,\n",
       "  0.5494788441692466,\n",
       "  0.593049254698639,\n",
       "  0.6160505961972285,\n",
       "  0.6103740763546798,\n",
       "  0.6017907475490196,\n",
       "  0.5504355238685679,\n",
       "  0.6013736263736263,\n",
       "  0.6291169268441995,\n",
       "  0.5607851105331599,\n",
       "  0.5700591805766313,\n",
       "  0.5936465324384788,\n",
       "  0.5587778810408922,\n",
       "  0.5906086408073162,\n",
       "  0.6073938461538462,\n",
       "  0.5859066100667072,\n",
       "  0.6166656403940887,\n",
       "  0.5690514018691589,\n",
       "  0.6508984238178634,\n",
       "  0.6080490797546013,\n",
       "  0.5843603575832306,\n",
       "  0.5919193440428381,\n",
       "  0.5073244359707658,\n",
       "  0.6910177151120752,\n",
       "  0.5416043518234753,\n",
       "  0.6709887459807073,\n",
       "  0.6518702522029778,\n",
       "  0.5490973312401883,\n",
       "  0.5253521554341226,\n",
       "  0.5812318121693122,\n",
       "  0.5313677811550152,\n",
       "  0.6345638297872341,\n",
       "  0.5675038497074222,\n",
       "  0.5744412035615597,\n",
       "  0.6180216718266254,\n",
       "  0.6036632312822067,\n",
       "  0.5261668861092824,\n",
       "  0.6594449541284403,\n",
       "  0.5745610051468363,\n",
       "  0.6067430491903453,\n",
       "  0.6247953410981696,\n",
       "  0.6274875311720698,\n",
       "  0.6433706505295008,\n",
       "  0.5721017156862745,\n",
       "  0.5720231919438511,\n",
       "  0.5962557147211216,\n",
       "  0.606542471634468,\n",
       "  0.5683903045369795,\n",
       "  0.5745608431810922,\n",
       "  0.6672133168927249,\n",
       "  0.5452871467639016,\n",
       "  0.6228982785602504,\n",
       "  0.5161141720232629,\n",
       "  0.599029827798278,\n",
       "  0.5840726052471019,\n",
       "  0.593049670024314,\n",
       "  0.6998678614823816,\n",
       "  0.5608825328846743,\n",
       "  0.6806114737203709,\n",
       "  0.5978910529519172,\n",
       "  0.6214233128834357,\n",
       "  0.6323129610115912,\n",
       "  0.6018188759926695,\n",
       "  0.5905621753742744,\n",
       "  0.6607165163081193,\n",
       "  0.5673041755562329,\n",
       "  0.5319251421351864,\n",
       "  0.5799086757990868,\n",
       "  0.6059429418303075,\n",
       "  0.5321428571428571,\n",
       "  0.5688832094175961,\n",
       "  0.5788847926267281,\n",
       "  0.5787050138418949,\n",
       "  0.6068055555555556,\n",
       "  0.6455088640840446,\n",
       "  0.5598119325551232,\n",
       "  0.5567290302463361,\n",
       "  0.5792576120424222,\n",
       "  0.588757603406326,\n",
       "  0.5844780132869345,\n",
       "  0.6239166411277964,\n",
       "  0.6094087168546175,\n",
       "  0.6098328785811733,\n",
       "  0.5936278713629404,\n",
       "  0.5643593004769475,\n",
       "  0.5776891715590347,\n",
       "  0.5796989966555184,\n",
       "  0.6380176933158583,\n",
       "  0.6524893875075803,\n",
       "  0.5725478316326531,\n",
       "  0.5669725621060437,\n",
       "  0.7104083204930661,\n",
       "  0.614872346970163,\n",
       "  0.5792349817457684,\n",
       "  0.5848605150214592,\n",
       "  0.5539852280025691,\n",
       "  0.6308830468486687,\n",
       "  0.61496548153262,\n",
       "  0.6762672381662319,\n",
       "  0.5873244629689003,\n",
       "  0.5852547233468287,\n",
       "  0.5863148788927335,\n",
       "  0.5743374613003096,\n",
       "  0.5423905619372865,\n",
       "  0.6314316109422492,\n",
       "  0.5816482504604051,\n",
       "  0.6153201820940819,\n",
       "  0.6386084982160233,\n",
       "  0.5084853540971449,\n",
       "  0.6397426586675087,\n",
       "  0.6300232558139536,\n",
       "  0.5597724230254351,\n",
       "  0.5602729839974898,\n",
       "  0.564001219884111,\n",
       "  0.6161857707509881,\n",
       "  0.6310336460692333,\n",
       "  0.604935444205349,\n",
       "  0.6119890216338392,\n",
       "  0.5356095238095239,\n",
       "  0.6204756262694652,\n",
       "  0.5899182351126196,\n",
       "  0.6261003667889297,\n",
       "  0.6311472841225627,\n",
       "  0.5471279533599264,\n",
       "  0.5844538232373387,\n",
       "  0.5689632107023412,\n",
       "  0.5573078091765421,\n",
       "  0.6095138431114041,\n",
       "  0.5434429223744293,\n",
       "  0.6104950495049506,\n",
       "  0.5810103626943005,\n",
       "  0.6139832610043398,\n",
       "  0.5465822784810127,\n",
       "  0.7686418714237632,\n",
       "  0.5968880048959608,\n",
       "  0.5640536820371644,\n",
       "  0.5859461114513166,\n",
       "  0.5838360969387755,\n",
       "  0.5390476190476191,\n",
       "  0.5616409791477788,\n",
       "  0.6486605914718019,\n",
       "  0.6058312995729103,\n",
       "  0.5744378221649484,\n",
       "  0.5623893129770992,\n",
       "  0.5169523809523809,\n",
       "  0.6735006313131313,\n",
       "  0.6109909090909091,\n",
       "  0.5770284917931248,\n",
       "  0.5635200746965453,\n",
       "  0.5510203756765362,\n",
       "  0.5888836573511543,\n",
       "  0.5269580795413831,\n",
       "  0.5838255956017105,\n",
       "  0.6266273442226256,\n",
       "  0.5417082294264339,\n",
       "  0.564789360393604,\n",
       "  0.5737170226130653,\n",
       "  0.5992382571075402,\n",
       "  0.5728662124496748,\n",
       "  0.6231385869565217,\n",
       "  0.6653372093023255,\n",
       "  0.6635979087452472,\n",
       "  0.6074142857142857,\n",
       "  0.5713708651399491,\n",
       "  0.6036014737488485,\n",
       "  0.5551159554730983,\n",
       "  0.6264631122132671,\n",
       "  0.6379572887650882,\n",
       "  0.5490630944831959,\n",
       "  0.6375775133103664,\n",
       "  0.6541628753412193,\n",
       "  0.6231102941176471,\n",
       "  0.5903217744454858,\n",
       "  0.5878284228769497,\n",
       "  0.5630308880308881,\n",
       "  0.5313901581722319,\n",
       "  0.5916173120728929,\n",
       "  0.5462534775888718,\n",
       "  0.5168480620155039,\n",
       "  0.5164112034472145,\n",
       "  0.6123939393939394,\n",
       "  0.5454474410052099,\n",
       "  0.5613461538461538,\n",
       "  0.5958832565284178,\n",
       "  0.6431921880400968,\n",
       "  0.5798449376710246,\n",
       "  0.5493253424657534,\n",
       "  0.6735860906862745,\n",
       "  0.6107679020100503,\n",
       "  0.5454343155310006,\n",
       "  0.5738966353440436,\n",
       "  0.5790559975520196,\n",
       "  0.5248582554517134,\n",
       "  0.5201595415117719,\n",
       "  0.6200895426926767,\n",
       "  0.6043406593406594,\n",
       "  0.5785554520037278,\n",
       "  0.5943694158075601,\n",
       "  0.6375765069551778,\n",
       "  0.6128566978193146,\n",
       "  0.6424029126213593,\n",
       "  0.6300531753266485,\n",
       "  0.6172313546423135,\n",
       "  0.6067431192660551,\n",
       "  0.6000748646065626,\n",
       "  0.5959041878172588,\n",
       "  0.5365366972477064,\n",
       "  0.5816571519188075,\n",
       "  0.6281689211481359,\n",
       "  0.5487309476474487,\n",
       "  0.6107533212560387,\n",
       "  0.5602032645518941,\n",
       "  0.6526591817902184,\n",
       "  0.5119777070063695,\n",
       "  0.5858999691262735,\n",
       "  0.5424067524115755,\n",
       "  0.5251066747942701,\n",
       "  0.5334816753926702,\n",
       "  0.5519900959455277,\n",
       "  0.6173813953488372,\n",
       "  0.6304985976939856,\n",
       "  0.6114772036474164,\n",
       "  0.560325153374233,\n",
       "  0.5557662776412776,\n",
       "  0.6181809844084377,\n",
       "  0.5519750835612276,\n",
       "  0.650640166028097,\n",
       "  0.5881671826625386,\n",
       "  0.6400342689295039,\n",
       "  0.5841224747474747,\n",
       "  0.6060952236081534,\n",
       "  0.5591732036397866,\n",
       "  0.5930635749385749,\n",
       "  0.5652031769486516,\n",
       "  0.5735422384873436,\n",
       "  0.5913984168865435,\n",
       "  0.5891643059490085,\n",
       "  0.5982834757834757,\n",
       "  0.6029125384352579,\n",
       "  0.6442474101157831,\n",
       "  0.6461575342465753,\n",
       "  0.5992331488114621,\n",
       "  0.5767983651226158,\n",
       "  0.573,\n",
       "  0.5603665413533835,\n",
       "  0.5651099236641222,\n",
       "  0.5803276440109723,\n",
       "  0.6320880464689698,\n",
       "  0.5439856181150551,\n",
       "  0.5957835558678847,\n",
       "  0.6283147540983607,\n",
       "  0.5726690507152147,\n",
       "  0.6303245856353591,\n",
       "  0.5787002161160854,\n",
       "  0.6201413482447965,\n",
       "  0.5886570996978852,\n",
       "  0.606682056017236,\n",
       "  0.5282329066500157,\n",
       "  0.5969940846824409,\n",
       "  0.5593300852618758,\n",
       "  0.5752790843524616,\n",
       "  0.5896731078904992,\n",
       "  0.5874930275797955,\n",
       "  0.5689638718473075,\n",
       "  0.551565749235474,\n",
       "  0.5934249263984298,\n",
       "  0.5420907928388746,\n",
       "  0.621106569785044,\n",
       "  0.595409475465313,\n",
       "  0.6850155569383947,\n",
       "  0.5912178891983906,\n",
       "  0.5977145493694248,\n",
       "  0.5795676172953081,\n",
       "  0.6071883875039444,\n",
       "  0.5590364025695932,\n",
       "  0.6679968673860077,\n",
       "  0.516682534471438,\n",
       "  0.5527295244385733,\n",
       "  0.5748595679012346,\n",
       "  0.5737550138846035,\n",
       "  0.6238909968954811,\n",
       "  0.5372202001819837,\n",
       "  ...]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trainer._eval_save_prefix = OUTPUT_PREFIX + \"-test-pos-unbiased\"\n",
    "model_trainer._evaluate_partial(test_dataset_pos_unbiased)\n",
    "\n",
    "model_trainer._eval_save_prefix = OUTPUT_PREFIX +  \"-test-neg-unbiased\"\n",
    "model_trainer._evaluate_partial(test_dataset_neg_unbiased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "biased_results = dict()\n",
    "\n",
    "# biased_results[\"STRATIFIED_15\"] = stratified(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=1.5, K=30, partition=100)\n",
    "biased_results[\"AOA\"] = aoa(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", K=10)\n",
    "biased_results[\"UB_15\"] = eq(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=1.5, K=10)\n",
    "biased_results[\"UB_2\"] =  eq(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=2, K=10)\n",
    "biased_results[\"UB_25\"] =  eq(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=2.5, K=10)\n",
    "biased_results[\"UB_3\"] =  eq(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=3, K=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "unbiased_results = dict()\n",
    "\n",
    "# unbiased_results[\"STRATIFIED_15\"] = stratified(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=1.5, K=1, partition=100)\n",
    "unbiased_results[\"AOA\"] = aoa(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", K=10)\n",
    "unbiased_results[\"UB_15\"] = eq(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=1.5, K=10)\n",
    "unbiased_results[\"UB_2\"] =  eq(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=2, K=10)\n",
    "unbiased_results[\"UB_25\"] =  eq(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=2.5, K=10)\n",
    "unbiased_results[\"UB_3\"] =  eq(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=3, K=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items = max_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9793,  4121,  9688,  9295,  9370,  2772,  9591,  8120,  8225,\n",
       "        9275,   653,  3018,  8222,  4000,  8220,  9556, 10601,  6794,\n",
       "        4426,  9371,  6376,  3458,  7109,  8951,  7845,   934,  2483,\n",
       "        7307,  8536,  2496,  2372,  6176,  2341,  6602,  7643,  1801,\n",
       "        5711,  3895,  7766,  7637,  9875,  7615,  6727, 10661,   828,\n",
       "        3670,  1257,  9532,  2689,  5256, 10444,  6569,  5723,  9663,\n",
       "        3726,   638,  3325,  8420,  1212,  8729,  7693,  3187,   412,\n",
       "        5554,  2945,  2210,  8813,  7607,   342,  2810,  7641,  2103,\n",
       "        5338,  7735,  5511, 10368,  1469,  9335,  5384,  2346,  7150,\n",
       "        8852,  2511,  9668,  2098,  5706,  4495,  6338,  7725,  5550,\n",
       "        2119,  7552, 10373,  4977,  4541,  5806,  8538,  2266,  2425,\n",
       "        5961,  9643,  4712,  4217,  4403,  4903,  4565,  2419,   390,\n",
       "        1351,  3184,   985,  5006,  8417,  2600,  9379,  3589,  1766,\n",
       "       10400,  6849,  7337, 10296,  6924,  5229,  4476,  3372,  4922,\n",
       "        8996,  6326, 10556,  2366,  3594,  9375, 10525,  4442,  3338,\n",
       "        2930,   718, 10277,   478, 10005,  6587, 10034,  1245, 10490,\n",
       "        9424,  8128,  7269, 10660,  7846,  8338,  1470,  6007,  8989,\n",
       "        8488,  5363,   300,  6836,  4524,  9122,  3182,  8109,  4439,\n",
       "        3949,  9846,  4280,  4901,  6641,  7401,   722,  1219,  4192,\n",
       "         620,  8185,  4635,  8324,  6645,  8677,  8243,  3280,  7028,\n",
       "        7685,  6110,  5247,  8723,  5230, 10117,  3129,  4777,  8913,\n",
       "        3501,  6352,  5270,  5810,  1923,  7089,  5364,  9199,  4500,\n",
       "        5601,  5092,   615,  5855,  3783,  3843,  6529,  4726,  1462,\n",
       "        3962,  7695,  6948,  6102,   863,  5644,  4833,  2590,  9230,\n",
       "        2159, 10549,  7304,  1153, 10331,   626,  1398,   576,  4268,\n",
       "        2112,  7295, 10279,  9744,  6107,  3430,  6254, 10033,    55,\n",
       "        5246,  1846,  7618,  9746,  2935, 10014,   275,  8261,  2821,\n",
       "        7527,  2213,  8273,  2544,  3955,  7878,  1689,  1733,  8038,\n",
       "        2583,   841,  8465,  8213, 10016,  8083,  7977,  8211,  3484,\n",
       "        9930, 10668,  6847,  4517,  2699,  2083,  8836,  7193,  2872,\n",
       "        3498,  2977,  3453,  8427,  8577,  5231,  6249,  8850,  1388,\n",
       "        9778,  7341,  5597,    39,  4158,  2983, 10587,  7592,  1640,\n",
       "        9077,  8653,  7928,  3471,  5412,  8501,  1318,  5616,  5454,\n",
       "        1988, 10022,  1759,  5634,  8195,  9968,  6871,  5652,  4484,\n",
       "        3612,  4335,  3074,  8430,  7303,  5324,  2550,   553,  6130,\n",
       "        5573,  1790,  9298,  8192,  9213,  2378,  6247,  6380,  6446,\n",
       "        3640, 10478,   330,  1629,  9568,  6537,  8658,  3210,  8825,\n",
       "        3030,  3828,  2543,  2975,  8510,  7475,  3216,  2523,  6621,\n",
       "        3119,  7917,  1464,  6289,  1973,  1039,  5654, 10669,  7807,\n",
       "        7248,   797,  5224,  9392,  8615,  1902,  6582,  4612,  5276,\n",
       "        6304,  9083,  2094,  9400,  9495,  7960,  9789, 10039,  6278,\n",
       "        7644,  2007,  7036, 10348,  8069,  4227,  2061, 10035,   207,\n",
       "        4652,  2845,  9175,  7377,  4211,   634,  6890,  3181,  6979,\n",
       "        7835,  9149,  4954,  8977,  6908,  3008,  4254,  5643,  4623,\n",
       "        5512,  9208,  2197,  9655,  1741,  6324,  8244,  8096,  1489,\n",
       "        7574,  1183,  5627,  4199,  9016,   881,  7609,  4428,  7900,\n",
       "        1732,  7009, 10708,  2390,  3107,   814,  4276,  1329,  2863,\n",
       "         329,   688,  1678,   498,  6266,  4836,  4164,  1147,  3970,\n",
       "        3910,   777,  1652,  9589,  4808,  7665,   119,  6745,  5913,\n",
       "        2837,  9526,  2612,  4376,   836,  9263,  4002,  7816,  4388,\n",
       "        2669,  3419,  3493,   237, 10703,  4487,  5012,  1721,   462,\n",
       "         197,  4818,  9541,  7027,  9854,  7509,  9660, 10374,  7879,\n",
       "        8896,  4520,  8544,  2512,  2306,  6133,  6861,  5629,  1275,\n",
       "        1304,  2579,  2228,  4316,  9705,  9734,  2773,  3185,  5374,\n",
       "        8291,  6140,  9885,  6798,  9007,  2991,  3418,  9610,  7700,\n",
       "        8992,   194,  1657,  5123,  6880])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = np.arange(1, num_items+1)\n",
    "\n",
    "partitions = np.random.choice(nums, 500, replace=False)\n",
    "partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eafc7711bcf94788825b521dfc1350c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute biased and unbiased results with stratified for values of partition in (1,2*len(sorted_items))\n",
    "# and store biased and unbiased results such that abs(biased_results[key]['auc'] - unbiased_results[key]['auc']) + abs(biased_results[key]['recall'] - unbiased_results[key]['recall']) is minimized\n",
    "\n",
    "#This is the gamma used to compute the best partition\n",
    "gamma = 15\n",
    "\n",
    "key = \"STRATIFIED_\" + str(gamma).replace(\".\",\"\")\n",
    "\n",
    "unbiased_results[key] = dict()\n",
    "biased_results[key] = dict()\n",
    "best_partition = np.random.choice(nums, 1)[0]\n",
    "\n",
    "#for p in tqdm(range(1, 2*num_items)):\n",
    "for p in tqdm(partitions):\n",
    "    temp_unbiased = stratified(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=gamma, K=10, partition=p)\n",
    "    temp_biased = stratified(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=gamma, K=10, partition=p)\n",
    "    if not unbiased_results[key]:\n",
    "        unbiased_results[key] = temp_unbiased\n",
    "    if not biased_results[key]:\n",
    "        biased_results[key] = temp_biased\n",
    "    elif abs(temp_biased['auc'] - temp_unbiased['auc']) + abs(temp_unbiased['recall'] - temp_biased['recall']) < abs(biased_results[key]['auc'] - unbiased_results[key]['auc']) + abs(biased_results[key]['recall'] - unbiased_results[key]['recall']):\n",
    "        biased_results[key]['auc'] = temp_biased['auc']\n",
    "        biased_results[key]['recall'] = temp_biased['recall']\n",
    "        unbiased_results[key]['auc'] = temp_unbiased['auc']\n",
    "        unbiased_results[key]['recall'] = temp_unbiased['recall']\n",
    "        best_partition = p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3179"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "unbiased_results[\"STRATIFIED_15\"] = stratified(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=1.5, K=10, partition=best_partition)\n",
    "biased_results[\"STRATIFIED_15\"] = stratified(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=1.5, K=10, partition=best_partition)\n",
    "\n",
    "unbiased_results[\"STRATIFIED_2\"] = stratified(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=2, K=10, partition=best_partition)\n",
    "biased_results[\"STRATIFIED_2\"] = stratified(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=2, K=10, partition=best_partition)\n",
    "\n",
    "unbiased_results[\"STRATIFIED_25\"] = stratified(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=2.5, K=10, partition=best_partition)\n",
    "biased_results[\"STRATIFIED_25\"] = stratified(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=2.5, K=10, partition=best_partition)\n",
    "\n",
    "unbiased_results[\"STRATIFIED_3\"] = stratified(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=3, K=10, partition=best_partition)\n",
    "biased_results[\"STRATIFIED_3\"] = stratified(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=3, K=10, partition=best_partition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "unbiased_results[\"STRATIFIED_v2_15\"] = stratified_2(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=1.5, K=10, partition=best_partition)\n",
    "biased_results[\"STRATIFIED_v2_15\"] = stratified_2(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=1.5, K=10, partition=best_partition)\n",
    "\n",
    "unbiased_results[\"STRATIFIED_v2_2\"] = stratified_2(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=2, K=10, partition=best_partition)\n",
    "biased_results[\"STRATIFIED_v2_2\"] = stratified_2(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=2, K=10, partition=best_partition)\n",
    "\n",
    "unbiased_results[\"STRATIFIED_v2_25\"] = stratified_2(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=2.5, K=10, partition=best_partition)\n",
    "biased_results[\"STRATIFIED_v2_25\"] = stratified_2(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=2.5, K=10, partition=best_partition)\n",
    "\n",
    "unbiased_results[\"STRATIFIED_v2_3\"] = stratified_2(OUTPUT_PREFIX+\"-test-pos-unbiased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-unbiased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=3, K=10, partition=best_partition)\n",
    "biased_results[\"STRATIFIED_v2_3\"] = stratified_2(OUTPUT_PREFIX+\"-test-pos-biased_evaluate_partial.pickle\", OUTPUT_PREFIX+\"-test-neg-biased_evaluate_partial.pickle\", output_name+\"training_arr.npy\", gamma=3, K=10, partition=best_partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, value = random.choice(list(biased_results.items()))\n",
    "rows = 2#len(list(value.keys()))\n",
    "columns = 13#len(list(biased_results.items()))\n",
    "results_array = np.zeros((rows,columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_results = dict()\n",
    "\n",
    "list_biased_res = list(biased_results.keys())\n",
    "\n",
    "for i in range(len(list_biased_res)):\n",
    "    key = list_biased_res[i]\n",
    "\n",
    "    for j in range(len(list(biased_results[key].keys()))):\n",
    "        key_2 = list(biased_results[key].keys())[j]\n",
    "\n",
    "        results_array[j][i] = abs(biased_results[key][key_2] - unbiased_results[key][key_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_df = pd.DataFrame(columns=list(biased_results.keys()), data=results_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_values = list(biased_results[list(biased_results.keys())[0]].keys())\n",
    "mae_df.insert(0, \"metric\", metric_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RESULTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>AOA</th>\n",
       "      <th>UB_15</th>\n",
       "      <th>UB_2</th>\n",
       "      <th>UB_25</th>\n",
       "      <th>UB_3</th>\n",
       "      <th>STRATIFIED_15</th>\n",
       "      <th>STRATIFIED_2</th>\n",
       "      <th>STRATIFIED_25</th>\n",
       "      <th>STRATIFIED_3</th>\n",
       "      <th>STRATIFIED_v2_15</th>\n",
       "      <th>STRATIFIED_v2_2</th>\n",
       "      <th>STRATIFIED_v2_25</th>\n",
       "      <th>STRATIFIED_v2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.158301</td>\n",
       "      <td>0.296241</td>\n",
       "      <td>0.313291</td>\n",
       "      <td>0.322564</td>\n",
       "      <td>0.327105</td>\n",
       "      <td>0.363518</td>\n",
       "      <td>0.850604</td>\n",
       "      <td>3.681992</td>\n",
       "      <td>13.350223</td>\n",
       "      <td>0.296238</td>\n",
       "      <td>0.313261</td>\n",
       "      <td>0.322522</td>\n",
       "      <td>0.327064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.016254</td>\n",
       "      <td>0.009118</td>\n",
       "      <td>0.008212</td>\n",
       "      <td>0.007366</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>0.009118</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>0.007365</td>\n",
       "      <td>0.006643</td>\n",
       "      <td>0.009184</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.007410</td>\n",
       "      <td>0.006682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   metric       AOA     UB_15      UB_2     UB_25      UB_3  STRATIFIED_15  \\\n",
       "0     auc  0.158301  0.296241  0.313291  0.322564  0.327105       0.363518   \n",
       "1  recall  0.016254  0.009118  0.008212  0.007366  0.006642       0.009118   \n",
       "\n",
       "   STRATIFIED_2  STRATIFIED_25  STRATIFIED_3  STRATIFIED_v2_15  \\\n",
       "0      0.850604       3.681992     13.350223          0.296238   \n",
       "1      0.008211       0.007365      0.006643          0.009184   \n",
       "\n",
       "   STRATIFIED_v2_2  STRATIFIED_v2_25  STRATIFIED_v2_3  \n",
       "0         0.313261          0.322522         0.327064  \n",
       "1         0.008264          0.007410         0.006682  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecSysEvaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
