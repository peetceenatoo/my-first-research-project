{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SET UP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from openrec.tf1.legacy import ImplicitModelTrainer\n",
    "from openrec.tf1.legacy.utils import ImplicitDataset\n",
    "from openrec.tf1.legacy.recommenders import CML, BPR\n",
    "from openrec.tf1.legacy.utils.evaluators import AUC\n",
    "from openrec.tf1.legacy.utils.samplers import PairwiseSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "import os\n",
    "\n",
    "seed = 76424236\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "folder_name = f\"./Dataset/\"\n",
    "\n",
    "if os.path.exists(folder_name) == False:\n",
    "    os.makedirs(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = dict()\n",
    "raw_data['train_data'] = np.load(folder_name + \"training_arr.npy\")\n",
    "raw_data['val_data'] = np.load(folder_name + \"validation_arr.npy\")\n",
    "raw_data['max_user'] = 15401\n",
    "raw_data['max_item'] = 1001\n",
    "batch_size = 8000\n",
    "test_batch_size = 1000\n",
    "display_itr = 1000\n",
    "\n",
    "train_dataset = ImplicitDataset(raw_data['train_data'], raw_data['max_user'], raw_data['max_item'], name='Train')\n",
    "val_dataset = ImplicitDataset(raw_data['val_data'], raw_data['max_user'], raw_data['max_item'], name='Val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TRAIN MODEL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/piccinatomattia/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:391: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/piccinatomattia/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:31: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/piccinatomattia/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:41: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/piccinatomattia/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:43: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/piccinatomattia/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:33: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/piccinatomattia/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/interactions/pairwise_eu_dist.py:71: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/piccinatomattia/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:596: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/piccinatomattia/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/piccinatomattia/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/modules/extractions/latent_factor.py:75: The name tf.scatter_update is deprecated. Please use tf.compat.v1.scatter_update instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/piccinatomattia/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:144: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/piccinatomattia/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:365: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 16:48:25.872622: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2024-02-15 16:48:25.886383: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2419200000 Hz\n",
      "2024-02-15 16:48:25.890953: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5631e117ac90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-15 16:48:25.891006: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/piccinatomattia/miniconda3/envs/RecSys-Evaluation/lib/python3.7/site-packages/openrec/tf1/legacy/recommenders/recommender.py:148: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Avoid tensorflow using cached embeddings\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "\n",
    "cml_model = CML(batch_size=batch_size, max_user=train_dataset.max_user(), max_item=train_dataset.max_item(), \n",
    "    dim_embed=50, l2_reg=0.001, opt='Adam', sess_config=None)\n",
    "sampler = PairwiseSampler(batch_size=batch_size, dataset=train_dataset, num_process=4)\n",
    "model_trainer = ImplicitModelTrainer(batch_size=batch_size, test_batch_size=test_batch_size,\n",
    "                                     train_dataset=train_dataset, model=cml_model, sampler=sampler,\n",
    "                                     eval_save_prefix=folder_name + \"yahoo\",\n",
    "                                     item_serving_size=500)\n",
    "auc_evaluator = AUC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Subsampling negative items]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Start training with sampled evaluation, sample size: 200 ==\n",
      "[Itr 100] Finished\n",
      "[Itr 200] Finished\n",
      "[Itr 300] Finished\n",
      "[Itr 400] Finished\n",
      "[Itr 500] Finished\n",
      "[Itr 600] Finished\n",
      "[Itr 700] Finished\n",
      "[Itr 800] Finished\n",
      "[Itr 900] Finished\n",
      "[Itr 1000] Finished\n",
      "INFO:tensorflow:./Dataset/yahoo-1000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 1000] loss: 2132.264733\n",
      "..(dataset: Val) evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7328/7328 [00:05<00:00, 1364.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..(dataset: Val) AUC 0.8785219033144833\n",
      "[Itr 1100] Finished\n",
      "[Itr 1200] Finished\n",
      "[Itr 1300] Finished\n",
      "[Itr 1400] Finished\n",
      "[Itr 1500] Finished\n",
      "[Itr 1600] Finished\n",
      "[Itr 1700] Finished\n",
      "[Itr 1800] Finished\n",
      "[Itr 1900] Finished\n",
      "[Itr 2000] Finished\n",
      "INFO:tensorflow:./Dataset/yahoo-2000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 2000] loss: 737.583823\n",
      "..(dataset: Val) evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7328/7328 [00:04<00:00, 1517.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..(dataset: Val) AUC 0.8910914633395196\n",
      "[Itr 2100] Finished\n",
      "[Itr 2200] Finished\n",
      "[Itr 2300] Finished\n",
      "[Itr 2400] Finished\n",
      "[Itr 2500] Finished\n",
      "[Itr 2600] Finished\n",
      "[Itr 2700] Finished\n",
      "[Itr 2800] Finished\n",
      "[Itr 2900] Finished\n",
      "[Itr 3000] Finished\n",
      "INFO:tensorflow:./Dataset/yahoo-3000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 3000] loss: 628.045095\n",
      "..(dataset: Val) evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7328/7328 [00:05<00:00, 1396.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..(dataset: Val) AUC 0.8951388031680569\n",
      "[Itr 3100] Finished\n",
      "[Itr 3200] Finished\n",
      "[Itr 3300] Finished\n",
      "[Itr 3400] Finished\n",
      "[Itr 3500] Finished\n",
      "[Itr 3600] Finished\n",
      "[Itr 3700] Finished\n",
      "[Itr 3800] Finished\n",
      "[Itr 3900] Finished\n",
      "[Itr 4000] Finished\n",
      "INFO:tensorflow:./Dataset/yahoo-4000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 4000] loss: 581.388277\n",
      "..(dataset: Val) evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7328/7328 [00:07<00:00, 940.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..(dataset: Val) AUC 0.8962030982781471\n",
      "[Itr 4100] Finished\n",
      "[Itr 4200] Finished\n",
      "[Itr 4300] Finished\n",
      "[Itr 4400] Finished\n",
      "[Itr 4500] Finished\n",
      "[Itr 4600] Finished\n",
      "[Itr 4700] Finished\n",
      "[Itr 4800] Finished\n",
      "[Itr 4900] Finished\n",
      "[Itr 5000] Finished\n",
      "INFO:tensorflow:./Dataset/yahoo-5000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 5000] loss: 557.894164\n",
      "..(dataset: Val) evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7328/7328 [00:04<00:00, 1525.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..(dataset: Val) AUC 0.8969368878137339\n",
      "[Itr 5100] Finished\n",
      "[Itr 5200] Finished\n",
      "[Itr 5300] Finished\n",
      "[Itr 5400] Finished\n",
      "[Itr 5500] Finished\n",
      "[Itr 5600] Finished\n",
      "[Itr 5700] Finished\n",
      "[Itr 5800] Finished\n",
      "[Itr 5900] Finished\n",
      "[Itr 6000] Finished\n",
      "INFO:tensorflow:./Dataset/yahoo-6000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 6000] loss: 542.519586\n",
      "..(dataset: Val) evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7328/7328 [00:04<00:00, 1560.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..(dataset: Val) AUC 0.8970892273843377\n",
      "[Itr 6100] Finished\n",
      "[Itr 6200] Finished\n",
      "[Itr 6300] Finished\n",
      "[Itr 6400] Finished\n",
      "[Itr 6500] Finished\n",
      "[Itr 6600] Finished\n",
      "[Itr 6700] Finished\n",
      "[Itr 6800] Finished\n",
      "[Itr 6900] Finished\n",
      "[Itr 7000] Finished\n",
      "INFO:tensorflow:./Dataset/yahoo-7000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 7000] loss: 534.255741\n",
      "..(dataset: Val) evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7328/7328 [00:04<00:00, 1671.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..(dataset: Val) AUC 0.8968870370503513\n",
      "[Itr 7100] Finished\n",
      "[Itr 7200] Finished\n",
      "[Itr 7300] Finished\n",
      "[Itr 7400] Finished\n",
      "[Itr 7500] Finished\n",
      "[Itr 7600] Finished\n",
      "[Itr 7700] Finished\n",
      "[Itr 7800] Finished\n",
      "[Itr 7900] Finished\n",
      "[Itr 8000] Finished\n",
      "INFO:tensorflow:./Dataset/yahoo-8000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 8000] loss: 528.727392\n",
      "..(dataset: Val) evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7328/7328 [00:04<00:00, 1612.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..(dataset: Val) AUC 0.8967568938090202\n",
      "[Itr 8100] Finished\n",
      "[Itr 8200] Finished\n",
      "[Itr 8300] Finished\n",
      "[Itr 8400] Finished\n",
      "[Itr 8500] Finished\n",
      "[Itr 8600] Finished\n",
      "[Itr 8700] Finished\n",
      "[Itr 8800] Finished\n",
      "[Itr 8900] Finished\n",
      "[Itr 9000] Finished\n",
      "INFO:tensorflow:./Dataset/yahoo-9000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 9000] loss: 522.831909\n",
      "..(dataset: Val) evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7328/7328 [00:04<00:00, 1627.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..(dataset: Val) AUC 0.8966660143131612\n",
      "[Itr 9100] Finished\n",
      "[Itr 9200] Finished\n",
      "[Itr 9300] Finished\n",
      "[Itr 9400] Finished\n",
      "[Itr 9500] Finished\n",
      "[Itr 9600] Finished\n",
      "[Itr 9700] Finished\n",
      "[Itr 9800] Finished\n",
      "[Itr 9900] Finished\n",
      "[Itr 10000] Finished\n",
      "INFO:tensorflow:./Dataset/yahoo-10000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[Itr 10000] loss: 520.152143\n",
      "..(dataset: Val) evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7328/7328 [00:04<00:00, 1638.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..(dataset: Val) AUC 0.8964089462055704\n"
     ]
    }
   ],
   "source": [
    "model_trainer.train(num_itr=10001, display_itr=display_itr, eval_datasets=[val_dataset],\n",
    "                    evaluators=[auc_evaluator], num_negatives=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SAVE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:./Dataset/cml-yahoo is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "cml_model.save(folder_name + \"cml-yahoo\",None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecSysEvaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
