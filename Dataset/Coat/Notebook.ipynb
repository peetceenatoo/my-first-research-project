{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.random as npr\n",
    "from scipy import sparse, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "seed = 2384795\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "# Preparing folder for output data\n",
    "output_name = f\"./generated_data/\"\n",
    "if os.path.exists(output_name) == False:\n",
    "    os.makedirs(output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './original_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(os.path.join(DATA_DIR, 'train.ascii'), sep=\" \", header=None, engine=\"python\")\n",
    "test_data = pd.read_csv(os.path.join(DATA_DIR, 'test.ascii'), sep=\" \", header=None, engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_vd_data = pd.DataFrame({\"userId\": sparse.coo_matrix(raw_data).row,                            \"songId\": sparse.coo_matrix(raw_data).col,                           \"rating\": sparse.coo_matrix(raw_data).data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame({\"userId\": sparse.coo_matrix(test_data).row,                            \"songId\": sparse.coo_matrix(test_data).col,                           \"rating\": sparse.coo_matrix(test_data).data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   userId  songId  rating\n",
       " 0       0      72       2\n",
       " 1       0     136       2\n",
       " 2       0     150       3\n",
       " 3       0     171       3\n",
       " 4       0     188       3,\n",
       " (6960, 3))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_vd_data.head(), tr_vd_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   userId  songId  rating\n",
       " 0       0      12       4\n",
       " 1       0      17       3\n",
       " 2       0      74       4\n",
       " 3       0      78       2\n",
       " 4       0      92       2,\n",
       " (4640, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(), test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4640 entries, 0 to 4639\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   userId  4640 non-null   int32\n",
      " 1   songId  4640 non-null   int32\n",
      " 2   rating  4640 non-null   int64\n",
      "dtypes: int32(2), int64(1)\n",
      "memory usage: 72.6 KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_proportion(data, uid, test_prop=0.5, random_seed=0):\n",
    "    data_grouped_by_user = data.groupby(uid)\n",
    "    tr_list, te_list = list(), list()\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    for u, (_, group) in enumerate(data_grouped_by_user):\n",
    "        n_items_u = len(group)\n",
    "\n",
    "        if n_items_u >= 5:\n",
    "            idx = np.zeros(n_items_u, dtype='bool')\n",
    "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
    "\n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        else:\n",
    "            tr_list.append(group)\n",
    "\n",
    "        if u % 5000 == 0:\n",
    "            print(\"%d users sampled\" % u)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "    \n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(tp, id):\n",
    "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "    count = playcount_groupbyid.size()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_activity = get_count(tr_vd_data, 'userId')\n",
    "item_popularity = get_count(tr_vd_data, 'songId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_uid = user_activity.index\n",
    "unique_sid = item_popularity.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = len(unique_uid)\n",
    "n_items = len(unique_sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290, 300)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users, n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "song2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "user2id = dict((uid, i) for (i, uid) in enumerate(unique_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the test set, only keep the users/items from the training set\n",
    "\n",
    "test_data = test_data.loc[test_data['userId'].isin(unique_uid)]\n",
    "test_data = test_data.loc[test_data['songId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn userId and songId to 0-based index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerize(tp):\n",
    "    uid = list(map(lambda x: user2id[x], tp['userId']))\n",
    "    sid = list(map(lambda x: song2id[x], tp['songId']))\n",
    "    tp.loc[:, 'uid'] = uid\n",
    "    tp.loc[:, 'sid'] = sid\n",
    "    return tp[['uid', 'sid', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_vd_data = numerize(tr_vd_data)\n",
    "test_data = numerize(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do we really need to split for our purpose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users sampled\n",
      "0 users sampled\n"
     ]
    }
   ],
   "source": [
    "train_data, vad_data = split_train_test_proportion(tr_vd_data, 'uid', test_prop=0.6, random_seed=12345)\n",
    "obs_test_data, vad_data = split_train_test_proportion(vad_data, 'uid', test_prop=0.5, random_seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total of 290 unique users in the training set and 290 unique users in the entire dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"There are total of %d unique users in the training set and %d unique users in the entire dataset\" % (len(pd.unique(train_data['uid'])), len(unique_uid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total of 300 unique items in the training set and 300 unique items in the entire dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"There are total of %d unique items in the training set and %d unique items in the entire dataset\" % (len(pd.unique(train_data['sid'])), len(unique_sid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_fill(part_data_1, part_data_2, unique_id, key):\n",
    "    # move the data from part_data_2 to part_data_1 so that part_data_1 has the same number of unique \"key\" as unique_id\n",
    "    part_id = set(pd.unique(part_data_1[key]))\n",
    "    \n",
    "    left_id = list()\n",
    "    for i, _id in enumerate(unique_id):\n",
    "        if _id not in part_id:\n",
    "            left_id.append(_id)\n",
    "            \n",
    "    move_idx = part_data_2[key].isin(left_id)\n",
    "    part_data_1 = part_data_1.append(part_data_2[move_idx])\n",
    "    part_data_2 = part_data_2[~move_idx]\n",
    "    return part_data_1, part_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, vad_data = move_to_fill(train_data, vad_data, np.arange(n_items), 'sid')\n",
    "train_data, obs_test_data = move_to_fill(train_data, obs_test_data, np.arange(n_items), 'sid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total of 300 unique items in the training set and 300 unique items in the entire dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"There are total of %d unique items in the training set and %d unique items in the entire dataset\" % (len(pd.unique(train_data['sid'])), len(unique_sid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(os.path.join(output_name, 'train.csv'), index=False)\n",
    "vad_data.to_csv(os.path.join(output_name, 'validation.csv'), index=False)\n",
    "tr_vd_data.to_csv(os.path.join(output_name, 'train_full.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_test_data.to_csv(os.path.join(output_name, 'obs_test_full.csv'), index=False)\n",
    "test_data.to_csv(os.path.join(output_name, 'test_full.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecSysEvaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
